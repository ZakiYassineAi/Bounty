{"origin_pdf_path": "https://7520354.fs1.hubspotusercontent-na1.net/hubfs/7520354/The%20YesWeHack%20Bug%20Bounty%20Report%20-%202025%20Edition.pdf", "text_in_pdf": "FINAL PODIUM OF FERRERO EVENT September 2024  \n\n  \n\n\"The atmosphere is really cool. it's nice to see other hunters, to discuss together, to exchange some hints... it's very cool.\"  \n\n  \n\nThis opportunity was essential to explore new areas and methodologies for detecting vulnerabilities, push the limits of security testing, and strengthen our proactive approach to protecting digital assets and data. The goal is to learn, grow and continue to build a more secure digital environment.\"  \n\n  \n\nFINAL PODIUM OF BANCO GALICIA EVENT November 2024  \n\n  \n\n6  \n\nIt's like an emotional rollercoaster: you're calm and then suddenly you have to triage vulnerabilities, understand them, discuss them with the hunters.\"  \n\n  \n\n  \n\n  \n\n\"A live hacking event is always a good experience because we are able to meet the people behind their handle or nickname.  \n\n  \n\n  \n\nBUG BOUNTY AND THE CHALLENGE OF SECURI  \n\nWe  can expect to see increasing adoption of crowdsourced  security   testing   within  the  open source  ecosystem   given the   proliferation  of vulnerabilities   across   this ubiquitous,  critically important software. In turn, we anticipate that growing  numbers   of  hunters  will  acquire   the specialist skills required for probing open source scopes.  \n\nThe vast majority of applications (97%) contain open source components, according to GitHub, while legacy open source software continues to persist The implications of   inadequate vulnerability management were particularly laid bare by 'Log4Shell, which is widely considered to be one of, if not the, most damaging vulnerability of all time. The super-critical flaw in Log4j, an open-source Java logging tool built into applications with billions of users collectively, caused havoc when it surfaced in 2021 through an otherwise unremarkable software update.  \n\nA 2024 report from Sovereign Tech Fund (STF), which invests in open digital infrastructure to ensure a resilient, sustainable open source ecosystem, says bug bounties are effective at boosting the number and quality of vulnerability reports. In 'Bug Bounties and FOsS: Opportunities, Risks, and a Path Forward' Dr Ryan Ellis also writes that crowdsourcing security testing helps \"projects retain expert talent and reduce community churn, and they can provide accountability  mechanisms   and   tools   that   are otherwise lacking\". Moreover, the report from STF, a YesWeHack customer, endorses how Bug Bounty platforms incentivise honest, professional conduct on the part of hunters through financial rewards, as well as a points-based system that rewards quality vulnerabilities, and clear, responsive communication with customers.  \n\nBug Bounty is particularly useful as an extra layer of security for mature open-source projects, said the report.  \n\n  \n\nSovereign Tech Fund  \n\nDr Ellis noted the mixed security performance of this huge, diverse ecosystem, with some libraries much better resourced and more attentively maintained than others. After all, the likes of Google, Microsoft and Red Hat help to fund some projects, while others are maintained unassisted by volunteers who juggle the task in conjunction with day jobs. The STF report therefore   recommends  that   projects  invest  in remediation capabilities and, to prevent an overload of low quality reports, general maintenance before embarking on a Bug Bounty Program.  \n\nWhether they provide critical functions or are built into applications used by millions, open source targets on YesWeHack currently include some highly consequential libraries. As well as Log4j, STF has public programs for systemd, GNOME, ntpd-rs, OpenPGP.js, Sequoia PGP and CycloneDX Rust Cargo. (Given other STF active investments include the likes of Drupal, PHP and GNU libmicrohttpd, the organisation may well be a source of exciting new hunting opportunities in the not-too-distant future.)  \n\nDespite the resource constraints dogging some corners of the ecosystem, the open source rewards on offer on YesWeHack are among the most generous on our platform - reflecting the commitment to security of their custodians and the challenging nature of many of the targets. All seven STF programs are currently offering rewards up to 10,oo0 for critical vulnerabilities. We also have a trio of open source programs from Open-Xchange, with PowerDNS offering max rewards of E8,0o0 and Ox App Suite plus Dovecot offering up to ∈5,000.  \n\nOur societies increasingly rely on open source software as critical infrastructure, and it takes a lot of effort to keep that infrastructure safe. Which is why STF is committed to fostering the community of security researchers looking to use their skills to secure the open source ecosystem  \n\n  \n\nNot just motivated by money, we believe hunters also relish  the  chance to  secure critical infrastructure that underpins a free and open internet - and to help others do the same. Consider for instance how 'Sigabrt, who stars on our open source leaderboard, contributed  to community knowledge with a case study detailing a vulnerability he found on GNOME  \n\nTOP7 TAKEAWAYSFROM OUR BUG BOUNTY REPORT  \n\nAs we enter our 1oth year, YesWeHack is continuing to play our part in popularising Bug Bounty worldwide, including in territories with modest levels of crowdsourced security testing. Of course, in a world of accelerating change, we must also strive to more fully realise the intrinsic benefits of Bug Bounty by strengthening our people, processes and platform. In pursuit of this goal, it's impossible to ignore one technology in particular. It's also a transformational technology for ethical and malicious hackers alike. While Al is not explicitly mentioned elsewhere in this report, it doubtless played an increasing role in the emergence of new hacking techniques and the automation of vulnerability discovery, validation and remediation - and this trend will surely accelerate. We can expect LLM bugs to become more common, for instance.  \n\nYesWeHack's experiences during 2024 offer salutary lessons about not just the value of our own products but the nature of the Bug Bounty model in general too. In summarising the statistics amassed from our platform and anecdotal evidence provided by hunters and customers, the following seven trends stand out:  \n\n01  \n\n> The rapid increase in the number of YesWeHack programs evidences increasing Bug Bounty adoption worldwide - and the visible segment (public programs) is just the tip of the iceberg (namely 10% of all our programs)  \n\n02  \n\n> CISOs and other senior security professionals frequently cite the same Bug Bounty benefits as their release schedules accelerate: agility, scalability, continuous testing of unparalleled depth and breadth, an aid to compliance, and a facilitator of secure development practices  \n\n03  \n\n> As scopes are hardened, new products are launched and numbers of vulnerability reports of various severities fluctuate, it's clear how pivotal customer success and triage teams are to programs' alignment with customer goals and prompt remediation of bugs, especially the most critical (our low duplicate rate attests to our success in this latter area)  \n\n04  \n\nBug Bounty is potentially lucrative given the size of top-end payouts and the prolific performance of many hunters - and an excellent return on investment for customers given results-based pricing and the size of more typical bounties  \n\n05  \n\nYet hunters are not just motivated by money - their palpable enthusiasm is also born of a passion for hacking itself, the thrill of climbing the leaderboard. and the chance to collaborate and share advice with peers. It's not for nothing that we describe our hunters as a'community  \n\n06  \n\n> Customers and hunters alike extol the value of not just technical hacking expertise but soft skills too - in particular tenacity and a talent for communication and collaboration. Our points-based system rewards hunters who excel in both dimensions  \n\nLive hacking events are producing impressive results for some of the world's most illustrious brands - whose experiences may help persuade other organisations to follow suit  \n\nWe're confident that these insights will continue to hold true as we progress through 2025 and beyond - alongside, no doubt, some trends that few of us had foreseen. Whether you're a hunter, CisO or other security professional, we hope to continue our exciting journey with your support. No doubt we'll see many of you at conferences and live hacking events throughout 2025.\n\nRichmond Journal of Law & T echnology Richmond Journal of Law & T echnology \nVolume 29 Issue 1 Article 3 \n11-30-2022 \nShooting the Messenger: Remediation of Disclosed V ulner abilities Shooting the Messenger: Remediation of Disclosed V ulner abilities \nas CF AA \"Loss\" as CF AA \"Loss\" \nRiana Pf efferkorn \nStanfor d Internet Obser vatory \nFollow this and additional works at: https:/ /scholarship.richmond.edu/jolt \nRecommended Citation Recommended Citation \nRiana Pf efferkorn, Shooting the Messenger: Remediation of Disclosed V ulner abilities as CF AA \"Loss\" , 29 \nRich. J.L. & T ech 89 (). \nAvailable at: https:/ /scholarship.richmond.edu/jolt/v ol29/iss1/3 \nThis Ar ticle is br ought t o you for fr ee and open access b y the Law School Journals at UR Scholarship Reposit ory. It \nhas been accepted for inclusion in Richmond Journal of Law & T echnology b y an authoriz ed edit or of UR \nScholarship Reposit ory. For mor e information, please contact scholarshipr eposit ory@richmond.edu . \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n \n \n \n \n 89 SHOOTING THE MESSENGER : \nREMEDIATION OF DISCLOSED VULNERABILITIES AS CFAA  \n“LOSS” \n \n \n \n \nRiana Pfefferkorn \n \nCite as: Riana Pfefferkorn, Shooting the Messenger: Remediation of \nDisclosed Vulnerabilities as CFAA “Loss,” 29 R ICH. J.L. & TECH. 89 \n(2022).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n Research Scholar, Stanford Internet Observatory. The Internet Observatory’s funding \nsources are available at https://cyber.fsi.stanford.edu/io/news/stanford -internet-\nobservatory -two-years . Thank s to Dan Bateyko and to participants in the 2022 \nCybersecurity  Law and Policy Scholars Conference for their helpful comments and \nsuggestions on an earlier draft, and to the hardworking staff of the Richmond Journal of \nLaw and Technology. This article is dedicated to the memories of Peter Eckersley, Elliot Harmon, Dan Kaminsky,  Dmitry Karshtedt,  and Sherwin Siy.  \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n \n \n \n \n 90  \nAbstract \n \nThe Computer Fraud and Abuse Act (CFAA) provides a \ncivil cause of action for computer hacking victims that have \nsuffered certain types of harm. Of these harms, the one most \ncommonly invoked by plaintiffs is having suffered $5,000 or \nmore of cognizable “loss” as defined by the statute. In its first-ever CFAA case, 2021’s Van Buren v. United States, \nthe Supreme Court included intriguing language that “loss” in civil cases should be limited to “technological harms” \nconstituting “the typical consequences of hacking.” To date, \nlower courts have only followed the Court’s interpretation if \ntheir circuit already interpreted “loss” narrowly pre-Van Buren and have continued to approach “loss” broadly \notherwise.  \n \nVan Buren did not fully dissipate the legal risks the \nCFAA has long posed to a particular community: people \nwho engage in good-faith cybersecurity research. \nDiscovering and reporting security vulnerabilities in \nsoftware and hardware risks legal action from vendors \ndispleased with unflattering revelations about their products’ \nflaws. Research activities have even led to criminal \ninvestigations at times . Although Van Buren narrowed the \nCFAA’s scope and prompted reforms in federal criminal charging policy, researchers continue to face some legal \nexposure. The CFAA still lets litigious vendors “shoot the \nmessenger” by suing over security research that did them no \nharm. Spending just $5,000 addressing a vulnerability is \nsufficient to allow the vendor to sue the researcher who \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n \n \n \n \n 91 reported it, because such remediation costs qualify as “loss” \neven in courts that read that term narrowly.  \n \nTo mitigate the CFAA’s legal risk to researchers, a \ncommon proposal is a statutory safe harbor for security research. Such proposals walk a fine line between being \nunduly byzantine for good-faith actors to follow and lax \nenough to invite abuse by malicious actors. Instead of the \nsafe harbor approach, this article recommends a simpler way \nto reduce litigation over harmless research: follow the \nmoney.  \n The Article proposes (1) amending the CFAA’s “loss” \ndefinition to prevent vulnerability remediation costs alone from satisfying the $5,000 standing threshold absent any \nother alleged loss, and (2) adding a fee-shifting provision \nthat can be invoked where plaintiffs’ losses do not meet that \nthreshold. Tightening up the “loss” calculus would \ndisqualify retaliatory litigation against beneficial (or at least \nbenign) security research while preserving victims’ ability to \nseek redress where well-intended research activities do \ncause harm. Fee-shifting would deter weak CFAA claims \nand give the recipients of legal threats some leverage to fight \nback. Coupled with the Van Buren decision, these changes \nwould reach beyond the context of vendor versus researcher: they would help rein in the CFAA’s rampant misuse over \nbehavior far afield from the law’s core anti-hacking purpose.  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 92 I.  I NTRODUCTION  \n \n[1]  The Computer Fraud and Abuse Act (CFAA)1 is the nation’s federal \ncomputer trespass statute. It prohibits trespass and damage to or theft from a computer and allows victims to recover civilly for the “loss” incurred in \nresponding to an intrusion.\n2  \n [2]  As “an anti-hacking statute,”\n3 the CFAA has hindered cybersecurity \nprogress by treating those who seek to fix cybersecurity shortcomings the same as those who seek to exploit them. The law is so broad that it can be \nread to prohibit not just malicious computer intrusions and destruction, but \nalso research that aims in good faith to improve the state of computer \nsecurity by finding digital security vulnerabilities and reporting them to the \nproduct vendors.\n4 These activities are chilled by the threat of liability under \nthe CFAA.   \n[3]  The Supreme Court’s first-ever CFAA case, 2021’s Van Buren v. \nUnited States,\n5 somewhat reined in the law’s scope. It thus partially \nmitigated the legal threat to security researchers, especially by prompting \n \n1 Computer Fraud and Abuse Act of 1986, 18 U.S.C. § 1030.  \n \n2 18 U.S.C. §§ 1030(a)(2) , (a)(5), (e)(11), (g) ; see also Robert Chesney,  Cybersecurity \nLaw, Policy, and Institutions 17 (U. of Texas Law, Pub. Law Research Paper No. 716, \nAug. 23, 2021) (framing the statute as one involving trespass and theft) . \n \n3 United States v. Nosal, 676 F.3d 854, 857 (9th Cir. 2012) (en banc).  \n \n4 JOSEPH LORENZO HALL & STAN ADAMS , TAKING THE PULSE OF HACKING : A RISK \nBASIS FOR SECURITY RESEARCH  8–11 (2018), https://josephhall.org/papers/2018- 03-27-\nRisk-Basis -for-Security -Research- FNL.pdf [https://perma.cc/9SQG -GZLD] ; \nCybersecurity Information Sharing Act, 6 U.S.C. § 1501(17)  (“The term ‘security \nvulnerability’ means any attribute of hardware, software, process, or procedure that could \nenable or facilitate the defeat of a security control.”).  \n5 Van Buren v. United States, 141 S. Ct. 1648 (2021).  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 93 changes in federal criminal charging policy. However, some risk remains, \nprincipally of civil litigation. Although Van Buren narrowly interpreted \n“loss” in the civil context to “focus on technological harms,”6 a review of \nsubsequent CFAA decisions reveals that lower courts have not followed the \nCourt’s lead unless their precedent already favored a narrow reading of that \nterm.7 \n \n[4]  The CFAA’s definition of “loss” is why, even after Van Buren, \nvendors can threaten legal action against security researchers.  If a vendor \nspends enough money investigating and repairing (or “patching”) a flaw (or \n“bug”), the Act grants the vendor standing to file suit and “shoot the \nmessenger” who brought the vulnerability to its attention. For a vendor that \nfinds and patches its own bugs, there is nobody to sue; repairs are part of \nthe cost of doing business. Yet, if a vulnerability is found and reported by \nan outsider rather than an insider, the CFAA lets a vendor externalize its \nremediation costs onto the outsider, even where the outsider has done no damage to the vendor’s computer systems. This is comparable to someone \nwho, having “enter[ed] a doorway with no lock,” alerts the building owner \nto the insecure entryway , only to be “held liable for the cost of installing a \nlock afterwards.”\n8 Van Buren does not foreclose such “shooting the \nmessenger” lawsuits.  \n[5]  To shield good-faith security researchers from legal risk, \ncommentators have frequently proposed adding a “safe harbor” to the CFAA for researchers’ activities. After critiquing the safe-harbor approach, \nthis Article suggests an alternative way to protect researchers from civil \nliability: amending the Act to (1) preclude vulnerability remediation costs \n \n6 Id. at 1659 –60. \n \n7 See infra  Section IV .B.  \n \n8 Note, Immunizing the Internet, or: How I Learned to Stop Worrying and Love the \nWorm, 119  HARV. L. REV. 2442,  2454  (2006)  (criticizing the “loss” definition as \n“overinclusive” because  patching costs are “money that one should reasonably expect \nusers to spend anyway” upon discovery of a security flaw, “regardless of whether their \nsystems have been attacked.” ). \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 94 alone from supplying statutory standing and (2) shift fees onto civil \nplaintiffs who prove unable to meet the revised statutory standing bar. This \nproposal would deter legal threats over beneficial research while preserving \nliability in instances of bad-faith or malicious conduct or where well-\nintended research goes awry. \n \nII.  T HE COMPUTER FRAUD AND ABUSE ACT \n [6]  The CFAA is “a civil and criminal anti-hacking statute designed to \nprohibit the use of hacking techniques to gain unauthorized access to electronic data.”\n9 At a high level, the CFAA prohibits two types of conduct: \naccessing a computer without authorization and exceeding authorized \naccess to a computer.10 To grasp why these prohibitions pose a threat to \nsecurity researchers requires understanding a few additional provisions of the statute. \nA.  Obtaining Information from a Protected Computer \n \n[7]  Several offenses under the CFAA require the involvement not \nmerely of a computer, but of a “protected computer.”\n11 As defined by the \nAct, “protected computer” means any computer or device that can connect \nto the Internet.12  \n \n \n9 Cvent, Inc. v. Eventbrite, Inc., 739 F. Supp. 2d 927, 932 (E.D. Va. 2010).  \n \n10 See 18 U.S.C. §§ 1030(a), (b), (e)(1).  \n \n11 18 U.S.C. §§ 1030(a)(2)(C), (a)(4), (a)(5), (a)(7).  \n \n12 Id. § 1030(e)(2)(B) (“[T]he term ‘protected computer’ means a computer  . . .   which is \nused in or affecting interstate or foreign commerce or communication, including a \ncomputer located outside the United States that is used in a manner that affects interstate or foreign commerce or communication of the United States[.]”).  \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 95 [8]  This loose definition of “protected computer” is part of what makes \none of the Act’s substantive offenses, subsection 1030(a)(2)(C), very broad \nin scope. Subsection 1030(a)(2)(C) is “[t]he least demanding CFAA \nprovision.”13 It requires only that the defendant “intentionally accesses a \ncomputer without authorization or exceeds authorized access, and thereby obtains . . . information from any protected computer[.]”\n14 It does not \nrequire that the defendant cause (or threaten to cause) any harm to the protected computer, in contrast to several other subsections of the statute.\n15 \nNor does this subsection specify what kind of information must be obtained \nor how much.16 Obtaining “some information––any information” is \nenough.17  \n \n[9]  This combination of “protected computer” and “obtaining \ninformation” makes the language of subsection (a)(2)(C) worryingly broad in scope. “Because a ‘protected computer’ is any computer with internet \naccess, and ‘obtain’ includes merely viewing information, any person who \nintentionally views information on a computer can potentially incur liability \n \n13 Samantha Jensen, Comment, Abusing the Computer Fraud and Abuse Act: Why Broad \nInterpretations of the CFAA Fail , 36 H AMLINE L. REV. 81, 94 (2013).  \n \n14 18 U.S.C. § 1030(a)(2)(C).  \n \n15 Compare  id. (no harm or threat requirement), with  id. §§ 1030(a)(5) , (7) ( requiring that \na defendant cause harm or threaten to cause harm) . \n \n16 Compare  id. § 1030(a)(2)(C) (prohibiting obtaining mere  “information from any \nprotected computer” ), with id. § 1030(a)(2)(A) –(B) (prohibiting obtaining  financial \nrecords or  information from any United States agency).  \n \n17 Orin S. Kerr, Vagueness Challenges to the Computer Fraud and Abuse Act , 94 M INN. \nL. REV. 1561, 1578 (2010) ; see also  id. at 1567 (“Since most forms of unauthorized \naccess will reveal information to read, even if it is only the prompts or graphic interface \nprovided to those with access,  the new § 1030(a)(2)  effectively criminalized all interstate \nhacking.”); United States v. Auernheimer, 748 F.3d 525, 537 –38 (3d Cir. 2014)  (“The \ncrime is complete even if the offender never looks at the information and immediately \ndestroys it, or the victim has no idea that information was ever taken.”) .  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 96 depending on how the court interprets authorization.”18 For years, \nsubsection (a)(2)(C) was recognized for having the potential to be treated \nas “an overwhelmingly overbroad enactment” that would criminalize large \nswaths of innocuous behavior unless it was narrowly interpreted by the \ncourts.19 The Supreme Court rejected such a result in 2021, siding with the \nnarrower interpretation adopted by several courts of appeal.20 However, all \nof those cases limited the statute’s scope by reading “authorization” \nnarrowly — not by limiting what “obtains information” requir es.21  \nB.  “Loss” for Purposes of Civil Claims \n \n[10]  In addition to criminal penalties, the CFAA also provides a private \nright of action to “[a]ny person who suffers damage or loss by reason of a violation of [the statute.]”\n22 The Act limits the bases on which a civil action \n \n18 Jensen, supra  note 13, at 94 n.86 (citing S. Rep. No. 99 -432, at 6 (1986)).  \n \n19 United States v. Drew, 259 F.R.D. 449, 466 (C.D. Cal. 2009).  \n \n20 Van Buren v. United States, 141 S. Ct. 1648, 1653– 54 (2021)  (discussing the split \nbetween circuits that took “a broader view” and those that took the narrower view \npropounded by the defense).  \n \n21 Id. at 1662 (“In sum, an individual ‘exceeds authorized access’ when he accesses a \ncomputer with authorization but then obtains information located in particular areas of the computer —such as files, folders, or databases— that are off limits to him.”); United \nStates v. Nosal, 676 F.3d 854, 859 –60 (9th Cir. 2012) (en banc); Jensen, supra  note 13, at \n130– 31 (“Since obtaining information from a protected computer translates into viewing \nany information on any computer, the court [in Nosal ] correctly surmised that adopting \nthe government’s definition [of ‘exceeds authorized access’] would impermissibly ‘transform whole categories of otherwise innocuous behav ior into federal crimes simply \nbecause a computer is involved.’”); see also  Sandvig v. Barr, 451 F. Supp. 3d 73, 91 \n(D.D.C. 2020) (“The Court agrees with the clear weight of relevant authority and adopts a narrow interpretation of . . . ‘accesses . . . wit hout authorization’ that excludes terms -of-\nservice violations.”).  \n22 18 U.S.C. §§ 1030(c), (g). \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 97 may be brought, of which the most common is “loss to 1 or more persons \nduring any 1-year period . . . aggregating at least $5,000 in value.”23 The \nCFAA defines “loss” to mean, as relevant here, “any reasonable cost to any victim, including the cost of responding to an offense, conducting a damage \nassessment, and restoring the data, program, system, or information to its \ncondition prior to the offense.”\n24 If the plaintiff fails to allege losses of at \nleast $5,000, the CFAA claim will be dismissed for lack of jurisdiction.25  \n \n[11]  The federal courts differ in how broadly they construe this \ndefinition, particularly the “cost of responding to an offense” portion. The Ninth Circuit reads the definition as “a narrow conception of ‘loss,’” limited \nto “harms caused by computer intrusions, not general injuries unrelated to \nthe hacking itself.”\n26 Similarly, district courts in the Second Circuit limit \nthe “loss” definition’s “cost of responding to an offense” language to “situations involving damage to or impairment of the protected \ncomputer.”\n27 Likewise, district courts in the Eighth Circuit have repeatedly \n \n23 Id. §§ 1030(c)(4)(A)(i)(I) , (g); B RENDA R. SHARTON ET AL ., KEY ISSUES IN COMPUTER \nFRAUD AND ABUSE ACT (CFAA)  CIVIL LITIGATION (2022) , Westlaw W -014-6206 \n(“Plaintiffs typically rely on the first factor, which requires proof that the computer fraud \ncaused a combined loss of at least $5,000 to one or more persons during any one -year \nperiod.”); U.S.  DEP’T OF JUSTICE , PROSECUTING COMPUTER CRIMES  42 (2010) , \nhttps://www.justice.gov/criminal/file/442156/download  [https://perma.cc/N8SF -DB2N] \n(“Of these enumerated harms, prosecutors most commonly charge loss .”). \n \n24 18 U.S.C. § 1030(e)(11).  \n \n25 See Nick Akerman, Why Two District Courts Dismissed Valid Computer Fraud and \nAbuse Claims for Lack of Jurisdiction, C ASE TEXT (Sept. 1, 2010), \nhttps://casetext.com/analysis/why -two-district -courts- dismissed- valid- computer- fraud -\nand-abuse -claims -for-lack-of-jurisdiction- 1 [https://perma.cc/32C9 -WNJS ]. \n \n26 Andrews v. Sirius XM Radio Inc., 932 F.3d 1253, 1262 –63 (9th Cir. 2019); Calendar \nResearch LLC v. StubHub, Inc., No. 17 -CV-04062, 2020 U.S. Dist. LEXIS 112361, at \n79 (C.D. Cal. May 13, 2020) (“[A] [p] laintiff must show [its] loss is related to \n[defendant’s] allegedly unlawful access.”).  \n \n27 Better Holdco, Inc. v. Beeline Loans, Inc., No. 20 -CV-8686, 2021 U.S. Dist. LEXIS \n138908, at 8 –10 (S.D.N.Y. July 26, 2021) (“In assessing whether certain costs are \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 98 held that “[t]he weight of relevant authority restricts the CFAA ‘loss’ \nrequirement to actual computer impairment[,]” with Third Circuit district \ncourts ruling similarly.28  \n [12]  The Fourth Circuit, by contrast, has called the “loss” definition a \n“broadly worded provision.”\n29 The Sixth and Eleventh Circuits also \nostensibly employ a broader reading,30 although the Sixth Circuit recently \n \nproperly considered the ‘cost of responding to an offense,’  [Second Circuit district \ncourts] focus on the connection between the plaintiff’s response and ‘damage to or \nimpairment of the protected device.’ ” (citing 18 U.S.C. § 1030(e)(11)). In tension with \nthis “damage or impairment” requirement , other Southern District decisions have allowed \n“loss” to include the cost of investigations that ultimately found no actual damage . See id. \nat 10 –11 (citing Kaufman v. Nest Seekers, LLC, No. 05 -CV-6782, 2006 U.S. Dist. \nLEXIS 71104, at 24 –25 (S.D.N.Y. Sept. 26, 2006) ; Univ. Sports Publ’ns  Co. v. \nPlaymakers Media Co., 725 F. Supp. 2d 378, 387 (S.D.N.Y. 2010)) . \n \n28 Burnett v. Grundy, No. 14 -00301- CV, 2014 U.S. Dist. LEXIS 192624, at 5 (W.D. \nMo. Oct. 28, 2014) (citing Dewitt Ins., Inc. v. Horton, No. 13- CV-2585, 2014 U.S. Dist. \nLEXIS 72384 , at 10 (E.D. Mo. May 28, 2014));  Volpe v. Abacus Software Sys. Corp. , \nNo. 20- 10108, 2021 U.S. Dist. LEXIS 112641, at 15 –16 (D.N.J. June 16, 2021).  But see  \nErvin & Smith Advert. & Pub. Rels., Inc. v. Ervin, No. 08 -CV-459, 2009 U.S. Dist. \nLEXIS 8096, at 2 5–27 (D. Neb. Feb. 3, 2009) (rejecting defendant’s argument that \n“loss” must be constrained to “the physical damage done to Plaintiff’s computer system \nonly.”).  \n \n29 A.V. ex rel.  Vanderhye v. iParadigms, LLC, 562 F.3d 630, 646 (4th Cir. 2009). District \ncourts in the Fourth Circuit have relied on this language when counting as “loss” expenses that seem loosely tethered to repairing the alleged intrusion. E.g., Space \nSys./Loral, LLC v . Orbital ATK, Inc., 3 06 F. Supp. 3d 845, 852– 53 (E.D. Va. 2018) \n(“[Plaintiff] presents the costs it incurred as a result of the alleged CFAA violation that \nincluded conducting a damage assessment and convening and communicating with NASA and [Defendant] regarding the alleged breach. ”); Estes Forwarding Worldwide \nLLC v. Cuellar, 239 F. Supp. 3d 918, 927 –28 (E.D. Va. 2017) (allowing “loss” to include \nthe cost of plaintiff’s lawsuit against Comcast to uncover defendant’s identity as the Comcast subscriber whose IP address was use d to improperly access plaintiff’s Google \nDrive account).  \n \n30 Brown Jordan Int’l, Inc. v. Carmicle, 846 F.3d 1167, 1173 (11th Cir. 2017); Yoder & \nFrey Auctioneers, Inc. v. EquipmentFacts, LLC, 774 F.3d 1065, 1073 -74 (6th Cir. 2014).  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 99 opined that the “loss” definition “confirm[s] the Act’s narrow scope” by \n“aim[ing] at preventing the typical consequences of hacking” (as \ndistinguished from misuse of information), language the Supreme Court \nborrowed when interpreting the CFAA the following year.31 \n [13]  The statutory “loss” definition has received occasional attention in \nacademic literature. On the one hand, it has been criticized for enabling harsher penalties in criminal CFAA cases, where victim losses heavily \ninfluence sentencing,\n32 because courts let hacking victims tally their own \ncosts with little rigor or scrutiny.33 Victims control how much time and \nresources they expend “responding to an offense,” and courts accept the \ndollar numbers victims submit without question.34 Plus, the value of \nemployees’ and consultants’ time makes $5,000 a low bar to hit.35 On the \n \n31 Van Buren v. United States, 141 S. Ct. 1648, 1660 (2021) ( quoting Royal Truck & \nTrailer Sales & Serv. v. Kraft, 974 F.3d 756, 760 (6th Cir. 2020) ).  \n \n32 United States v. Agarwal, 24 F.4th 886, 889 (3d Cir. 2022) (“Under the United States \nSentencing Guidelines (USSG), th e recommended prison term is influenced heavily by \nthe loss suffered by the victims.”).  \n \n33 See James T. Graves et al. , Perception Versus Punishment in Cybercrime , 109 J.  CRIM. \nL. & CRIMINOLOGY  313, 321 (2019) (“[T]he CFAA is prone to inflated loss \ncalculations.”) .  \n \n34 Jennifer Granick, Faking It: Calculating Loss in Computer Crime Sentencing , 2 I/S:  \nJ.L.  & POL’Y FOR INFO. SOC’Y 207, 215, 221– 22 (2006)  (“Damage from an offense is a \nfunction of the idiosyncrasies of incident investigation, including the skills, experience, \nhourly rate, and remediation choices of the victim, and not necessarily the offender’s \nactions.”) .  \n \n35 “It is well settled that the value of time for employees who investigate [the defendant’s] \naccess qualifies as a loss.” Shawn E. Tuma, What Does the CFAA Mean and Why Should \nI Care? —A Primer on the Computer Fraud and Abuse Act for Civil Litigators , 63 S.C.  L. \nREV. 141, 187 (2011) . Perhaps $5,000 was a meaningful amount in 1986, but these days \nit is a fraction of the cost of hiring an incident response firm after an attack. See Mike \nBurgard, Cyber Incident Response: The Real Cost of Not Having a Plan or Cyber \nInsurance , MARCO (May 2 5, 2021), https://www.marconet.com/blog/cyber -incident -\nresponse [https://perma.cc/4XXK -ZXYW]; Andrea M. Matwyshyn & Stephanie K. Pell, \nBroken , 32 H ARV. J.L.  & TECH. 479, 557 n.408 (2019) (“[I]n light of the time value of \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 100 other hand, courts’ narrow interpretation of “loss” in the civil context was \nrecently critiqued for denying Americans the CFAA as a vehicle for \nremedying the alleged unwanted collection and misuse of their private \ninformation by corporate defendants.36  \n [14]  All told, however, out of the ample academic literature about the \nCFAA, little focuses on the “loss” provision.\n37 This may surprise practicing \nlawyers, since what losses courts will count for standing purposes is a \nquestion of great consequence to practitioners litigating CFAA claims (and \nof course, to their clients).38 For example, the CFAA has been invoked \nrepeatedly in consumer privacy lawsuits, but courts almost always dismiss \nthe claim due to plaintiffs’ inability to meet the $5,000 jurisdictional \nminimum, because “the loss of personal information is not a cognizable loss \nunder the statute.”39 The meaning of “loss” is frequently dispositive in civil \nlitigation, yet it is rarely examined in CFAA scholarship. \n \nmoney, even the statutory minimum amount of $5000 required by 18 U.S.C. 1030(g) \ntranslates to at least $8000 in 2018 dollars.”).  \n \n36 See Alicia Nakhjavan,  Note,  The “Worst Law in Technology”: How the Computer \nFraud and Abuse Act Allows Big Businesses to Collect and Sell Your Personal Information , 87 B\nROOK . L. REV. 1077, 1087 (2022) (“ This limited definition of loss has \nprevented many Americans from obtaining the reli ef the CFAA offers, particularly when \nthe claim is based on a loss of personal privacy.”).  \n \n37 E.g., Ioana Vasiu & Lucian Vasiu, Break on Through: An Analysis of Computer \nDamage Cases, 14 P ITT. J. TECH. L. & POL’Y 158, 186– 192 (2014); George Roach & \nWilliam J. Michiels, Damages Is the Gatekeeper Issue for Federal Computer Fraud , 8 \nTUL. J. TECH. & INTELL . PROP. 61, 62  (2006) . \n \n38 Cf. Sharton et al., supra note 23 (providing practical guidance to practitioners on this \nissue); Tuma, supra  note 35, at 182 –88 (pairing guidance to civil litigators on how to \nsufficiently plead the $5,000 threshold with spec ific examples of what has and has not \nconstituted a loss in court decisions).  \n \n39 Nakhjavan,  supra  note 36, at 1081 –82, 1087– 95. While in private practice from 2011 \nto 2015, the author  of this Article defended clients in multiple consumer privacy class \nactions where her case team successfully obtained the dismissal of the CFAA claim on \njust these grounds.  \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 101 III.  T HE CFAA’ S THREAT TO SECURITY RESEARCH  \n \n[15]  One aspect of the CFAA that has been well-documented is the \nchilling effect the law has had on the field of cybersecurity research. For years, the CFAA has been an object of fear for security researchers. A \nhistory of civil lawsuits and even criminal charges stemming from research activities has induced the understandable concern that their work could \nexpose them to liability due to the law’s notoriously broad substantive \nscope.\n40  \nA.  “Hackers” and Vulnerability Disclosure \n \n[16]  The community of people who look for computer security \nvulnerabilities is large and diverse. It encompasses a range of different motivations and goals, including mere curiosity, thrill-seeking, extortion, \nacademic interest, a desire to fix problems, and the urge to wreak havoc.\n41 \nEveryone in the community, regardless of their motivation, falls under the banner of “hackers,” notwithstanding the negative connotation the word \ncarries. In fact, malicious hackers comprise only a fraction of this \ncommunity.\n42 Mali cious individuals are commonly referred to as “black \nhat” hackers, “motivated by mischief or profit rather than by actually fixing vulnerabilities and security flaws.”\n43 Unlike black hat hackers, “white hat” \n(or “ethical”) hackers seek to improve cybersecurity by finding \n \n40 See, e.g., Hall & Adams, supra note 4; Nat Meysenburg, Cybersecurity Research \nShould Not Be a Crime: Why We Need Clear, Permanent CFAA and DMCA Exemptions , \nNEW AM. (Nov. 18, 2021), https://www.newamerica.org/oti/briefs/cybersecurity -\nresearch -should -not-be-a- crime/  [https://perma.cc/GLA5 -SC8N].  \n \n41 Ido Kilovaty, Freedom to Hack , 80 O HIO ST. L.J. 455, 480 (2019).  \n \n42 Id.   \n \n43 Id. at 482.  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 102 vulnerabilities in hardware and software.44 White hat hackers then disclose \nsuch vulnerabilities in a manner that makes them likely to be fixed (or \n“patched”), all while taking measures to do minimal harm in the process.45 \nWhite hats may operate under contract with vendors (which also typically employ their own internal security teams), although independent white-hat \nvulnerability researchers far outnumber contractors and internal \nemployees.\n46 White hat hacking is the category of activity this Article \ncontemplates when referring to “good faith” security research.  \n[17]  In between white and black hats are “gray hat” hackers, whose \nmotivations are more ambiguous.\n47 Some may have the same goals as white \nhats but are more willing to break the law in looking for bugs and to go \npublic with their findings in order to draw attention to vulnerabilities and \nshame vendors into fixing them.48 Other gray hats may have financial \nmotives more akin to black hats, leading them to monetize the vulnerabilities they find by selling that information to third parties rather \nthan disclosing vulnerabilities to the vendor so they can be patched.\n49  \n \n44 Id. at 481. \n \n45 Id. (“It would be best . . . to define w hite hats as hackers who seek to improve security \nwhile minimizing possible harm to the vulnerable target by neither exploiting the \nvulnerability nor selling it to malicious actors.”); Cassandra Kirsch, The Grey Hat \nHacker: Reconciling Cyberspace Reality and the Law, 41 N . KY. L. REV. 383, 385 –86 \n(2014).  \n \n46 Alexander Gamero- Garrido  et al.,  Quantifying the Pressure of Legal Risks on Third -\nparty Vulnerability Research,  in CC’17:  PROC. OF THE 2017  ACM  SIGSAC  CONF. ON \nCOMPUT . & COMMC ’NS SECURITY 1501  (2017),  https://acmccs.github.io/papers/p1501 -\ngamero -garridoA.pdf  [https://perma.cc/53VE -CWN6].  \n \n47 See Kilovaty,  supra  note 41, at 48 3; Kirsch, supra  note 45, at 386. \n \n48 Kilovaty, supra  note 41, at 482 (“Another distinction made [between white and gray \nhats] in literature is based on disclosure: hackers disclosing vulnerabilities directly to the vendor are white hats, while those publicizing vulnerabilities to the broader public are considered gray hats.”) (footnote omitted) ; Kirsch, supra  note 45, at 388.  \n \n49 Kilovaty, supra  note 41, at 483. \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 103  \n[18]  Given the diversity of the security community, it should come as \nlittle surprise that there is a longstanding difference of opinion about how best to disclose vulnerabilities.\n50 That is because the consequences of \ndisclosure can vary depending on how broad the dissemination is (i.e., to the vendor only versus the public at large) and what those who receive the \ndisclosure do with that knowledge.\n51 Disclosing a bug ought to improve \nsecurity by prompting the vendor to patch the bug (rather than sweeping it \nunder the rug and leaving users at risk).52 However, disclosure can also \nimpair security. Releasing detailed information about the flaw to the general public instead of the vendor could enable malicious actors to exploit it \nbefore the vendor can release a patch.\n53  \n [19]  There are several types of disclosure commonly used within the \nsecurity community. The first approach is generally known as “full disclosure.” A hacker who uses full disclosure releases the details of the bug \nto the public without first notifying the vendor, so that either the vendor will be pressured into fixing the bug or, if the vendor takes no action, affected \nusers can act to protect themselves.\n54 Compare that with “responsible \ndisclosure,” wherein a researcher first reports a bug to the vendor and allows \nthe vendor some time to fix the bug before publicly disclosing it.55 \nHowever, there is still disagreement over what exactly responsible \n \n50 Id. at 505 (“[T]here should be consensus on how to disclose vulnerabilities in an \nacceptable manner. At present, the philosophy on disclosure is highly fragmented and \ncontext -dependent.”).  \n \n51 Id. at 513.  \n \n52 See Kirsch, supra  note 45, at 388; Kilovaty, supra  note 41,  at 514.  \n \n53 Kirsch, supra  note 45,  at 388.  \n \n54 Kilovaty, supra  note 41,  at 516 –17. \n \n55 Id. at 514 –16. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 104 disclosure means in this context.56 Next, a “coordinated vulnerability \ndisclosure” is when a researcher reports a vulnerability to the vendor (or to \na relevant government agency that can in turn notify the vendor) and the \nparties then work collaboratively throughout the reporting, investigation, \nand remediation process before any party makes a public disclosure of the \nvulnerability.57 Coordinated vulnerability disclosure is a form of \nresponsible disclosure.58 Finally, those who wish to exploit vulnerabilities \nfor their own ends (such as black hats and intelligence agencies) favor \n“nondisclosure,” in which the actor does not report the discovered \nvulnerability.59  \n [20]  To encourage the responsible reporting of vulnerabilities (and \nharness hackers into playing by a set of rules), many organizations now publish vulnerability disclosure programs (VDPs), which invite hackers to \ntest the organization’s products for flaws and report what they find.\n60 \nOrganizations might also offer “bug bounty” programs (often hosted by a third-party platform), in which hackers are paid rewards for finding and \n \n56 Id. This Article’s proposal for protecting good -faith security research sidesteps the \ndebate over what counts as “responsible disclosure.” For our  purposes, it does not matter \nprecisely how someone disclosed a vulnerability; it matters only that they were the \nmessenger who n otified the vendor of it.  See infra  Section VI.B.  \n \n57 Coordinated Vulnerability Disclosure , MICROSOFT SEC. RESPONSE CTR., \nhttps://www.microsoft.com/en- us/msrc/cvd [https://perma.cc/5LEB -RHWH].  \n \n58 DANIEL ETCOVITCH & THYLA VAN DER MERWE , COMING IN FROM THE COLD: A SAFE \nHARBOR FROM THE CFAA  AND THE DMCA  § 1201  FOR SECURITY RESEARCHERS  12–13 \n(2018),  https://dash.harvard.edu/bitstream/handle/1/37135306/ComingOutoftheCold_  \nFINAL.pdf?sequence=1&isAllowed=y [ https://perma.cc/LD3Y -TBTW ]. \n \n59 Kilovaty, supra  note 41, at 514. \n \n60 Jasmine Arooni, Note,  Debugging the System: Reforming Vulnerability Disclosure \nPrograms in the Private Sector , 73 F ED. COMMC’N  L.J.  443, 445 n.6 (2021).  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 105 reporting vulnerabilities in compliance with terms set by the bounty offeror ; \nthese are effectively monetized VDPs.61 \nB.  Legal Risk to Researchers Under the CFAA \n \n[21]  One reason that VDPs and bug bounties exist is to establish, through \ncontract, “an alternative legal regime for facilitating ethical hacking,” amidst a statutory landscape that is “not well tailored to accommodate \n‘white-hat’ security research.”\n62 Along with other federal and state laws, the \nCFAA has long posed a serious risk of civil and criminal liability to security researchers, which paradoxically impedes rather than promotes the goal of \nbetter security.\n63 \n [22]  The CFAA has always posed a risk to researchers, even in its early \ndays. An early CFAA criminal prosecution involved a graduate student whose research into the poor state of network security on the then-nascent \nInternet went awry in late 1988, wreaking havoc on computer networks \naround the country.\n64 The CFAA has continued to cast a pall over security \n \n61 Id.; see Kirsch, supra note 45,  at 397; Gamero- Garrido et al., supra note 46, at 1503. \n \n62 Amit Elazari, Private Ordering Shaping Cybersecurity Policy: The Case of Bug \nBounties , in REWIRED : CYBERSECURITY GOVERNANCE 232 (Ryan Ellis & Vivek Mohan \neds., 2019); s ee Arooni, supra  note 60, at 445 n.6. \n \n63 See generally  Hall & Adams, supra  note 4 (listing the CFAA as a primary source of \nlegal risk to researchers, along with the Digital Millennium Copyright Act (DMCA), 17 \nU.S.C. §§ 512, 1201 –1205, 1301– 1332); SUNOO PARK & KENDRA ALBERT , A \nRESEARCHER ’S GUIDE TO SOME LEGAL RISKS OF SECURITY RESEARCH  6–23 (2020), \nhttps://clinic.cyber.harvard.edu/files/2020/10/Security_Researchers_Guide -2.pdf \n[https://perma.cc/MAM5 -CHBZ] (listing the CFAA, the DMCA, copyright, contract, \ntrade secrets, export control, and federal wiretapping laws as sources of legal risk).  \n \n64 United States v. Morris, 928 F.2d 504 (2d Cir. 1991) ; see also  Kerr, Norms of \nComputer Trespass , 116 C OLUM . L. REV. 1143,  1159 (2016)  (“[United States v. Morris  \nwas] [t]he very first federal appellate case on the meaning of authorization in the \nCFAA [.]”). \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 106 research in the years since.65 Discovering and reporting security \nvulnerabilities may draw legal threats from vendors, notwithstanding a \nresearcher’s responsible disclosure practices.66 Vendors “tend to get testy \nwhen deficiencies in their products and services are unceremoniously exposed [,]” and hackers have in the past been enjoined from, and even \ncriminally prosecuted for, publishing unflattering research findings.\n67  \n \n[23]  The advent of VDPs and bug bounties has in some respects only \nperpetuated the problem of researchers bearing liability by enabling vendors to control outside research into their products while providing little legal \nassurance to the researcher in return.\n68 The terms of these programs are \noften poorly drafted, voluminous, and impose onerous requirements on researchers, making compliance difficult.\n69 At the same time, these terms \noften do not contain strong contractual protections from liability for researchers, and indeed tend to allocate legal risk to the participant.\n70 \n \n65 See Computer Fraud and Abuse Act (CFAA) , NAT’L ASS’N CRIM. DEF. LAW., \nhttps://www.nacdl.org/Landing/ComputerFraudandAbuseAct  [https://perma.cc/8FEN -\nGMPH].  \n \n66 Jonathan Mayer, Cybercrime Litigation , 164 U . PA. L. REV. 1453, 1466– 67 (2016); \nGamero -Garrido et al., supra  note 46, at 1501; Hall & Adams, supra  note 4, at 12.  \n \n67 Mayer, supra  note 66, at 1466 –67; Kilovaty, supra note 41,  at 501 –02. \n \n68 Thomas E. Kadri, Digital Gatekeepers , 99 T EX. L. REV. 951, 977– 82 (2021); Elazari, \nsupra  note 62, at 11 –12; Kilovaty, supra note 41,  at 504.  \n \n69 Arooni, supra  note 60,  at 451 (“ Poorly crafted legal terms may subject a researcher to \nunknown liability, while overly -restrictive terms muzzle researchers and discourage \nresearch. ”); Elazari, supra  note 62, at 24 ( “[H]ackers are expected to master (and read) \naround twenty to thirty pages before submitting a bug, and also debate how to address \npotential conflicts: a considerable informational burden. ”). \n \n70 Kilovaty, supra note 41, at 504  (“[D]ue to differences in bargaining power, as well as \nstakes, the contractual language does not always provide for a ‘safe harbor’ for security researchers .”); Elazari, supra  note 62, at 26 (stating that common practice in VDP and \nbug bounty legal terms “shifts the legal risk to the hacker”) ; see also  E\nTCOVITCH & VAN \nDER MERWE , supra  note 58, at 39 ( “[T]he disclosure schedule is entirely determined by  \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 107 [24]  As a result of this hostile legal environment, good-faith researchers \nhave been scared to undertake research projects that might expose them to \nliability.71 This is bad news for the rest of us. Discussions of the CFAA’s \nlegal threat have “emphasized that cybercrime liability is, in fact, backfiring: by chilling vital research, cybercrime law actually reduces \ncomputer security.”\n72 The law’s chilling effect on security testing means \nvulnerabilities may go undiscovered, or at least unreported to the affected vendors.\n73 Legal interpretations of the CFAA that blurred “the line between \nmalicious hacking and researching for security vulnerabilities” have historically served only to “give[] cyber security researchers a disincentive \nto find security flaws, which makes the rest of us less safe” from malicious \nactivity.\n74 That is why not just cybersecurity researchers, but the public at \nlarge, had so much riding on the outcome of a court case about a crooked cop.\n75 \n \nthe vendor, assuming the finder would like to avoid having legal action levied against \nthem.  . . . [I]f a finder actively agrees to participate in a bug bounty program, then she \nsubmits to the vendor -determined publication deadline and the conditions stated within \nthe terms of such a program.”) . \n \n71 See Hall & Adams, supra  note 4, at 9. \n \n72 Mayer, supra  note 66, at 1467. \n \n73 Kilovaty, supra note 41, at 509  (“The CFAA’s strict liability for access ‘without \nauthorization’ is certainly a major threat to security researchers. At the same time, it \ndiscourages talented researchers from engaging responsibly with vendors .”). \n \n74 Kirsch, supra  note 45, at 394 ; see also  Trevor A. Thompson, Terrorizing the \nTechnological Neighborhood Watch: The Alienation and Deterrence of “White Hats” Under the CFAA , 36 F\nLA. ST. U.L.  REV. 537, 562– 63 (2009)  (“[T]his overbroad reach \neffectively isolates an ethical hacking community that would otherwise both reinforce positive  norms within the hacking community and provide the benefits of increased \ncooperation between ethical hackers and law enforcement.”).  \n \n75 See, e.g. , Amit Yoran, The Future of Cybersecurity Law Hinges On The Supreme \nCourt , FORBES (Nov. 16, 2020, 12:55 PM ), https://www.forbes.com/sites/amityoran1 \n/2020/11/16/the -future -of-cybersecurity -law-hinges -on-the-supreme -court/  \n?sh=6afa7fa5528a  [https://perma.cc/KU6Z -SCM5] (“The Court’s ruling will either be a \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 108 IV.  V AN BUREN V . UNITED STATES  \n \n[25]  In June 2021, the Supreme Court decided its first-ever CFAA case, \nVan Buren v. United States.76 The decision was hailed for reining in the \nscope of the CFAA’s “exceeds authorized access” provision.77 To bolster \nits conclusion, the Court also weighed in on the meaning of “loss” in the context of civil claims, construing the term narrowly to focus on \n“technological harms.”\n78  \n \n \nsignificant win for the security community, setting the legal parameters for legitimate \nsecurity research[,] or a detrimental roadblock, pushing security researchers into perilous \nsituations and society into the digital Dark Ages.”);  Joseph Marks & Tonya Riley, The \nCybersecurity 202:  There’s finally a Supreme C ourt battle coming over the nation’s main \nhacking law , WASH. POST (Apr. 24, 2020 , 7:30 AM ), https://www.washingtonpost.com/  \nnews/powerpost/paloma/the -cybersecurity -202/2020/04/24/the -cybersecurity -202-there -\ns-finally -a-supreme -court- battle- coming- over-the-nation-s- main -hacking-\nlaw/5ea1ade6602ff140c1cc5f51/  [https://perma.cc/A8KV -Z3RP] (“If the court agrees to \nnarrow how prosecu tors can use the law, it would be a huge victory for security \nresearchers. .  . . It would also make the Internet far safer, [cybersecurity professionals] \nsay. . .  That’s b ecause current interpretations of [the CFAA], have made researchers \nwary of revealing bugs they find because they fear getting in troubl e . . .”). \n \n76 141 S. Ct. 1648 (2021).  \n \n77 E.g., Orin S. Kerr, The Supreme Court Reins in the CFAA in  Van Buren, R EASON : \nVOLOKH CONSPIRACY (June 9, 2021 , 8:32 PM ), https://reason.com/volokh/2021/06/09/ \nthe-supreme -court- reins -in-the-cfaa- in-van-buren [https://perma.cc/Y47T -VDHU] (“ Van \nBuren  is a major victory for those of us who favor a narrow reading of the CFAA.”); \nDavid G. Savage, Unusual Supreme Court majority na rrows scope of computer anti -\nhacking law,  L.A.  TIMES (June 3, 2021 , 12:21 PM ), https://www.latimes.com/politics/ \nstory/2021 -06-03/unusual -supreme -court- majority -narrows -scope -of-anti-hacking-\ncomputer- law [https://perma.cc/MJD6 -CC3A]  (“The [American Civil Liberties Union]  \nwelcomed the decision as ‘ an important victory for civil liberties and civil rights \nenforcement i n the digital age. ’”). \n \n78 Van Buren , 141 S. Ct. at 1659 –60. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 109 [26]  Van Buren involved a police officer who had authorization to access \na police department database, but who searched it for a corrupt purpose in \nviolation of the department’s acceptable-use policy.79 This search prompted \nthe officer’s prosecution and conviction under the CFAA’s “exceeds authorized access” provision.\n80 The Court granted certiorari in order to \nresolve a circuit split that had persisted for the better part of a decade over whether the “exceeds authorized access” provision applied “only to those \nwho obtain information to which their computer access does not extend,” or whether it also reached “those who misuse access that they otherwise \nhave.”\n81  \n [27]  The Court adopted the narrower interpretation, holding that “an \nindividual ‘exceeds authorized access’ when he accesses a computer with authorization but then obtains information located in particular areas of the \ncomputer — such as files, folders, or databases — that are off limits to \nhim.”\n82 Using information one is authorized by the computer owner to \naccess, but for an impermissible purpose, is not “exceeding authorized access.”\n83 The contrary interpretation, the Court reasoned, “would attach \ncriminal penalties to a breathtaking amount of commonplace computer activity[,]” such as checking personal email or sports scores at work in \nviolation of an employer’s computer-use policy.\n84 If it “exceeds authorized \naccess” to misuse one’s otherwise permissible computer access, “then millions of otherwise law-abiding citizens are criminals.”\n85 The Court \n \n79 Id. at 1653. \n \n80 Id. \n \n81 Id. at 1653 –54.  \n \n82 Id. at 1662. \n \n83 Id. at 1661 –62. \n \n84 Van Buren , 141 S. Ct. at 1661 –62.  \n \n85 Id. at 1661. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 110 declined to read the statute so broadly, and accordingly overturned Mr. Van \nBuren’s conviction under section 1030(a)(2).86 \nA.  Impact on Good-Faith Security Research \n \n[28]  Van Buren reduced the threat the law poses to security researchers \nby stating that violations of policies or agreements are not CFAA violations too. Going forward, the Court’s ruling should shield researchers from \nliability for “exceeding authorized access” under the CFAA if they violate \na vendor’s terms of service or other contractual clauses (such as in a VDP \nor bug bounty program) that put constraints on how the researcher may \ngather information and what uses she may make of it.\n87  \n [29]  The decision has induced federal law enforcement to change its \nstance toward security research.\n 88 In May 2022, almost a year after the Van \nBuren decision, the Department of Justice revised its charging policy for the \nCFAA.89 In a move that surprised the cybersecurity community, the DOJ \nannounced that going forward, federal prosecutors “should decline \nprosecution if available evidence shows the defendant’s conduct consisted \n \n86 Id. at 1662. \n \n87 Aaron Mackey & Kurt Opsahl, Van Buren is a Victory Against Overbroad \nInterpretations of the CFAA, and Protects Security Researchers , ELEC. FRONTIER FOUND . \n(June 3, 2022), https://www.eff.org/deeplinks/2021/06/van- buren -victory- against -\noverbroad -interpretations- cfaa- protects -security  [https://perma.cc/N3GA -PBG3];  \nTimothy Edgar, Why Van Buren Is Good News for Cybersecurity , LAWFARE  (Aug. 4, \n2021, 10:18 AM ), https://www.lawfar eblog.com/why -van-buren -good- news -\ncybersecurity  [https://perma.cc/U22F -LNFM].  \n \n88 Department of Justice Announces New Policy for Charging Cases under the Computer \nFraud and Abuse Act , U.S.  DEP’T OF JUST. (May 19, 2022), https://www.justice.gov/  \nopa/pr/department -justice- announces -new-policy- charging -cases- under -computer- fraud -\nand-abuse -act [https://perma.cc/9ZVB -L5T7] [hereinafter DOJ Press Release ].  \n \n89 U.S. Dep’t  of Just., Just. Manual § 9 -48.000 (2022) [hereinafter DOJ Charging Policy ]. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 111 of, and the defendant intended, good-faith security research.”90 This is a \nsignificant move that may allay some of the historical fears surrounding the \nCFAA.  \n \n[30]  The new policy adopts the definition of “good-faith security \nresearch” adopted by the Copyright Office in the 2021 triennial rulemaking under the Digital Millennium Copyright Act (DMCA).\n91 To wit: \n \n“good faith security research” means accessing a computer \nsolely for purposes of good-faith testing, investigation, \nand/or correction of a security flaw or vulnerability, where \nsuch activity is carried out in a manner designed to avoid any \nharm to individuals or the public, and where the information \nderived from the activity is used primarily to promote the \nsecurity or safety of the class of devices, machines, or online \nservices to which the accessed computer belongs, or those \nwho use such devices, machines, or online services.92 \n [31]  The DOJ policy continues: “Security research not conducted in good \nfaith—for example, for the purpose of discovering security holes in devices, machines, or services in order to extort the owners of such devices, \nmachines, or services—might be called ‘research,’ but is not in good \nfaith.”\n93  \n \n \n90 Id. \n \n91 See 37 CFR § 201.40(b)(16).  \n \n92 Id. (quoting  U.S.  COPYRIGHT  OFF., SECTION 1201  RULEMAKING : EIGHT H TRIENNIAL \nPROCEEDING TO DETERMINE EXEMPTIONS TO THE PROHIBITION ON CIRCUMVENTION  258 \n(2021)) . \n \n93 DOJ Charging Policy , supra note 89. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 112 [32]  The May 2022 policy replaces the Department’s previous CFAA \ncharging policy from 2014,94 which listed factors for federal prosecutors to \nconsider (such as the need for deterrence and the sensitivity of the system \nor information affected) when deciding whether a CFAA prosecution \n“should be pursued because a substantial federal interest would be served \nby prosecution.”95 It is possible to interpret the new policy as recognition \nthat the “federal interest” is better served by encouraging rather than \npunishing researchers’ efforts to improve the nation’s cybersecurity.96 This \nview is bolstered by Deputy Attorney General Lisa Monaco’s statement in a press release about the new policy: “[c]omputer security research is a key \ndriver of improved cybersecurity . . . and today’s announcement promotes \ncybersecurity by providing clarity for good-faith security researchers who root out vulnerabilities for the common good.”\n97 \n [33]  To hear some DOJ officials tell it, the new policy is practically \nsuperfluous. According to DAG Monaco’s statement, “[t]he department has never been interested in prosecuting good-faith computer security research \n \n94 DOJ Press Release , supra  note 88 (indicating  that the 2022 policy supersedes prior \n2014 policy with immediate effect).  \n \n95 Memorandum from Eric H. Holder, Jr., Att’y Gen. , to the U .S. Att’ys & Assistant \nAtt’y Gens . for the Crim . & Nat’l Sec . Divs. (Sept. 11, 2014), https://www.eff.org/files/  \n2017/03/14/15 -1_ex_to_mtd_reply_- _charging_memo.pdf  [https://perma.cc/TZM4 -\nRQ3M].  \n \n96 See Riana Pfefferkorn, America’s anti -hacking laws pose a risk to national security, \nBROOKINGS : TECHSTREAM  (Sept. 7, 2021), https://www.brookings.edu/techstream/  \namericas -anti-hacking- laws-pose-a- risk-to-national -security/ [https://perma.cc/2U4H -\nH2SA] (commenting on the status of public and private cybersecurity while highlighting \nlegal risk as a barrier to good -faith cybersecurity research); Kimberly Adams & Daniel \nShin, “Good faith” hackers get a break from the government , MARKETPLACE TECH (May \n25, 2022), https://www.marketplace.org/shows/marketplace -tech/good- faith-hackers -get-\na-break -from -the-government/ [https://perma.cc/PTB9 -SMFT]  (acknowledging an \nadministrative shift due to the timing of the new DOJ policy).  \n97 DOJ Press Release , supra note  88. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 113 as a crime[.]”98 Further, according to Leonard Bailey, who heads the \nCybersecurity Unit of the DOJ’s Computer Crime and Intellectual Property \nSection (CCIPS), there has been only one CFAA prosecution in the past \ndecade against a security researcher.99  \n \n[34]  However, the Department’s claims do not paint the full picture. \nGiven the chance, the DOJ had previously refused to disavow that it might someday prosecute researchers for CFAA violations.\n100 The existence of \nonly one recent prosecution does not imply that that defendant was the only researcher investigated by the federal government in the last ten years. \n(Prosecutions in open court are just the tip of the law enforcement iceberg, and the number of investigations that did not culminate in prosecution \ncannot be easily quantified. Plus, federal investigators do not tend to \npublicize the details of open investigations.\n101) The new charging policy is \ntherefore significant, despite Department officials’ downplaying its importance and despite the existing dearth of prosecutions.  \n \n \n98 Id. \n \n99 Derek B. Johnson, The (still) unanswered questions around the CFAA and ‘good faith’ \nsecurity research , SC  MEDIA  (June 6, 2022), https://www.scmagazine.com/analysis  \n/rsac/the -still-unanswered -questions -around -the-cfaa- and-good- faith-security -research  \n[https://perma.cc/Y6R3 -NDLK].  Bailey did not specify the defendant in that case ; \nwithout that information,  it is not possible to evaluate whether that prosecution would \nnow be disfavored under the new policy.  \n \n100 Van Buren v. United  States, 141 S. Ct. 1648, 1661 (2021) (“ the Government stops far \nshort of endorsing ” limitations that might “ cabin its prosecutorial power” ) (citing \nSandvig  v. Barr , 451 F. Supp . 3d 73, 81– 82 (D.D.C. 2020) ); Sandvig, 451 F. Supp . 3d at \n81 (“[A]dvisory and non -binding statements and Department of Justice policies do not \neliminate the reasonable fear of prosecution.”) . \n \n101 See Can I obtain detailed information about a current FBI investigation that I see in \nthe news?, FBI , https://www.fbi.gov/about/faqs/can-i- obtain- detailed- information -about-\na-current -fbi-investigation- that-i- see-in-the-news [https://perma.cc/P9CF- 46JB].  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 114 [35]  The DOJ’s policy is undeniably an important step forward in \nrestoring trust between the security community and the authorities charged \nwith protecting the public. Nevertheless, it cannot fully assuage researchers’ \nfears. For one thing, this is a non-binding policy, not a law.102 Even if \ncharging good-faith researchers is disfavored, a prosecutor would still have \nthe discretion to do so.103 Additionally, the policy does not forbid \ninvestigating researchers over their work. Nor could it: after all, a determination that particular research counts as good faith (and so the \nresearcher should be let off the hook) will surely require some amount of \ngovernment scrutiny.\n104 Researchers may reasonably wonder how intrusive \nthat process might be.105 Finally, the DOJ policy has no effect on \nprosecutions under state-level anti-hacking laws. State laws  remain a source \nof potential criminal liability for security research. Indeed, a Missouri journalist was recently threatened with prosecution by the state governor for \nresponsibly disclosing serious flaws he had found in a state agency \nwebsite.\n106 \n \n102 Sandvig, 451 F. Supp. 3d at 81 (emphasizing the 2014 version of the policy).  \n \n103 See Van Buren , 141 S. Ct. 1648 at 1661 –62 (emphasizing the discretionary nature of  \nthe plain language in the 2014 version of the policy).  \n \n104 The good -faith determination is to be made on “available evidence,” and prosecutors \ncan consult CCIPS about how it applies in specific situations. DOJ Charging Policy , \nsupra note 89.  \n \n105 For a firsthand account of the stressful experience of a federal criminal CFAA \ninvestigation (one infamous for culminating in the defendant’s suicide) , see Quinn \nNorton, “Life Inside the Aaron Swartz Investigation,” THE ATLANTIC  (Mar. 3, 2013), \nhttps://www.theatlantic.com/technology/archive/2013/03/life -inside- the-aaron -swartz -\ninvestigation/273654/  [https://perma.cc/UV62- HMDP ].  \n \n106 See Rachel  Treisman, A Missouri newspaper told the state about a security risk. Now \nit faces prosecution , NPR (Oct. 14, 202 1, 4:37 PM),  \nhttps://www.npr.org/2021/10/14/1046124278/missouri -newspaper -security -flaws-\nhacking- investigation- gov-mike -parson  [https://perma.cc/3TF6 -46FL]; Jason Hancock, \nProsecutor: No ‘criminal intent’ by reporter Missouri governor accused of hacking , MO. \nINDEP . (Feb. 21, 2022 , 1:14 PM ), https://missouriindependent.com/2022/02/21/  \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 115 [36]  The new policy’s biggest limitation, however, is that it has no effect \non civil CFAA claims.107 The policy is for federal prosecutors, therefore it \ndoes not bind the hands of private plaintiffs.108 This distinction matters a lot \nto researchers trying to assess their legal risk, because it is civil litigation \nthat accounts for the majority of CFAA cases (against all defendants, not \njust researchers), according to a 2016 study by Jonathan Mayer.109 The \nstudy found that both civil and criminal CFAA cases are more frequent now than earlier in the statute’s lifetime.\n110 Following an initial “stead[y] \nincreas[e],” “cybercrime charging leveled off” after the mid-2000s, whereas “[c]ivil cybercrime litigation has unambiguously exploded.”\n111 “The \nincrease in criminal prosecutions and convictions, while significant, is not nearly as abrupt or substantial as the apparent increase in civil litigation.”\n112 \nThat is, if a researcher is accused of violating the CFAA, there were already good odds even before the DOJ’s policy shift that the accusation arose in a \ncivil complaint rather than a criminal indictment. Going forward (and \nassuming the new DOJ policy has legs), researchers’ CFAA liability risk \nfor responsibly finding and disclosing security vulnerabilities can be \nexpected to arise almost exclusively in the civil litigation context.  \n \nprosecutor -no-criminal -intent- by-reporter -missouri -governor -accused -of-hacking/  \n[https://perma.cc/AKC6- ZSGC]. \n \n107 Andrew Crocker, DOJ’s New CFAA Policy is a Good Start but Does Not Go Far \nEnough to Protect Security Researchers , ELEC. FRONTIER FOUND .: DEEPLINKS (May 19, \n2022), https://www.eff.org/deeplinks/2022/05/dojs -new-cfaa- policy- good- start- does-not-\ngo-far-enough -protect -security  [https://perma.cc/7Y9Y -6GZQ ] (“[The new policy] does \nnothing to lessen the risk of frivolous or overbroad CFAA civil litigation against security \nresearchers, journalists, and innovators.”).  \n \n108 DOJ Press Release , supra  note 88.  \n \n109 Mayer, supra  note 66, at 1472 –77. \n \n110 Id. \n \n111 Id. at 1472, 1475.  \n \n112 Id. at 1476. \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 116 [37]  This lingering civil risk exposure matters because the Van Buren \nruling has not been universally welcomed among private-sector vendors. \nVoatz, a mobile voting app company, gained notoriety in 2019 for referring \na college student to law enforcement for research that complied with its bug \nbounty terms at the time.113 The company responded to Van Buren with a \nwebinar in which its outside counsel warned security researchers that certain research methods could still violate the CFAA after Van Buren \n“even if [their] purpose is noble.”\n114 Voatz’s counsel also told researchers \nthe “safest bet” was to “work with [vendors] to identify any security \nvulnerabilities.”115 This stance accorded with the amicus curiae brief the \nsame attorney filed for Voatz in Van Buren, which urged the view that \nexternal research must follow terms dictated by the vendor, either through \na bug bounty program or “direct collaboration” with the vendor.116 \nAlthough Voatz’s preferred broad interpretation of the CFAA’s “exceeds \n \n113 Yael Grauer, Safe Harbor, or Thrown to the Sharks by Voatz? , COINTELEGRAPH MAG. \n(Feb. 7, 2020), https://cointelegraph.com/magazine/2020/02/07/safe -harbor -or-thrown -to-\nthe-sharks- by-voatz [https://perma.cc/TS6G -RNZA] ; Kevin Collier, FBI investigating if \nattempted 2018 voting app hack was linked to Michigan college course , CNN (Oct. 5, \n2019, 4:23 PM),  https://www.cnn.com/2019/10/04/politics/fbi -voting -app-hack-\ninvestigation [https://perma.cc/VC22 -F3YU]. To date, charges have not publicly been \nfiled against the student or students in question . \n \n114 Voatz, Voatz: Van Buren vs. United States Explained, June 29 th, 2021 , YOUTUBE, at \n40:20– 42:04  (July 2, 2021), https://www.youtube.com/watch?v=0uU6CO7WUrw  \n[https://perma.cc/BPN8 -SQ8L].  \n \n115 Id. \n \n116 See Brief for Voatz, Inc. as Amici Curiae Supporting Respondents, Van Buren v. \nUnited States, 141 S.  Ct. 1648 (2021) (No. 19 -783). The brief caused a furor in the \nsecurity community, prompting an open letter signed by numerous security experts \npushing back against Voatz’s vi ew of the CFAA and perceived factual inaccuracies in the \nbrief.  Response to Voatz’s Supreme Court Amicus Brief , disclose.io (Sept. 14, 2020), \nhttps://disclose.io/uploads/voatz -response -letter.pdf [https://perma.cc/2LHF -TF3Y].  \n \n\nRichmond Journal of Law & Technology                                        Volume XXIX, Issue 1  \n \n 117 authorized access” provision117 was not adopted by the Court,118 Voatz’s \nattitude toward the Court’s ruling indicates that vendors will still look for \nways to impose legal liability on security research. \n \n[38]  In fact, the Van Buren opinion gives those vendors a possible avenue \nfor doing so. A footnote in the opinion left open the question of whether authorized access may be controlled only through technical (“code-based”) \naccess barriers, or also by terms in a contract or policy.\n119 This footnote is \nat odds with the rest of the opinion, leaving commentators struggling to make sense of it.\n120 At a minimum, the footnote indicates that vendors could \nstill sue over good-faith research that circumvents a technological access barrier, even though the DOJ has chosen generally to disfavor criminal \ncharges in the same situation.\n121 Meanwhile, the Court’s footnote dangled \nthe possibility that research that does not circumvent any such barriers \nmight nevertheless still violate the CFAA if it contravenes a contractual or \npolicy provision. Vendors may seize upon the ambiguity the footnote \n \n117 Brief for Voatz, Inc. as Amici Curiae Supporting Respondents  at 3, Van Buren , 141  S. \nCt. 1648 ( No. 19- 783).  \n \n118 See Van Buren , 141 S. Ct . at 1661. \n \n119 Id. at 1658– 59 n.8; see Mackey & Opsahl, supra  note 87 (“[A]lthough the high court \ndid not narrow the CFAA as much as EFF would have liked, leaving open the question of \nwhether the law requires circumvention of a technological access barrier, it provided \ngood language that should help protect researchers [.]”).  \n \n120 Kerr,  The Supreme Court Reins in the CFAA in  Van Buren, supra  note 77 (“My first \nreaction to this footnote was puzzlement . How can the Court reject the government’s \nview that the policy controls and yet also leave open whether liability looks to policies? \nHow do you reconcile Footnote 8 with the rest of the opinion. . .?”) ; Mackey & Opsahl, \nsupra  note 87 (“This footnote is a bit odd, as the bulk of the majority opinion seems to \npoint toward the law requiring someone to defeat technological limitations on access, and \nthrow [s] shade at criminalizing TOS violations.”) .  \n \n121 See DOJ Charging Policy , supra note 89.", "files_in_pdf": [{"path": ".pdf_temp/chunk_2_1756428212/images/g1cj8p.jpg", "size": 18996}, {"path": ".pdf_temp/chunk_2_1756428212/images/blbz5n.jpg", "size": 14154}, {"path": ".pdf_temp/chunk_2_1756428212/images/27psqz.jpg", "size": 115733}, {"path": ".pdf_temp/chunk_2_1756428212/images/n7xbvz.jpg", "size": 95310}, {"path": ".pdf_temp/chunk_2_1756428212/images/tc0z7q.jpg", "size": 14326}, {"path": ".pdf_temp/chunk_2_1756428212/images/0i9bl1.jpg", "size": 243672}, {"path": ".pdf_temp/chunk_2_1756428212/images/rabr6r.jpg", "size": 21717}, {"path": ".pdf_temp/chunk_2_1756428212/images/4hoae5.jpg", "size": 18255}, {"path": ".pdf_temp/chunk_2_1756428212/images/pvrwbr.jpg", "size": 193182}, {"path": ".pdf_temp/chunk_2_1756428212/images/mozknh.jpg", "size": 92547}, {"path": ".pdf_temp/chunk_2_1756428212/images/tdywm8.jpg", "size": 36849}]}