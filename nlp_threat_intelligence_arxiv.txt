{"origin_pdf_path": "https://arxiv.org/pdf/2311.08807.pdf", "text_in_pdf": "[208] F Böhm, F Menges, and G Pernul. Graph-based visual analytics for cyber threat intelligence. cybersecurity 1 (1): 1–19, 2018.   \n[209] Sudip Mittal, Anupam Joshi, and Tim Finin. Cyber-all-intel: An ai for security related threat intelligence. arXiv preprint arXiv:1905.02895, 2019.   \n[210] Md Tanvirul Alam, Dipkamal Bhusal, Youngja Park, and Nidhi Rastogi. Looking beyond iocs: Automatically extracting attack patterns from external cti. arXiv preprint arXiv:2211.01753, 2022.   \n[211] Aditya Pingle, Aritran Piplai, Sudip Mittal, Anupam Joshi, James Holt, and Richard Zak. Relext: Relation extraction using deep learning approaches for cybersecurity knowledge graph improvement. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, pages 879–886, 2019.   \n[212] Yali Gao, Xiaoyong Li, Hao Peng, Binxing Fang, and S Yu Philip. Hincti: A cyber threat intelligence modeling and identification system based on heterogeneous information network. IEEE Transactions on Knowledge and Data Engineering, 34(2):708–722, 2020.   \n[213] Z Li, J Zeng, Y Chen, and Z Liang. Attackg: Constructing technique knowledge graph from cyber threat intelligence reports.” arxiv, may 28, 2022. accessed: Aug. 02, 2022.   \n[214] Zong-Xun Li, Yu-Jun Li, Yi-Wei Liu, Cheng Liu, and Nan-Xin Zhou. K-ctiaa: Automatic analysis of cyber threat intelligence based on a knowledge graph. Symmetry, 15(2):337, 2023.   \n[215] Florian Klaus Kaiser, Uriel Dardik, Aviad Elitzur, Polina Zilberman, Nir Daniel, Marcus Wiens, Frank Schultmann, Yuval Elovici, and Rami Puzis. Attack hypotheses generation based on threat intelligence knowledge graph. IEEE Transactions on Dependable and Secure Computing, 2023.   \n[216] Hyeonseong Jo, Yongjae Lee, and Seungwon Shin. Vulcan: Automatic extraction and analysis of cyber threat intelligence from unstructured text. Computers & Security, 120:102763, 2022.   \n[217] Yongyan Guo, Zhengyu Liu, Cheng Huang, Nannan Wang, Hai Min, Wenbo Guo, and Jiayong Liu. A framework for threat intelligence extraction and fusion. Computers & Security, 132:103371, 2023.   \n[218] Yuta Kazato, Yoshihide Nakagawa, and Yuichi Nakatani. Improving maliciousness estimation of indicator of compromise using graph convolutional networks. In 2020 IEEE 17th Annual Consumer Communications & Networking Conference (CCNC), pages 1–7. IEEE, 2020.   \n[219] Siwar Kriaa and Yahia Chaabane. Seckg: Leveraging attack detection and prediction using knowledge graphs. In 2021 12th International Conference on Information and Communication Systems (ICICS), pages 112–119. IEEE, 2021.   \n[220] Jun Zhao, Minglai Shao, Hong Wang, Xiaomei Yu, Bo Li, and Xudong Liu. Cyber threat prediction using dynamic heterogeneous graph learning. Knowledge-Based Systems, 240:108086, 2022.   \n[221] Elmar Kiesling, Andreas Ekelhart, Kabul Kurniawan, and Fajar Ekaputra. The sepses knowledge graph: An integrated resource for cybersecurity. In International Semantic Web Conference, pages 198–214. Springer, 2019.   \n[222] Jun Zhao, Xudong Liu, Qiben Yan, Bo Li, Minglai Shao, Hao Peng, and Lichao Sun. Automatically predicting cyber attack preference with attributed heterogeneous attention networks and transductive learning. computers & security, 102:102152, 2021.   \n[223] Yongfei Li, Yuanbo Guo, Chen Fang, Yingze Liu, Qingli Chen, et al. A novel threat intelligence information extraction system combining multiple models. Security and Communication Networks, 2022, 2022.   \n[224] Soham Dasgupta, Aritran Piplai, Priyanka Ranade, and Anupam Joshi. Cybersecurity knowledge graph improvement with graph neural networks. In 2021 IEEE International Conference on Big Data (Big Data), pages 3290–3297. IEEE, 2021.   \n[225] Shaswata Mitra, Aritran Piplai, Sudip Mittal, and Anupam Joshi. Combating fake cyber threat intelligence using provenance in cybersecurity knowledge graphs. In 2021 IEEE International Conference on Big Data (Big Data), pages 3316–3323. IEEE, 2021.   \n[226] Gautam Srivastava, Rutvij H Jhaveri, Sweta Bhattacharya, Sharnil Pandya, Praveen Kumar Reddy Maddikunta, Gokul Yenduri, Jon G Hall, Mamoun Alazab, Thippa Reddy Gadekallu, et al. Xai for cybersecurity: state of the art, challenges, open issues and future directions. arXiv preprint arXiv:2206.03585, 2022.   \n[227] Zhibo Zhang, Hussam Al Hamadi, Ernesto Damiani, Chan Yeob Yeun, and Fatma Taher. Explainable artificial intelligence applications in cyber security: State-of-the-art in research. IEEE Access, 2022.   \n[228] Harsha Moraliyage, Vidura Sumanasena, Daswin De Silva, Rashmika Nawaratne, Lina Sun, and Damminda Alahakoon. Multimodal classification of onion services for proactive cyber threat intelligence using explainable deep learning. IEEE Access, 10:56044–56056, 2022.   \n[229] Huiling Li, Jun Wu, Hansong Xu, Gaolei Li, and Mohsen Guizani. Explainable intelligence-driven defense mechanism against advanced persistent threats: A joint edge game and ai approach. IEEE Transactions on Dependable and Secure Computing, 19(2):757–775, 2021.   \n[230] Qinqin Wang, Hanbing Yan, and Zhihui Han. Explainable apt attribution for malware using nlp techniques. In 2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS), pages 70–80. IEEE, 2021.   \n[231] Wenhan Ge, Junfeng Wang, Tongcan Lin, Binhui Tang, and Xiaohui Li. Explainable cyber threat behavior identification based on self-adversarial topic generation. Computers & Security, 132:103369, 2023.   \n[232] Cynthia Wagner, Alexandre Dulaunoy, Gérard Wagener, and Andras Iklody. Misp: The design and implementation of a collaborative threat intelligence sharing platform. In Proceedings of the 2016 ACM on Workshop on Information Sharing and Collaborative Security, pages 49–56, 2016.   \n[233] Borce Stojkovski, Gabriele Lenzini, Vincent Koenig, and Salvador Rivas. What’s in a cyber threat intelligence sharing platform? a mixed-methods user experience investigation of misp. In Annual Computer Security Applications Conference, pages 385–398, 2021.   \n[234] Eric Jollès, Sébastien Gillard, Dimitri Percia David, Martin Strohmeier, and Alain Mermoud. Building collaborative cybersecurity for critical infrastructure protection: Empirical evidence of collective intelligence information sharing dynamics on threatfox. In International Conference on Critical Information Infrastructures Security, pages 140–157. Springer, 2022.   \n[235] Alessandra de Melo e Silva, João José Costa Gondim, Robson de Oliveira Albuquerque, and Luis Javier García Villalba. A methodology to evaluate standards and platforms within cyber threat intelligence. Future Internet, 12(6):108, 2020.   \n[236] Thomas D Wagner, Esther Palomar, Khaled Mahbub, and Ali E Abdallah. Towards an anonymity supported platform for shared cyber threat intelligence. In Risks and Security of Internet and Systems: 12th International Conference, CRiSIS 2017, Dinard, France, September 19-21, 2017, Revised Selected Papers 12, pages 175–183. Springer, 2018.   \n[237] Md Farhan Haque and Ram Krishnan. Toward automated cyber defense with secure sharing of structured cyber threat intelligence. Information Systems Frontiers, pages 1–14, 2021.   \n[238] Gustavo González-Granadillo, Mario Faiella, Ibéria Medeiros, Rui Azevedo, and Susana González-Zarzosa. Etip: An enriched threat intelligence platform for improving osint correlation, analysis, visualization and sharing capabilities. Journal of Information Security and Applications, 58:102715, 2021.   \n[239] Florian Menges, Benedikt Putz, and Günther Pernul. Dealer: decentralized incentives for threat intelligence reporting and exchange. International Journal of Information Security, 20(5):741–761, 2021.   \n[240] Davy Preuveneers, Wouter Joosen, Jorge Bernal Bernabe, and Antonio Skarmeta. Distributed security framework for reliable threat intelligence sharing. Security and Communication Networks, 2020, 2020.   \n[241] Davy Preuveneers and Wouter Joosen. Tatis: trustworthy apis for threat intelligence sharing with uma and cp-abe. In Foundations and Practice of Security: 12th International Symposium, FPS 2019, Toulouse, France, November 5–7, 2019, Revised Selected Papers 12, pages 172–188. Springer, 2020.   \n[242] Sean Barnum. Standardizing cyber threat intelligence information with the structured threat information expression (stix). Mitre Corporation, 11:1–22, 2012.   \n[243] Raúl Riesco and Víctor A Villagrá. Leveraging cyber threat intelligence for a dynamic risk framework: Automation by using a semantic reasoner and a new combination of standards (stix™, swrl and owl). International Journal of Information Security, 18(6):715–739, 2019.   \n[244] Florian Menges and Günther Pernul. A comparative analysis of incident reporting formats. Computers & Security, 73:87–101, 2018.   \n[245] Andrew Ramsdale, Stavros Shiaeles, and Nicholas Kolokotronis. A comparative analysis of cyber-threat intelligence sources, formats and languages. Electronics, 9(5):824, 2020.   \n[246] Vitor Jesus, Balraj Bains, and Victor Chang. Sharing is caring: Hurdles and prospects of open, crowd-sourced cyber threat intelligence. IEEE Transactions on Engineering Management, 2023.   \n[247] Christian Sillaber, Clemens Sauerwein, Andrea Mussmann, and Ruth Breu. Data quality challenges and future research directions in threat intelligence sharing practice. In Proceedings of the 2016 ACM on Workshop on Information Sharing and Collaborative Security, pages 65–70, 2016.   \n[248] Daniel Schlette, Fabian Böhm, Marco Caselli, and Günther Pernul. Measuring and visualizing cyber threat intelligence quality. International Journal of Information Security, 20:21–38, 2021.   \n[249] Adam Zibak, Clemens Sauerwein, and Andrew C Simpson. Threat intelligence quality dimensions for research and practice. Digital Threats: Research and Practice, 3(4):1–22, 2022.   \n[250] Li Qiang, Jiang Zhengwei, Yang Zeming, Liu Baoxu, Wang Xin, and Zhang Yunan. A quality evaluation method of cyber threat intelligence in user perspective. In 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE), pages 269–276. IEEE, 2018.   \n[251] Thomas Schaberreiter, Veronika Kupfersberger, Konstantinos Rantos, Arnolnt Spyros, Alexandros Papanikolaou, Christos Ilioudis, and Gerald Quirchmayr. A quantitative evaluation of trust in the quality of cyber threat intelligence sources. In Proceedings of the 14th international conference on availability, reliability and security, pages 1–10, 2019.   \n[252] Harm Griffioen, Tim Booij, and Christian Doerr. Quality evaluation of cyber threat intelligence feeds. In Applied Cryptography and Network Security: 18th International Conference, ACNS 2020, Rome, Italy, October 19–22, 2020, Proceedings, Part II 18, pages 277–296. Springer, 2020.   \n[253] Thomas D Wagner, Esther Palomar, Khaled Mahbub, and Ali E Abdallah. A novel trust taxonomy for shared cyber threat intelligence. Security and Communication Networks, 2018, 2018.   \n[254] David W Chadwick, Wenjun Fan, Gianpiero Costantino, Rogério De Lemos, Francesco Di Cerbo, Ian Herwono, Mirko Manea, Paolo Mori, Ali Sajjad, and Xiao-Si Wang. A cloud-edge based data security architecture for sharing and analysing cyber threat information. Future generation computer systems, 102:710–722, 2020.   \n[255] Tongtong Jiang, Guowei Shen, Chun Guo, Yunhe Cui, and Bo Xie. Bfls: Blockchain and federated learning for sharing threat detection models as cyber threat intelligence. Computer Networks, 224:109604, 2023.   \n[256] Daire Homan, Ian Shiel, and Christina Thorpe. A new network model for cyber threat intelligence sharing using blockchain technology. In 2019 10th IFIP International Conference on New Technologies, Mobility and Security (NTMS), pages 1–6. IEEE, 2019.   \n[257] Soumya Purohit, Roshan Neupane, Naga Ramya Bhamidipati, Varsha Vakkavanthula, Songjie Wang, Matthew Rockey, and Prasad Calyam. Cyber threat intelligence sharing for co-operative defense in multi-domain entities. IEEE Transactions on Dependable and Secure Computing, 2022.   \n[258] Raúl Riesco, Xavier Larriva-Novo, and Víctor A Villagrá. Cybersecurity threat intelligence knowledge exchange based on blockchain: Proposal of a new incentive model based on blockchain and smart contracts to foster the cyber threat and risk intelligence exchange of information. Telecommunication Systems, 73(2):259–288, 2020.   \n[259] Philip Huff and Qinghua Li. A distributed ledger for non-attributable cyber threat intelligence exchange. In Security and Privacy in Communication Networks: 17th EAI International Conference, SecureComm 2021, Virtual Event, September 6–9, 2021, Proceedings, Part I 17, pages 164–184. Springer, 2021.   \n[260] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE signal processing magazine, 37(3):50–60, 2020.   \n[261] Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang. Crafting adversarial input sequences for recurrent neural networks. In MILCOM 2016-2016 IEEE Military Communications Conference, pages 49–54. IEEE, 2016.   \n[262] Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan, and Girish Chowdhary. Robust deep reinforcement learning with adversarial attacks. arXiv preprint arXiv:1712.03632, 2017.   \n[263] Shilin Qiu, Qihe Liu, Shijie Zhou, and Wen Huang. Adversarial attack and defense technologies in natural language processing: A survey. Neurocomputing, 492:278–307, 2022.   \n[264] Basemah Alshemali and Jugal Kalita. Improving the reliability of deep neural networks in nlp: A review. Knowledge-Based Systems, 191:105210, 2020.   \n[265] Wei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. Adversarial attacks on deep-learning models in natural language processing: A survey. ACM Transactions on Intelligent Systems and Technology (TIST), 11(3):1–41, 2020.   \n[266] MITRE. Virus total data poisoning case studies. https://github.com/mitre/advmlthreatmatrix/blob/ master/pages/case-studies-page.md#virustotal-poisoning, 2021.   \n[267] Nitika Khurana, Sudip Mittal, Aritran Piplai, and Anupam Joshi. Preventing poisoning attacks on ai based threat intelligence systems. In 2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP), pages 1–6. IEEE, 2019.\n\nNLP-Based Techniques for Cyber Threat Intelligence  \n\nMarco Arazzi 1, Dincy R. Arikkat2, Serena Nicolazzo3, Antonino Nocera1, Rafidha Rehiman K. A.2, Vinod P. 2,4,\\, Mauro Conti4  \n\n1 Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Italy 2 Department of Computer Applications, Cochin University of Science and Technology, India 3 Department of Computer Science, University of Milan, Italy 4 Department of Mathematics, University of Padua, Italy  \n\n\\ Corresponding author: vinod.p@cusat.ac.in, vinod.puthuvath@unipd.it  \n\nAbstract  \n\nIn the digital era, threat actors employ sophisticated techniques for which, often, digital traces in the form of textual data are available. Cyber Threat Intelligence (CTI) is related to all the solutions inherent to data collection, processing, and analysis useful to understand a threat actor’s targets and attack behavior. Currently, CTI is assuming an always more crucial role in identifying and mitigating threats and enabling proactive defense strategies. In this context, NLP, an artificial intelligence branch, has emerged as a powerful tool for enhancing threat intelligence capabilities. This survey paper provides a comprehensive overview of NLP-based techniques applied in the context of threat intelligence. It begins by describing the foundational definitions and principles of CTI as a major tool for safeguarding digital assets. It then undertakes a thorough examination of NLP-based techniques for CTI data crawling from Web sources, CTI data analysis, Relation Extraction from cybersecurity data, CTI sharing and collaboration, and security threats of CTI. Finally, the challenges and limitations of NLP in threat intelligence are exhaustively examined, including data quality issues and ethical considerations. This survey draws a complete framework and serves as a valuable resource for security professionals and researchers seeking to understand the state-of-the-art NLP-based threat intelligence techniques and their potential impact on cybersecurity.  \n\nKeywords Cyber Threat Intelligence $\\cdot$ Natural Language Processing $\\cdot$ Data Crawling $\\cdot$ Named Entity Recognition Knowledge Graph  \n\n1 Introduction  \n\nNowadays, Cyber Threat Intelligence (CTI, hereafter) has gained a paramount role in cybersecurity, providing organizations with valuable insights into the Tactics, Techniques, and Procedures (TTPs) employed by cyber adversaries. Indeed, since there has been a significant increase in the variety and number of cyber attacks and malware samples, security practitioners have started to rely on CTI to promptly recognize the indicators of a cyber attack, collect information about the attack methods, and respond to it accurately and timely. Hence, in broad terms, the CTI pipeline takes as input cybersecurity data and produces valuable insights aimed at enhancing proactive cybersecurity defenses. This includes formulating strategies to minimize the impact of cyber attacks and prevent them in the future.  \n\nDue to the intricate and multifaceted nature of the cyber security context, different organizations and experts may emphasize different aspects of CTI based on their specific needs, objectives, and contexts. For this reason, several definitions of CTI exist. For instance, one of the most popular definitions states that CTI is “evidence-based knowledge, including context, mechanisms, indicators, implications, and actionable advice about an existing or emerging menace or hazard to assets that can be used to inform decisions regarding the subject’s response to that menace or hazard” [1]. The authors of [2] state that CTI refers to “the set of data collected, assessed, and applied regarding security threats, threat actors, exploits, malware, vulnerabilities, and compromise indicators”. Finally, Dalziel [3] describes CTI as “data that has been refined, analyzed, or processed such that it is relevant, actionable, and valuable”.  \n\nDespite the numerous CTI definitions and the various strategies for effectively utilizing them, a common baseline revolves around identifying suitable solutions to collect, manage, and analyze CTI data. In this context, recent research findings have proved that Artificial Intelligence (AI), and especially Natural Language Processing (NLP) techniques, play a crucial for several reasons. Firstly, because much of the information is represented by unstructured text data, such as threat reports, social media posts, news articles, and hacker forums, NLP allows CTI analysts to automatically handle these textual data and to enable the uncovering of relevant threats and trends. The analysis process of such information can be significantly sped up by automatically extracting key details from large volumes of text, such as Indicators of Compromises (IoCs) and TTP. Moreover, NLP can unravel the relationships between entities and events mentioned in text data, helping contextualize the information and building a more complete view of cyber threats and the actors behind them. Additionally, we can gain information about threat actors by analyzing online communications, forums, and other text sources through NLP techniques. Furthermore, because the CTI landscape is variegated, NLP can help to integrate information from various sources and formats into a coherent view, also assisting cybersecurity practitioners in the reports generation and sharing. Finally, NLP has also been exploited as a powerful tool to identify emerging threats and trends by analyzing large datasets of text-based information, thus proactively averting potential cyber attacks.  \n\nTaking all the above reasons into account, we can affirm that NLP plays a crucial role in enhancing the effectiveness and efficiency of CTI by helping analysts cope with vast amounts of textual data, extracting actionable intelligence, and predicting the evolution of cyber threats. Nevertheless, a comprehensive survey on NLP-based techniques for CTI is still missing in the current scientific literature. Consequently, with this paper, we aim to flil this gap by providing a clear and updated picture of the CTI landscape, its multiple sources, and its gathering and sharing methods under a main perspective, focusing on NLP techniques and how they can enhance CTI ability to detect, analyze, and respond to cyber threats, effectively.  \n\nWe list our contributions as follows:  \n\n• We discuss the notion of Cyber Threat Intelligence and its life cycle.   \n• We undertake a comprehensive examination of crawling techniques to extract data from main CTI Web sources, namely social networks, clear, and Dark Web.   \n• We analyze NLP models, techniques, and applications within the CTI domain. In particular, we give a detailed picture of the main papers dealing with text classification, similarity, clustering, summarization, cross-lingual, and topic detection in the context of CTI.   \n• We describe the most recent results of NLP-based techniques for relation extraction and representation.   \n• We address the topics of CTI standardization protocols and results sharing.   \n• We exhaustively examine the challenges and limitations of NLP in threat intelligence, including data quality issues, CTI security, and ethical considerations.  \n\nThe outline of this paper is as follows. In Section 2, we present the related survey studies. Section 3 discusses the methodology we adapted to conduct this survey. Section 4 explains the CTI life cycle and different types of CTI. In Section 5, we make an overview of NLP techniques and their role in CTI. Section 6 deals with the different Web crawling techniques to collect CTI data from clear, Dark/Deep Web, and social networks. Section 7 details classical NLP-based techniques applied to CTI data, whereas NLP-based techniques for Relation Extraction are described in Section 8. Section 9 deals with papers about CTI sharing and collaboration. Section 10 focuses on security aspects related to CTI and, in particular, on adversarial attacks. In Section 12, we discuss several open challenges and insights for further research work. Finally, in Section 13, we draw our conclusion to the survey.  \n\n2 Related Work  \n\nThis section provides an overview of the existing literature surveys in the field of CTI.  \n\nA survey on CTI mining techniques and the CTI knowledge acquisition taxonomy is presented in [4]. This survey is quite recent and analyzes the methodology that transforms cybersecurity-related information into evidence-based knowledge for proactive cybersecurity defense using CTI mining, proposed by papers published before 2022. Cascavilla et al. [5] focused on papers that deal with CTI data crawling, incident prediction and avoidance, and standardization of cyber-criminal activities in the Surface, Deep, and Dark Web. Similarly to our work, Rahaman et al. [6] analyzed different extraction purposes, namely CTI text classification, IoCs and TTPs extractions. Moreover, they identified several types of textual sources for CTI extraction (i.e., hacker forums, threat reports, social media posts, and online news articles), and they observed that NLP and Machine Learning (ML) based techniques, such as supervised classification, Named Entity Recognition (NER), topic modeling, and dependency parsing, are the primary techniques used for CTI extraction.  \n\nThe surveys presented in [7, 8, 9] analyzed the application of AI and ML in producing actionable CTI. While the authors of [7] only mentioned a work related to NLP and gave a brief survey on data collection and sharing. The authors in [8] conducted a short discussion on ML and AI tools (such as adversarial learning). The survey presented in [9] summarizes commonly used cyber security data sources with several approaches dealing with adversarial learning.  \n\nTable 1: Surveys related to our work   \n\nttacPaper Sun et al. [4]2014-2022Rahman et al.[6]2013-2022Cascavilla et al.[5]2002-2020Montasari et al. [7]2015-2020Samtani et al.[10]2013-2019√Samtani et al. [9]2012-2020Ibrahim et al. [8]2014-2020Basheer et al. [11]2017-2021Miloshevska [12]2015-2018Gao et al. [13]2007-2019Georgescu et al. [14]2007-2019Tounsi et al.[15]2010-2017Abu et al.[18]2011-2017Wagner et al. [17]2001-2018Sauerwein et al.[19]2012-2021√El-Kosairy et al.[16]2019-2022√Schlette[20]2001-2020Sun et al. [21]2013-2018OurSurvey2018-2023  \n\nThe paper illustrated in [10] provides a systematic review of existing CTI platforms within the industry; they reviewed the major data sources (without detailing the crawling techniques) and gave some insights on visualization, report generation, and intelligence dissemination. Moreover, they mentioned the enhancement of NLP and text mining as potential opportunities in the field of CTI.  \n\nThe works described in [11, 12] provide an analysis of the current role of the Dark Web as an environment that facilitates cybercrime and illicit gain. In particular, [11] compares state-of-the-art research studies that leverage the dark Web as an information source for CTI, describing their goals, approaches, tools, case studies, results, and possible limitations. A group of surveys focuses mainly on NER aspects related to the cybersecurity domain [13, 14]. Specifically, the authors of [13] introduced common NER models, methods, and related resources.  \n\nThe work presented in [15] focuses on Technical Threat Intelligence (TTI, hereafter) and the major problems related to it, CTI sharing, and evaluates the most known open source tools offering TTI. Surveys [16, 17, 18, 19] specifically deal with CTI Sharing. In particular, El-Kosairy et al.[16] highlight the most recent contributions, which discussed how blockchain is integrated with CTI to solve the issue of CTI sharing. The survey presented in [17] gives an insight into diverse problems pertaining to CTI sharing between 2001 and 2018. Specifically, it deals with the way of establishing a threat-sharing program with decentralized stakeholders, focusing on what information can be shared, with whom, and how to automate some of the collaboration processes. Moreover, it also covers topics like CTI anonymization, encrypting the data, and presenting privacy risk scores. The work presented in [20] sheds light on existing standardization approaches for incident responses. Finally, Sun et al. [21] described state-of-the-art cybersecurity incident prediction schemes and methods; moreover, the type of datasets used in each work is identified and referenced in minute detail.  \n\nWith respect to the previous surveys reported in this section, our paper introduces important contributions to the research community. Indeed, first, we analyze the publications produced in a very recent period (i.e., from 2018 to 2023); this is a crucial aspect because, with the technological improvement of AI solutions, novel NLP-based strategies for CTI are more and more advanced, and effective with respect to the results obtainable only a few years ago. Moreover, while existing works already consider some overlapping aspects with our survey, our proposal analyzes the recent CTI literature completely from the perspective of the exploitation of NLP techniques, thus providing a comprehensive report of how NLP-based solutions have been successfully adopted in the reference context. Table 1 provides a summary analysis of the contributions of the existing related surveys compared to ours.  \n\n3 Methodology  \n\nIn this study, we undertake a comprehensive literature review process, which can be outlined as follows: it involves establishing clear search objectives, entails the identification of relevant literature from journals and conference proceedings via a search engine driven by a well-defined search strategy, and encompasses the application of selection criteria to fliter the articles during this iterative process. Figure 1 presents the PRISMA flow diagram, providing a visual representation of the screening process. The diagram highlights the count of research works identified, excluded, and included.  \n\n  \nFigure 1: PRISMA Flowchart for paper selection process  \n\n3.1 Research Objectives  \n\nThe primary objective of this comprehensive literature survey is to conduct an in-depth analysis of NLP models, techniques, and their applications within the CTI domain. This entails a detailed exploration of common data sources and the methodologies employed for data collection in the CTI field. The study delves deeply into the relevant literature, with a specific focus on papers that address topics like text classification, similarity, clustering, summarization, crosslingual analysis, and topic detection, all within the context of CTI. The research extends its purview to encompass recent developments in NLP-based techniques for relation extraction. The survey also examines the literature related to adversarial attacks in the CTI field. Moreover, this research explores CTI standardization protocols and the sharing platforms, contributing to the enhancement of collaboration and knowledge dissemination in the CTI community. Furthermore, the study aims to identify areas in CTI where improvements are needed and to pinpoint potential research directions that can advance the capabilities of CTI. Lastly, this paper undertakes an exhaustive examination of the challenges and limitations that NLP encounters within the context of threat intelligence.  \n\n3.2 Search Strategy  \n\nTo gather relevant research focusing on NLP-based techniques for CTI, we designed a search strategy to align with our research objectives. We meticulously conducted searches through Google Scholar and Web of Science, thus accessing a wealth of scholarly resources. In addition, our search strategy encompassed a wide array of esteemed academic databases, such as the Institute of Electrical and Electronics Engineers (IEEE) Xplore, the Association for  \n\nComputing Machinery (ACM) Digital Library, ScienceDirect, and SpringerLink. The search scope encompasses a broad spectrum of publication years, spanning from 2018 to 2023, ensuring a well-rounded coverage of recent research in the field. Further, we developed the search terms to facilitate our initial exploration. The search terms assist in identifying relevant research and employ a combination of specific keywords and phrases to encompass various aspects of the threat intelligence and cybersecurity domain. The primary search term includes “threat intelligence\", “cyber intelligence\", and “CTI\". In conjunction with the primary term; we integrated additional search terms such as “indicators of compromise\", “tactics, techniques and procedures\", “hacker forum\", “dark web\", “APT attack\", “cyber attack\", “cyber security\", “named entity recognition\", “knowledge graph\", “cyber security relation extraction\", “adversarial attack\", “CTI platform\", and “CTI standardization\".  \n\n3.3 Selection Criteria  \n\nIn this section, we list the set of selection criteria we exploited to determine whether a scientific paper, identified through the search queries, is relevant to our study and reaches enough quality to be included in this survey. A paper is eligible for inclusion in the present work if it meets at least one of the inclusion criteria and none of the exclusion criteria applies. At the end of this screening, 192 papers have been selected based on inclusion/exclusion criteria.  \n\n3.3.1 Inclusion Criteria  \n\nTo evaluate the relevance of a paper and include it in our survey, we followed the subsequent criteria:  \n\n• we consider the corresponding author or the supervisor’s importance in the field under analysis;   \n• we count the number of citations (we refer to Google Scholar [22] and Scopus; [23] Web sites to establish this value);   \n• we privilege more recent works;   \n• we take into account the importance of the journal (or the conference) where the paper has been published (we consider Scimago [24] and Core.edu [25] as ranking Web sites for journals and conferences respectively to establish this value).  \n\n3.3.2 Exclusion Criteria  \n\nAfter the inclusion, the exclusion process is followed. A paper is excluded if only one of the following criteria is met:  \n\n• the paper is not written in English;   \n• the paper is not peer-reviewed or not presented at reputable conferences;   \n• the paper’s year of publication is earlier than 2018;   \n• the paper is relevant in the NLP context but it is not specifically focused on CTI;   \n• the paper lacks relevance, it is an incremental refinement of an earlier proposed approach, there is a duplicate publication, or there is a most recent and cited advancement of the work published in a more important journal or conference.  \n\n4 Overview of Cyber Threat Intelligence  \n\nCTI enables organizations to understand the evolving threat landscape, enhance their defenses, and respond effectively to emerging cyber attacks. Organizations adopt various types of CTI and go through various stages. The CTI life cycle and types are explained below  \n\n4.1 Threat Intelligence Life Cycle  \n\nCTI is a data-driven process that helps organizations defend against cyber threats and attacks. It involves several stages, working together to collect, process, and analyze data, providing valuable insights for cyber security. This systematic process transforms data into actionable intelligence, requiring continuous adaptation to evolving needs and real-world events. Different researchers have highlighted various versions of the CTI life cycle, with Irshad et al. [26] mentioned six stages, Basheer et al. [11] and Ainslie et al. [27] mentioned four stages. They all typically follow a cyclical and iterative process, allowing for ongoing review and adaptation. The core principles of intelligence collection, analysis, and dissemination remain crucial in addressing the ever-changing cyber threat landscape. In light of existing literature, the main CTI phases can be grouped into six stages, namely Planning and Direction, Collection, Processing, Analysis, Dissemination, and Feedback. The CTI process begins with Planning and Direction, where organizations establish their objectives, priorities, and requirements for threat intelligence. In the Collection phase, raw data is gathered from diverse sources, including open-source feeds, commercial threat intelligence providers, and internal logs. This data may include IoCs, malware samples, and network traffic logs collected through automated tools and manual research. Once data is collected, it needs to be refined and organized. Processing phase involves the conversion of raw data into a more structured format that can be used for analysis. In the Analysis phase, the processed data is analyzed to identify patterns, trends, and potential threats. Once the threat intelligence is analyzed and assessed, the findings are shared with relevant stakeholders during the Dissemination phase. Information is typically disseminated in a clear and actionable format, such as reports or alerts. Continuous improvement is a crucial aspect of a mature CTI system, with feedback collected from various stakeholders to evaluate the effectiveness of threat intelligence, identify areas for improvement, and address emerging requirements. The Feedback stage supports the refinement and adaptation of the CTI program to changing threats and organizational needs.  \n\n4.2 Types of Cyber Threat Intelligence  \n\nCTI encompasses a wide range of subcategories, highlighting the diversity of information sources and purposes. These subcategories include open-source intelligence, technical intelligence, human intelligence, measurement and signature intelligence, social media intelligence, geospatial intelligence, signal intelligence, Deep or Dark Web intelligence, and communication intelligence [11]. However in most of studies [15, 19], CTI classified into four types:  \n\n• Strategic Intelligence: Strategic threat intelligence aims to provide valuable insights for business decisions and processes, considering the impact of external factors such as geopolitics on adversaries’ actions. Strategic threat intelligence relies on expert analysts and authoritative sources to collect and interpret data from various channels, facilitating organizations in gaining insights into past incidents, understanding the intentions of threat actors, recognizing emerging trends, and developing risk mitigation strategies. It encompasses aspects like financial consequences, attribution of attacks, and industry-specific perspectives. By connecting global events and policies with potential cyber threats, strategic threat intelligence empowers decision-makers to assess risks and align cybersecurity investments with their strategic objectives. This type of intelligence is typically conveyed through comprehensive reports. It provides top executives and IT management with the means to identify risks, threat actors, and the origins of breaches while focusing on long-term challenges and real-time alerts for critical assets.  \n\n• Operational Intelligence: Operational threat intelligence serves as a vital tool for organizations to gain a deeper understanding of potential threat actors, including their motives, capabilities, and opportunities for launching attacks, while also identifying vulnerable IT assets and assessing the potential consequences of successful attacks. This form of intelligence is typically amassed by government entities and greatly beneftis incident response and forensic teams by enabling them to implement security measures for enhanced detection, early recognition of attacks, and safeguarding critical assets. The sources of operational threat intelligence predominantly comprise human intelligence, data from social media platforms, chat rooms, and real-world events linked to cyber attacks. It involves the analysis of human behavior and evaluating threat groups to forecast and prepare for forthcoming attacks. Typically presented in comprehensive reports, operational threat intelligence includes in-depth information about documented malicious activities, suggested courses of action, and alerts about emerging threats.  \n\n• Tactical Intelligence: Tactical threat intelligence is a pivotal component in the protection of an organization’s assets, offering valuable insights into the TTPs employed by threat actors in cyber attacks. This intelligence category primarily serves the needs of cybersecurity professionals, including IT service managers, security operations managers, administrators, and architects. It empowers these experts to gain an in-depth understanding of adversaries’ attack methodologies, anticipate potential data breaches, assess the technical proficiencies and objectives of the attackers, and pinpoint the avenues of attack. Consequently, it enables security personnel to proactively devise strategies for detecting and mitigating threats, which may involve integrating known indicators into security products and rectifying system vulnerabilities. Tactical threat intelligence is sourced from various outlets, such as campaign reports, incident reports, malware analysis, attack group reports, and human intelligence. The collection of this data entails activities such as analyzing technical papers, collaborating with other organizations, and obtaining information from third-party sources. This intelligence encompasses intricate technical details, including the specifics of malware, details of campaigns, the methodologies employed in attacks, and information about the tools used, often documented in forensic reports.  \n\nTable 2: Summary of the acronyms used in the paper.   \n\nSymbolDescriptionAPTAdvancedPersistentThreatCTACyberThreatActorCTICyber ThreatIntelligenceCVECommonVulnerabilities and ExposuresDNFDark Net ForumDNMDarkNetMarketplaceFinTechFinancial TechnologyGNNGraph Neural NetworkIDSIntrusionDetectionSystemIoCIndicatorofCompromiseIRCInternetRelayChatKGKnowledge GraphMLMachine LearningNERNamedEntityRecognitionNISTNationalInstituteofStandardsandTechnologyNLPNatural LanguageProcessingOIEOpenInformationExtractionOSINTOpen SourceIntelligenceOSNOnlineSocialNetworkSVMSupportVectorMachineTTITacticalThreatIntelligenceTTPsTactics,Techniques &ProceduresCRFConditionalRandomFieldSTIXStructured ThreatInformationExpressionBERTBidirectionalEncoderRepresentationsfromTransformersXAIeXplainableArtificialIntelligenceNVDNationalVulnerabilityDatabase  \n\n• Technical Intelligence: Technical threat intelligence is centered on understanding the tools and resources used by attackers in their malicious activities, encompassing elements like command and control channels. In contrast to tactical threat intelligence, this form of intelligence has a shorter lifespan but is highly specific, enabling swift distribution and response to threats. While tactical threat intelligence covers the broader malware used in attacks, technical threat intelligence delves into the detailed implementation aspects of that malware, encompassing specifics such as IP addresses, domains, phishing email headers, and malware checksums. This intelligence is typically consumed by Security Operations Center (SOC) staff and incident response (IR) teams, which is crucial in identifying malicious activities. The indicators used in technical threat intelligence are sourced from active campaigns, attacks on other organizations, or data feeds from external parties and are often gathered during investigations of attacks on different entities. Security professionals leverage this information to bolster the detection capabilities of security systems like IDS/IPS, firewalls, and endpoint security systems. This, in turn, facilitates the identification of malicious traffic and suspected IP addresses involved in malware distribution and spam emails. Technical threat intelligence is directly integrated into digital security devices to block and identify malicious traffic, both incoming and outgoing, within an organization’s network.  \n\n5 Natural Language Processing in Cyber Threat Intelligence  \n\nThis section is devoted to presenting the most common techniques employed in the NLP pipeline and how they can be applied to process CTI reports. In particular, we will describe the fundamental strategies of preprocessing and tokenization to sanitize the text from possible noise to enhance the robustness of the model built upon. Following that, we will introduce different representation techniques, from the most basic to the advanced ones, that make use of Deep Learning (DL) models to obtain more sophisticated and contextualized representations. Then, we will introduce the most modern NLP models that represent the state-of-the-art in combination with the tool that implements them.  \n\n5.1 Preprocessing and Tokenization  \n\nPreprocessing and Tokenization are fundamental preliminary cleaning phases in the pipeline of an NLP task. Data cleaning is important to reduce the dimension of each text, remove noise, and improve the performance of models that take sanitized text as input. Common strategies to preprocess the data [28], are listed in the following:  \n\n• remove HTML tags if the crawled resource is an HTML page; • replace characters not in A-Za-z0-9(),!?’‘ with whitespace; • convert text to lowercase,  \n\nTable 3: Preprocessing and Tokenization.   \n\nPaperLemmatization/ StemmingStopwordsRemovalTokenizationOrbinatoet al.[32] Gao et al.[33] Gao et al.[34] Kadoguchi et al. [35] Evangelatos et al.[40] Kuehn et al.[41] Dasgupta et al. [42] Wang et al.[43] Yang et al.[36] Ji et al. [37]√ ×x √ √  \n\n• replace leading/trailing white spaces with a single space,   \n• remove stop-words and duplicates,   \n• filtered out frequent and common words (i.e., appearing in more than $85\\%$ of the documents), • filtered out rare words (i.e., appearing fewer than three times in the entire corpus).  \n\nA common tool for data preprocessing is Stanford CoreNLP1 [29]. Also, the studies that leverage social network posts (i.e., tweets) follow similar preprocessing steps. The common ones, listed in [30], are: (1) conversion of all the characters of a tweet to lowercase, (2) tokenizing the text according to white-space separations, (3) removing tokens that are not encoded in ASCII or that are not comprised of alpha-numeric characters, (4) removing punctuations from each token, (5) substitute digits with word representations, (6) remove stop words, and (7) stem tokens. For the last two steps, [30] utilizes the functionalities available in the Natural Language ToolKit (NLTK) libraries [31].  \n\nTo disambiguate terms, which are inflected forms of the same word, two techniques are the most common: lemmatization and stemming. The former consists of substituting the inflected forms in the text with the original word and the latter, instead, reduces the inflected token to their root. These techniques have an important role also in the CTI approaches that involve NLP. An example of this can be seen in [32, 33, 34, 35, 30, 36, 37, 38] where the authors apply NLP-based strategies to extract CTI from unstructured sources, automatically. In particular, they applied a sanitization phase that includes stemming, lemmatization, and stopword/tag removal, to the descriptions of adversarial techniques. Such techniques are very common and can be applied before any ML algorithm. Models like BERT [39] require as input a sequence of a fixed length. In these situations, the input must preprocessed by either truncating it or adding a padding sequence to reach the required length. In addition, because such a model can interpret only numerical values, tokenizers are used to convert input tokens into numerical identifiers, encoding representations according to their vocabulary. For example, this approach is adopted by the authors of [40, 41, 42, 43] where they use BERT to perform Named Entity Recognition (NER) and threat classification in CTI. In particular, in addition to padding and truncation, they took into consideration a case-sensitive tokenizer because capitalized letters could be informative of phrases referring to a ransomware name. The authors of these papers also use tokenizers to split complex words into terms to make them identifiable in a reference vocabulary. Table 3 reports a summarized view of the different techniques adopted by reference papers in the CTI domain.  \n\n5.2 Text Representation Techniques  \n\nAs already mentioned in the previous section, neural networks and statistical algorithms cannot interpret text without converting it into a numerical representation. Representation techniques can leverage different strategies, ranging from statistical approaches, such as the very common Bag-of-Words [44], or representation obtained by a neural network, as done by Word2Vec [45].  \n\nAs for statistical approaches, Bag-of-Words is a well-known strategy that represents text by counting the occurrences of the words in the corpus of the documents. The idea behind this approach is to measure the importance of a word according to its frequency in relation to a specific outcome of the target ML algorithm. With this strategy, word frequencies are considered with the same relevance in the computation of the final result. However, this can be considered the main flaw of the Bag-of-Words approach since some of the words with high frequency, like ‘IP’ or ‘Port’ in the CTI field, are actually noise that negatively affects the performance of the target model. To solve this problem, some enhancements to the Bag-of-Words strategy have been proposed. One of the most common solutions in this sense is TF-IDF [46]. TF-IDF follows the same philosophy of Bag-of-Words by encoding the importance of a word and assigning a score to them, but instead of simply counting the word occurrences, it weights their contributions according to how frequent they are in the different documents. In this way, this approach lowers the contribution of too frequent terms.  \n\nTable 4: Text Representation Techniques in the literature   \n\nPaperBag-of-Words/ Bag-of-CharactersTF-IDFGloVeWord2vec/ doc2VecNayak et al. [48]×Kim et al. [52] Dionisio et al.[51]Kadoguchi et al. [35]× ××Ampel et al. [49]×Kadoguchi et al. [50]Le et al. [53]Zhao et al. [29]Adewopo et al.[54]Bo et al.[55]Kristiansen et al.[56]Pantelis et al.[57]Li et al. [58]Queiroz et al.[59]×Kadoguchi et al. [50]Biswas et al. [60]×Li et al. [61]×Ayoade et al.[62]×Goseva et al.[63]××  \n\nAnother method based on statistical analysis is GloVe [47]. GloVe is an algorithm that generates vector representations of words, building the co-occurrence matrix between words and encoding the information regarding the probability ratio of co-occurrence probabilities of words. As for the approaches using neural network representations, a well-established method is Word2Vec. Unlike previous methods, Word2Vec uses a neural network to create a space where words are represented as vectors, and their positions in this space reflect how they relate to each other. The Word2Vec approach proposes two strategies. The first strategy is called Continuous Bag-of-Words (CBOW) and is used to generate word representation starting from the representation of the context. The second one, called Skip-Gram, is used to generate the context vector starting from a single word.  \n\nThe strategies introduced above are fundamental tools to generate representations of text to be fed into NLP models targeted to CTI tasks like, topic modeling or classification [35, 48, 49, 50, 51, 52, 53, 29, 54, 55, 56, 57, 58]. For instance, the solution proposed by [48] applies a TF-IDF strategy to generate representations of malicious URLs that are then fed to a K-means algorithm to obtain the different topics.  \n\nIn [52] Bag-of-Characters representation, a Bag-of-Word strategy applied at a character level is used to generate the embedding of short-text CTI reports to be processed by a BiLSTM network for the NER task. Similarly, in [51], Word2Vec and GloVe are used in the same way on short text documents about CTI from Twitter. Another example of this is proposed by [35], where the authors analyze posts from the Dark Web. To do so, they exploited doc2Vec, which works analogously to Word2Vec but instead of generating word representations it produces vector embeddings of the entire document. Then, the obtained vectors are used as input to an unsupervised clustering algorithm. The approach presented in [49] uses an embedding matrix generated using GloVe as input to a C-BiLSTM network that aims at exploiting source code labeling. Analogously, the work presented in [50] generates document representations using doc2Vec, as done by [35], but in this case, it is used to classify cyber attacks using a Multilayer Perceptron (MLP) network.  \n\nA schematic report of the techniques used by the papers analyzed in this section is visible in Table 4.  \n\n5.3 NLP Algorithms and Models  \n\nIn Section 5.2, we presented well-known and established representation techniques. Nowadays, more advanced neural models have emerged to build sophisticated techniques of representation and learning. As a matter of fact, one of the main drawbacks of previous approaches is the inability to have different representations of the words in different contexts. For instance, algorithms such as Word2Vec and GloVe generate the same word representations in any context. To overcome this flaw, modern models like ELMo [64] or those based on the transformer architecture can generate different embeddings according to the surroundings of the words [39]. ELMo uses a bidirectional LSTM trained to generate different contextualized representations for each word to solve the ambiguity of words with different meanings. In particular, the ELMo model has been trained on a large set of data to predict the next word of a sequence. With such characteristics, this model is capable of generating generally enough representations to be used in different tasks or even improved with accurate fine-tuning.  \n\nTable 5: NLP solutions used for Text Representation in the reference literature   \n\nPaperELMoBERTGPTZhou et al.[69]√Wang et al.[43]√Alam et al. [70]×√Yin et al.[71]√Liu et al.[72]√Ranade et al.[75]√Chan et al.[38]Ranade et al.[73]√setiantoetal.[74]×  \n\nThis aspect is shared also with transformer-based models like BERT [39] and GPT [65]. The original architecture of BERT is characterized by an encoder-only model proposed in two versions that differ in the number and dimension of their encoding blocks. The basic one is composed of 12 encoding blocks with 768 hidden units each; the larger model is characterized by 16 blocks with a size of 1024 units. Compared to LSTM models, transformers are unaware of the concept of sequence. To solve this issue, a positional embedding layer is added at the entrance of the BERT model to encode in each word representation information about their position in the sentence. One of the main characteristics of BERT refers to the strategy used to pre-train the model. The training has been performed on two different tasks contemporaneously. In particular, in the first task, the model objective is to predict the original value of a masked word in a sentence. With the second task, instead, the authors train BERT to predict the next sentence. Like ELMo, BERT can be used to produce different representations of a word according to the context. The second example of a transformer-based model is GPT, which recently received huge attention due to its text generation capabilities [66, 67, 68]. Different from BERT, GPT is characterized by a decoder-only architecture. The authors proposed different evaluations of their GPT model over the years. In its latest version, GPT-4, the training is characterized by a reinforcement learning phase that uses rewards given by humans. This strategy allows the model to achieve extra quality in the produced text compared to the previous versions.  \n\nAs said earlier, due to the large amount of data used for the training, the models discussed in this section are general enough to be used as a backbone in NLP pipelines in the CTI field. This is demonstrated by the authors of [69], who test their proposed NER dataset with different combinations of models that exploit representation produced by ELMo and BERT. Another example can be seen in [43], where the authors slightly modify the input of a BERT model to adapt it to a different objective, i.e., restoring the original order of a permuted text. The authors of [70] proposed a Python library for NER tasks on CTI documents, which allows the import of pre-trained BERT models. In [71], the authors presented EXBERT, a framework that uses BERT as a backbone to generate the embeddings that are hence provided as input to a classifier. The objective is to predict the exploitability of vulnerabilities from their software descriptions. The approach proposed by [72] uses BERT for data augmentation in the context of cybersecurity. In [73], a GPT-2 fine-tuned model is used to generate fake CTI reports to demonstrate a data poisoning attack on a knowledge extraction system. Instead, the authors of [74] proposed to use a GPT-2 fine-tuned model to parse Unix commands from log flies in real time. A schematic summary of the NLP tools used by the papers described above is visible in Table 5.  \n\n5.4 NLP Libraries and Tools  \n\nThe processing procedures presented in 5.1 are well-known and established techniques implemented in many libraries. Two of the most popular choices are the libraries implemented in Python $\\mathrm{NLTK}^{2}$ and spaCy3. NLTK is a very easy-touse library that implements many different useful tasks for preprocessing and also basic algorithms for clustering, such as K-means and classification, e.g., Naive Bayes. As for the preprocessing tasks, it implements several lemmatizations and stemming approaches and provides lists of stopwords to remove in different languages. SpaCy, instead, provides more advanced tools like wrappers for neural network models implemented in the main frameworks Tensorflow and Pytorch with GPU support. Interestingly, in the latest version of spaCy at the time of writing this article, developers added support to transformer-based models. Another powerful tool that offers advanced capabilities like tokenization, POS-Tagging, and NER is the one proposed by Stanford, called Stanford $\\mathrm{CoreNLP^{4}}$ , available for both Python and Java languages. When it comes to transformer-based models, such as BERT and GPT described in Section 5.3, one of the most well-known and complete ecosystems providing easy and intuitive access to such models in an NLP workflow is Hugginface5. Huggingface allows an easy import of pre-trained models and associate tokenizers to be used for many different tasks, including fine-tuning. In addition, the developers offer an open hub where it is possible to upload fine-tuned models freely downloadable by the community.  \n\nMost of the papers in the literature that involve NLP [30, 53, 57, 76, 32, 77, 63] use the NLTK library to exploit implemented algorithms, such as TF-IDF vectorizer, stop-words or stemming/lemmatization. However, many others [72, 37, 34, 33, 75, 78] use spaCy for vector representation and stemming/lemmatization. Stanford CoreNLP is typically used as an additional advanced library by many solution-proposing approaches for NER and POS-tagging [43, 78, 51, 40, 79]. Finally, as we stated before, transformer-based models are recently becoming very popular, and pre-trained ones are often exploited thanks to the support of the Huggingface community [75, 40, 38]. In such papers, pre-trained transformer-based models are used after a fine-tuning step for the specific task of CTI reports analysis.  \n\n6 NLP-Based Techniques for Threat Intelligence Collection  \n\nThe aim of this section is to survey the solutions for CTI data gathering from Online Social Networks (OSNs, for short), the Clear Web, and the Dark/Deep Web, where malicious actors collaborate and communicate to plan cyber attacks. Not all information gets published into standard CTI databases and appliances; CTI is often shared in unstructured ways like blogs, posts, or threat reports from security companies or experts. For this reason, multiple online data sources are used as signals to generate warnings indicative of new potential cyber threats. Information gathering is the first and crucial step for collecting relevant data about new vulnerabilities, exploits, security alerts, threat intelligence reports, and security tool configurations. From the collection perspective, data can be divided into two categories: $(i)$ indicator-based data, which mainly provides IoCs for quick attack prevention, and (ii) document-based data, which may contain richer and more comprehensive threat information than the former category, but, at the same time, may require more complex NLP techniques for the analysis. The first group is, in turn, divided into high-level IoCs (represented by TTPs, malware, and tools) and low-level IoCs (e.g., IP, URL, hash, domain name, source/destination port, timestamp, and infection type). In both cases, preliminary steps for crawling Web pages about malicious content involve (i) gathering URLs on the internet, $(i i)$ filtering out benign content, and then (iii) downloading malicious ones.  \n\n6.1 Crawling from Clear Web  \n\nThe clear (also Open or Surface) Web represents the standard, publicly accessible portion of the Internet, where information is openly available, indexed by search engines, and accessible via conventional Web browsers. Since their introduction, Web crawlers have been intended to gather data from Clear Web. In Figure 2, a general architecture for crawling this kind of Web is shown. Focused crawlers scan the Internet starting from some seed URLs. Usually, a Seeding module is in charge of locating initial URLs to be used by focused crawlers. Since they only search for relevant information, their performance can go down if different clusters of Web pages are isolated; hence, choosing a high number of appropriate seeds can solve this issue. To improve the performance of the overall architecture, inside the Seeding component, ML models can be used to classify URLs before navigating the Web pages. Finally, a page classification module is launched to assess if the Web page includes malicious content.  \n\n  \nFigure 2: General Architecture for crawling the Clear Web  \n\nIn [80], the authors proposed a two-stage architecture, including a crawling module and a content ranking module. The first part produces a focused crawler that employs NLP to decide if some target Web sites deal with specific cybersecurity-related vulnerabilities. Specifically, a Support Vector Machine (SVM) classifier is combined with a user-provided query relevant to the topic. Hence, with respect to the reference architecture in Figure 2, the Seeding module is enriched with this facility to improve seeds’ selection. Moreover, the second component is in charge of assessing the relevance and usefulness of the crawled content. In the extended version of the paper [81], the authors presented an architecture called inTIME, including a more complex crawling infrastructure built on top of NYU’s ACHE crawler6 and enhanced through the use of regex-based filters to direct the crawl to specific parts of a Web site. Moreover, to support focused crawling, inTIME includes the SMILE7 page classifier, which is based on an ML-based text classifier (e.g., SVM and random forest), trained by a selection of positive and negative examples of Web pages, to direct the crawl toward topically relevant Web sites.  \n\nThe issue of discriminating between benign and malicious Web pages before crawling their content is also faced by “MalCrawler”, which has been designed to crawl and search malicious Web sites efficiently [82]. In this system, the set of URLs representing the initial seeds’ collection is processed, and only malicious links are navigated. MalCrawler can also prevent redirections and cloaking, generally used to avoid showing pages containing malicious content to search engine crawlers. The libraries used to develop MalCrawler are: (ii) JSoup Library8 for parsing Web pages and extracting hyperlinks, document content, and JavaScript tags; (ii) Rhino a JavaScript Emulation Library to analyze the runtime behavior of JavaScript; and (iii) HTML Unit10 a browser emulation library written in Java to test redirection, and cloaking. Another recently presented focused crawler, called ThreatCrawl [41], leverages the aforementioned general architecture, and it is based on both a retrieval and an extraction step. Additionally, this system presents a monitor module as well, that stores the state of each retriever and extractor thread and can check for any critical error. Moreover, to extract the main content of an HTML Web Page and return it as parsed text, ThreatCrawl leverages both Trafliatura [83] and Beautiful Soup11. Both the works presented in [84] and [79] design a cybersecurity engine, according to which the data collection step is done manually from multiple data sources, which are updated periodically via a monitor. Specifically, the main scope of [79] is to model and visualize security datasets based on users’ queries and demands. Three datasets are exploited in this work, namely: (i) 1000 security news articles [85] mentioning security events and annotated by experts; $(i i)$ some vulnerability archives collected from authoritative vulnerability database; (iii) a number of tweets related to security keywords and extracted using a Python library called Twitterscraper12.  \n\nSimilarly to the previous paper, also in the work presented in [86], the authors crawl multiple data sources. To do so, a semantic search system is developed to facilitate searching for high-level IoCs in the CTI corpus. They identified 36 Cyber Threat Actors (CTAs) and collected publicly available documents describing both the attack incidents (APT) and the CTAs. As also done in [87, 88, 89], they leveraged a publicly available repository called APTNotes13 containing cyber threat reports since 2008. Using the search engine and the repository, they collected 327 unstructured CTI documents. The work described in [89] collects a set of publicly available reports starting from MITRE ATT&CK214 (a globally accessible knowledge base of adversary tactics and techniques based on real-world observations); and APT Groups and Operations15, which link threat actors to relevant reports. Through a manual expert review, the authors selected the most important threat actors for which there are a sufficient number of reports. The final dataset contains 249 reports, which describe attacks performed by 12 different actors. Similarly, the authors of [90] leveraged a dataset of corpora collected on the XianZhi platform 16  \n\nAnother important source of CTI data can be found in the authoritative cybersecurity databases available online. As a matter of fact, authors of several papers [77, 91, 92, 37, 93, 79] leveraged data from online databases. Often, they used this data in combination with posts gathered from the Twitter Social Network as a ground truth database. The most popular employed databases are listed in the following:  \n\n• Common Vulnerabilities and Exposures (CVE) database17. Each vulnerability present in this storage is identified by a CVE ID. The Web portal allows the user to make queries by CVE IDs to gather detailed information about the already known threats as well as to provide a Common Vulnerability Score (CVS) evaluating the impact of the given vulnerability.  \n\nTable 6: Crawling from Clear Web   \n\nPaperTechnologyusedtocrawldataSample SizeKoloveas et al.[80]ACHEopen-sourcefocusedcrawler20,000WebsitesSingh et al.[82]JSoupLibrary,Rhino,HTMLUnitanotdefinednumberofWebpagesPerry et al. [89]publiclyavailablereports249reportsKuehn et al.[41]TrafilaturaandBeautifulSoup259URLsSun et al.[79]ManualCollection1000news articles[85]andvulnerabilityarchivesfromauthoritativevulnerabilitydatabaseNoor et al. [86]CustomizedSearchEngine327unstructureddocumentsChen et al.[88]Github'sAPTNotes600articlesDong et al. [77]CVEandNVDdatabases78,296CVE,78.296NVDentriesAlvesetal.[92]CVE,PacketStormandotherCTIdatabases455.026entriesJi et al. [37] Vishnuetal.[93]PRCandHackmageddondatabases61,957cybersecurityeventsLi et al. [84]CVEdatabase134,091vulnerabilitydescriptionsWu et al.[90]ManualCollection610collectedarticlesXianZhiplatform971Websites  \n\n• Common weakness enumeration (CWE)18 is a community-driven project that aims at identifying and classifying common software security weaknesses in a standardized and systematic way. Moreover, for each weakness listed in the CWE, a piece of associated information is present about how to identify, mitigate, and prevent the vulnerability.  \n\n• Common Attack Pattern Enumeration and Classification (CAPEC) database19 provides a broad hold of a wide list of attack patterns, which are widely used by security analysts, developers, and testers. Similarly to CWE, CAPEC categorizes attack patterns into a hierarchical structure. Each attack pattern is assigned to a unique identifier and organized into different categories and families.   \n• The Web Application Security Consortium $(\\mathrm{WASC})^{20}$ collects and organizes the threats related to the security of Web sites. Its main focus is to categorize and classify various Web application security threats and vulnerabilities, making it easier for organizations to understand and address them.   \n• NIST’s National Vulnerability Database $(\\mathrm{NVD})^{21}$ mirrors and complements CVE entries on their database. It is maintained by the National Institute of Standards and Technology (NIST), which is a federal agency of the United States Department of Commerce. Every hour, NVD contacts CVE to obtain new CVE IDs of recently disclosed vulnerabilities.   \n• PacketStorm22 is an online resource and repository for a variety of current and historical cybersecurity-related information, tools, and databases.   \n• Privacy Rights Clearinghouse $({\\mathrm{PRC}})^{23}$ is an independently maintained collection of reports about cybersecurity incidents divided according to victim organization type (i.e., government agencies, businesses, medical service providers, educational institutions, etc.).  \n\n• Hackmageddon24 is another reputable collection of public reports about cybersecurity incidents.  \n\nTable 6 summarizes, for each analyzed paper, the technology used to crawl data and the amount of data crawled.  \n\n6.2 Crawling from Social Media  \n\nOnline social networks provide an open environment where both offensive and defensive practitioners can engage in discussions, report incidents, and promote timely information about vulnerabilities, attacks, and malware. Among the online social networks, Twitter has always been one of the most popular in the scientific research context, mainly because of $(i)$ its large and international user base (almost 400 million users), $(i i)$ its set of available APIs, that allows developers to easily integrate Twitter data into their systems, and (iii) the tagging functionality that allows users to label their tweets and search them via keywords (i.e., hashtags), thus providing a natural data aggregation capability. For all these reasons, Twitter has become the preferred platform for disseminating up-to-date IoCs and threat intelligence data and conducting threat hunting[94, 95].  \n\nOne of the main issues of gathering data from Twitter is to wisely choose starting keywords to fliter the stream listener results and reduce the amount of irrelevant information that is gathered. Nevertheless, crawling from this social network is quite a standard task for all the papers considered in this section and mainly proceeds with the execution of three tasks: data collection, keyword-based pre-filtering, and text pre-processing.  \n\n• In the collection phase, an initial set of Twitter accounts is required. Starting from this list, the crawler usually queries Twitter’s streaming API for tweets. • In the pre-filtering phase, a set of user-defined keywords are used to drop irrelevant tweets. • In the pre-processing phase, some transformation on data is performed to make representation uniform.  \n\nFigure 3 summarizes the main steps explained above.  \n\n  \nFigure 3: General Architecture for crawling data from Twitter  \n\nThe works presented in [51, 96, 97, 98, 54] follow this standard crawling architecture to crawl tweets and classify them as potential cyber threats. As for the collection step, in [97], the authors identified accounts related to Hacktivists, cybersecurity feeds, security researchers, and companies. Then they crawled tweets from their timeline, and after that, they flitered these tweets again based on a security keyword fliter and on a keyword list obtained by the Department for Homeland Security [99]. Also, the framework IoCMiner [100] starts from an initial set of Twitter accounts to collect tweets about CTI. This initial set is built through Twitter user-defined lists of identified CTI experts with a mechanism of validation that measures the relevancy, popularity, and comprehensiveness of the list in addition to the credibility of its owner. Moreover, it employs a CTI classifier to further filter out non-CTI tweets from the observed data streams. Finally, IoCMiner uses a set of regular expression rules to extract IoCs from the identified tweets.  \n\nSimilarly, the framework presented in [98], called DISCOVER, aims to process data from multiple sources (such as Twitter and security blogs), and by employing data mining techniques, it identifies novel terms related to a potential cyber threat in the form of a warning alarm. To gather data from Twitter, they leveraged some experts’ proflies, which it identifies in the timeline of international researchers and security analysts. As for the security blogs, the authors manually chose a list of 290 blogs and extracted data from them via a custom crawler. Data from these two sources are filtered to find words related to cyber threats.  \n\nThe works analyzed up to this point collect the set of raw data from experts’ profiles and then apply a filter, based on keywords, on their timelines. The framework called #Twiti [101], instead, performs data collection in two ways: user tracking and keyword tracking. To perform the latter modality, it extracts the top 100 words that appear in tweets containing IoCs and uses them as starting keywords. Moreover, the presence of external sources is detected and also used as search criteria (such as URLs to security vendor blogs or Pastebin.com).  \n\nIn [30, 102], the authors presented a framework for the detection and classification of cyber threat indicators in the Twitter stream. Specifically, for [30] the data collected consists of a corpus of 21, 000 tweets gathered with a custom stream listener developed through Tweepy25. This work proceeds only using a list of keywords as a pre-filter for the stream listener, and after that, it performs two classification steps assessing the relevance of the cyber threats and the threat types. The first step is performed by leveraging the topic modeling API of IBM’s Watson Natural Language Understanding service [103]. The latter, instead, is done manually by simple string matching on the rough tweet text to find the type of thread. Similarly to [30], the framework CTI-Twitter [56] uses a set of manually decided keywords as input for the streaming API, but it also leverages a Python library known as GetOldTweets26 to enrich this set with a historical collection of tweets. In [102], authors presented a work to identify target domain-relevant feeds containing critical patterns, and they preprocessed the whole tweet stream, filtering it via keywords. The chosen keywords are related to traditional cybersecurity events, including account hijacking, data breaches, and denial of service attacks, and also to emerging events, such as ransomware and cryptocurrency mining malware. Interestingly, the authors also applied dynamic query expansion (DQE) to enrich tweet collection with tweets semantically related to cybersecurity.  \n\nThe dataset used by [91] comprises tweets collected using Twitter API and information crawled from vulnerability information databases, such as NVD. They linked the data from the two sources together if they refer to the same CVE ID. In particular, the initial seeds’ set is composed by searching on Twitter all the users’ profiles who periodically posted tweets containing the keyword “CVE” from June to September 2018. By observing the temporal characteristics of tweet activities, the authors found that Twitter message streams can directly reflect cyber threats. Similar works are presented in [53, 92, 104, 105, 106] that learn the features of CTI from the CVE descriptions and classify each input tweet as either normal or anomalous. In particular, the framework presented in [92] aims at comparing some aspects of the information present on vulnerability databases with Twitter data. The authors start searching for tweets mentioning the vulnerabilities indexed on the vepRisk database [107] containing all entries published on NVD, PacketStorm, and other minor security databases. Moreover, they leveraged the GetOldTweets library to have access to tweets at any point in time. The pre-flitering phase is performed manually, and the final database resulted in 3, 461, 098 tweets. The authors of [104], instead, gather their data from Twitter by searching for tweets matching the CVE identifiers and enriching this set with additional information from the NVD database. In addition to the standard gathering of tweets about CVE IDs via the Twitter APIs, the peculiarity of [105] is that it queries the vendor sites to collect the patch release dates to determine whether a vulnerability has had immediate or deferred disclosure. Also, the paper presented in [37] uses two external sources (i.e., collections of reports, namely PRC and Hackmageddon) as a ground truth database to test the proposed method. Moreover, it leverages a large stream of tweets from GNIP’s decahose27, which is a real-time trend detection and discovery solution delivering a $\\bar{10}\\%$ sample of real-time tweets.  \n\nThe paper presented in [108] deals with two social media conversation channels (Reddit and Twitter) and a collaborative software development platform (GitHub) and aims to compare user-generated content related to security vulnerabilities on these three digital platforms. In particular, Reddit28 is also a popular social network among researchers for its openness and for its focused topic-based conversations structured around subreddits, whereas GitHub29 is one of the most prominent collaborative open-source software development platforms. This work shows that both Twitter and Reddit can be used to accurately predict activity on GitHub. As classically done, the dataset for this work is built by flitering posts from both Twitter and Reddit through keywords containing a vulnerability identifier (i.e., CVE) from the NVD subset. When a CVE identifier appears in a post or a comment, all the related messages (e.g., tweets, retweets, and replies) are also gathered. As for Reddit and Github, a search on subreddits (repositories, respectively) via regular expression is carried out to find the CVE IDs.  \n\nSimilarly to Github, Paste sites are Web sites or online platforms that allow users to easily share and store plain text snippets or code snippets for a temporary period. These snippets can include code, configuration flies, notes, and other text-based information. The work presented in [109], leverages data from three prevailing paste sites for collection based on feedback from cybersecurity experts: Pastebin30, PasteFS31, and Pastelink32. The authors developed custom Web crawlers to collect each paste and their associated metadata (e.g., title, author).  \n\nThe social Web crawler presented in [80] uses links to discussion threads on IoT vulnerabilities to traverse a forum structure and download all relevant discussions on the topic. To filter out parts that are not relevant, part of the forum employs regex-based link filters. Examples of forum crawled are: (i) Wilders Security Forums33; $(i i)$ Oracle Security ${\\mathrm{Blog}}^{34}$ ; and (iii) Security Forum35. In the extended version of this paper, presented in [81], the author designed inTIME, a framework based on ML that can crawl data from multiple sources. As for social network monitoring, the authors show a use case where the system collects live tweets using the Twitter Stream API with keywords related to IoT vulnerabilities and leverages a CVE database as a dictionary of keywords. Finally, the authors of TI_spider [29] developed an automated data collection system from different social media, including blogs, hacking forum posts, security news, and security vendor bulletins. In particular, this system exploits 75 independent distributed crawlers, each of which monitors and collects a specific data source using a breadth-first search to collect threat descriptions.  \n\nTable 7: Crawling from Social Media   \n\nPaperSocial MediaTechnologySampleSizeBehzadan et al.[30]TwitterTweepy21,000 tweetsAdewopo et al.[54]TwitterTweepy500.000tweetsSapienza et al.[98]Twitter,Twitter API,tweetsof69profilesSun et al. [91]Securityblogs TwitterHTML parser TwitterAPI290securityblogs tweets of2,917profilesRodriguez et al. [97]TwitterTwitterAPI70,475 tweetsNiakanlahiji et al. [100]TwitterTwitterAPI2,300 tweetsDionisio et al.[51]TwitterTwitterAPI5,320tweetsLiu et al.[102]TwitterTwitterAPI2,031,766 tweetsShin et al.[101]TwitterTwitterAPI978,414 tweetsAlves et al. [92]TwitterGetOldTweets3,461,098 tweetsJi et al. [37]TwitterGNIP's decahose4,975,992,550tweetsSauerwein et al.[104]TwitterTwitterAPI709,880 tweetsSyed et al.[105]TwitterTwitterAPI13,277 tweetsKristiansen et al. [56]TwitterTwitterAPI,GetOldTweets76,047tweetsHorawalavithana et al.[108]Twitter,TwitterAPI105,596tweets,retweets,repliesReddit,Reddit API170,486 posts and commentsGitHubPublic download7,240,398activitiesZhao et al. [29]Social MediaCustom crawlers75 blogs,security forums,etc.Vahedi et al.[109]Pastebin,PasteFS,andPastelinkCustomWebcrawlers4,254,453 posts  \n\nEach crawler starts the collection from a homepage, including links to threat events. For each link, it crawls the HTML source codes and extracts threat event data leveraging Xpath (XML Path language).  \n\nTable 7 summarizes, for each analyzed paper, the Social Media analyzed, the technology used to crawl contents, the collected sample size, and the type of resource collected (i.e., tweets, users, replies, etc.).  \n\n6.3 Crawling from Dark/Deep Web  \n\nWith the term Deep Web, we refer to all Web content that is not indexed by search engines (whose content is not necessarily hidden). This includes Web pages and databases that are not accessible through search engine queries. The Dark Web, instead, represents a smaller, hidden portion of the Deep Web that is accessible through specialized software (like TOR - The Onion Router36, the Invisible Internet Project, or Freenet). It typically makes use of special encryption software to hide users’ identities and IP addresses and is often associated with illegal activities. The most frequently used platforms, where hackers gather to exchange malicious tools, information, and other content in the Dark/Deep Web, include hacker forums or Dark Net Forums (DNFs, for short), Dark Net Markets (DNM, hereafter), Internet Relay Chat (IRC, hereafter), and carding shops [110, 111].  \n\nHacker forums are repositories of thousands of readily available exploits enriched with comprehensive metadata, and they primarily revolve around major themes, such as carding and exploits. In contrast, DNMs often feature a substantial amount of non-cybersecurity-related content, such as pornography and illegal drugs, while lacking valuable CTI metadata, as observed by Ebrahimi et al. in their study [112]. Furthermore, researchers often face a significant risk when seeking additional details from DNMs, as products may need to be purchased. IRC and carding shops enable plain-text conversations or the posting of stolen credit card information, but they typically do not allow hackers to share exploits. Due to the analytical challenges posed by DNMs, IRC, and carding shops, cybersecurity researchers frequently prefer to focus their efforts on hacker forums when examining exploit-related content for CTI. Consequently, a significant number of relevant studies focus on the detection of cyber threats within these hacker forums [81, 113, 28, 114, 115]. While hacker forums on the Dark/Deep Web are built on similar frameworks as traditional forums, they incorporate a variety of anti-crawling measures aimed at impeding large-scale, automated data collection. Common mechanisms include authentication, Turing tests, throttling, CAPTCHA images, IP address blacklists, obfuscation, paywalls, and network traffic analysis [111]. Moreover, usually, each forum framework has a unique HTML structure, naming scheme, and different internet software packages. They are accessed through Tor, a network of servers running specialized software and providing anonymity to the user. In addition, many of them are written in different languages depending on their origin (the most frequent are English, Chinese, and Russian). For all these reasons, a traditional Web crawling approach cannot be directly applied to crawling hacker forums in the Dark/Deep Web.  \n\nThe general steps usually performed by all the cited articles are shown in Figure 4, and they can be summarized as follows:  \n\n• Identifying forums. The first challenge is the identification of the relevant target forums, i.e. those containing users and content related to cybersecurity intelligence. Some researchers exploit expert knowledge to identify possible hacker forums[116, 110] or leverage an already existing list of possible resources [117, 80, 114, 118]. In many Dark Net forum conversations, participants may reference or share hyperlinks to other cyber-criminal communities or underground markets that can, in turn, be crawled[111, 110] (this mechanism is referred to as snowball identification). In general, due to the underground nature of the intended targets, obtaining a curated and always updated list is quite challenging; hence, the majority of works realize custom crawlers that traverse the Dark Web to find reachable sites over Tor. For this last set, the first suitable target forums are identified by hand or by a simple keyword search to bootstrap the process [111]. After obtaining a foothold, the content of these forums is analyzed to obtain further links and addresses to other targets in a more automated fashion in later iterations [117].  \n\n• Gaining access. Since forums often require some sort of authentication to access the site, crawlers need personal accounts to log in on each site. Some sites request new users to provide only a valid email address, and others may work only if invited by other active hackers or even require users to first buy credits.  \n\n• Data collection. After the previous phases, data collection is usually fully automated. This phase deals with establishing anonymous access to the forums over Tor and the collection of raw data. Usually, a custom Web crawler is developed. The crawler will automatically download the starting seed pages, identified in the first step, and constantly discover new pages by following encountered hyperlinks. Text parser programs, using regular expressions manually identified by researchers, can be used to automatically extract meaningful information from the HTML code of the Dark Net forums (i.e., author names, thread titles, and others).  \n\n  \nFigure 4: General steps for crawling Dark/Deep Web  \n\nThe work presented in [111] gives useful insights into the steps of Dark Net identification and Data collection. Before beginning to search for data sources, it is crucial for researchers to take precautionary measures to create a secure research environment to safely download, analyze, and archive Dark Net content. Researchers could have to deal with malware or malicious JavaScript code when browsing underground forums. To enhance safety, the following suggestions are given:  \n\n• Implementing virtual operating systems and networks to collect data on quarantined and isolated computers.   \n• Renting virtual private servers from cloud services to set up research tools on one server and then clone it to scale collection for different forums. This can provide resilience and scalability.   \n• Check for Terms of Service (ToS) violations when identifying potential cloud service providers or other external tools.   \n• Sanitized Collected data can be processed for secure long-term storage.   \n• The database should be placed on a network distinct from the servers used for downloading Dark Net content to prevent potential malware and other security threats from compromising the integrity of the archived data.  \n\nThe work of [111] presents a complete framework called DICE-E for conducting Dark Net forums identification, collection, and evaluation. Moreover, it carries out an empirical demonstration by collecting information from 4 DNFs located in the United States, China, Russia, and Iran, namely Antichat.ru, Ashiyane.org, HackHound.org, and Unpack.cn.  \n\nThe paper [117] presents BlackWidow, a system that monitors Dark Web services in real-time and continuously. Moreover, it adds custom functions that emulate typing and clicking behavior in order to login to forums automatically. Moreover, it employs the node.js headless Chrome browser puppeteer37 as a crawler within the Docker containers to collect forums’ content and metadata. A similar framework is presented in [119], and it is called the Exploit Vulnerability Attention Deep Structured Semantic Model (EVA-DSSM). As for the collection part, the authors identified a large and popular exploit-specific hacker forum containing a variety of malicious tools and used a Web crawler routed through Tor to collect all exploit-category, post-date, author-name, platforms-targeted, and exploit-description data into a relational database. This resulted in 18, 052 exploits across four categories (namely, Web applications, local, remote, and DoS) targeting 31 operating systems, Web applications, and programming languages.  \n\nThe custom crawler called HackerRank developed by Huang et al. [120] gathers data from 5 forums (i.e., Nulled, HackThisSite, HiddenAnswers, BreachForum, Raidgets) collecting all the threads from the forum first, and then all the posts under the thread, including the username, proflie, content, order, and time of the post. In addition, the authors also consider some mechanisms to deal with the anti-crawler mechanisms of the underground forums. Its aim is to realize an automatic method for identifying key hackers, also leveraging social network analysis metrics. In [80], the authors realize an architecture to extract CTI data not only from Clear Web and forums but also from specific Web sites on the Dark Web. This crawler is provided with several onion links that correspond to hacker forums or marketplaces, where cyber-crime tools are sold, and zero-day vulnerabilities/exploits are monitored. After a first manual authentication, the HTML text of the Web site is extracted along with useful metadata. In the extended version of this paper [81], the authors presented a complete framework capable of crawling from multiple and heterogeneous sources and supporting Dark Web crawling. This functionality relies on the use of TOR proxies to visit the user-specified onion links, and all the required actions (i.e., joining the TOR network, using the proxy, initializing the crawler) are automatically carried out via internal API calls. As for the authentication, a manual user login should be performed the first time the crawler encounters an authentication barrier. Then, session cookies are stored and used in all the subsequent crawler visits.  \n\nThe works presented in [28, 121] exploit data from a breached Dark Web site called Nulled. $\\mathrm{IO}^{38}$ whose database is publicly available 39 and from which the authors extracted hacker forum posts. Starting from this database, the authors of [28] identified the posts that are most relevant to cybersecurity through the SVM algorithm and clustered the relevant posts into topics using Latent Dirichlet Allocation (LDA). The paper described in [114] performed an incremental crawling strategy bypassing the anti-crawling measures of hacker forums to collect attachments. Information was collected from 10 hacker forums, namely OpenSC, Garage4hackers, Hacksden, AntiOnline, Crackingzilla, WebCracking, SafeSkyHacks, Ashiyane, Hack, and Haker. They leveraged the internet forum software package vBulletin40 and allowed users to embed attachments directly into their posts that can be freely accessed. All traffic is routed through Tor, thus ensuring anonymity. After the connection to Tor is successfully established, the Python crawler begins an automatic search for attachments, performing a Depth-First Search (DFS) approach for collection. This means that the crawler starts with one subforum and crawls each topic and posts within that subforum before moving on to the next subforum.  \n\nTavabi et al. [115] examined the dynamic patterns of discussion and identified forums with similar patterns among 80 hacker forums in the Dark and Deep Web. To do so, they exploited an already existing crawler infrastructure presented in [122]. As classically done by Dark and Deep Web crawlers, it uses anonymization protocols, such as Tor and I2P, and handles authentication to access non-indexed sites. Similarly to the previous research, the works presented in [123, 124, 125, 113] leverage the same infrastructure for crawling the Dark Web and Deep Web introduced by [122]. The authors of [123] created a custom crawler and several parsers for over 200 sites relating to malicious hacking. Instead, the paper presented in [124] deals with an approach to predict the posts on hacking forums. They formulated this problem as a sequential rule-mining task, where the goal is to discover hackers’ posting rules through sequences of peers’ posts to make future predictions.  \n\nThe authors of [113] implemented DARKMENTION, a system that retrieves information from both marketplaces where users sell information regarding vulnerabilities or exploits, and forums providing discussions about discovered vulnerabilities. They leveraged an already existing architecture introduced in [122] that includes customized crawlers and parsers built for each site and collects data from more than 400 platforms (both forums and marketplaces). To ensure the collection of cybersecurity-relevant data, they adopted ML models, and the filtering phase is performed by querying the CVE IDs in the NVD database using API calls. Regular expressions are used to identify CVE mentions in the Dark Web pages. The authors of [116] realized a custom Tor-routed Web spider to crawl and download all HTML pages of a popular hacker forum. The Web spider leverages a breadth-first search strategy and a specialized Python program using regular expressions to parse all data into a local relational database. The obtained dataset with 32, 766 posts (i.e., threats) made by 8, 429 hackers that span a 23-year period is publicly available online41. The work presented in [126] uses Dark Web data supplied by a threat intelligence company and accessed via APIs. The data is comprised of forum discussions and marketplace items offered for sale. Moreover, ML models are employed to filter out the data related to drugs, weapons, and so forth and ensure the collection of only cybersecurity-relevant data.  \n\nDifferently from the papers above, which mainly gather data from hacker forums, the works presented in [127, 112, 54] focus on threat identification in Dark Net Marketplaces (DNMs). For all these works, the markets’ identification is performed through deepdotweb.com, a Dark Net news Web site. For [127], 7 English marketplaces and 1 Russian are identified, whereas for [112], the selected marketplaces are Valhalla, Dream Market, Hansa, Alphabay, Minerva,  \n\nSilkRoad3, and Apple Market. A custom Web crawler is developed to traverse the onion links in a breadth-first manner. To avoid anti-crawling measures in dark net marketplaces, it implements several techniques, and it is also capable of waiting for a user’s response to access CAPTCHA-protected content. Moreover, Adewopo et al. [54] collected data from two Dark Net Markets (Silkroad and Wall Street) extracted from the Arizona State University database[110]. The data set contains over 128, 000 posts from different discussion threads. The thread titles are related to Carding, Newbie, Scam, Hacking, and Review threads.  \n\nThe authors of [118, 49, 110] performed a crawling from multiple sources. As for [118], the different sources are: (i) 3 major DNFs (providing 204, 001 threads and 14, 196 authors); (ii) 5 largest DNMs (providing 224, 270 product listings and 7, 911 vendors); and (iii) the two largest exploit databases, such as Exploit DB and 0day.today (providing 43, 678 exploit listings). The data-gathering process starts by creating an initial list of potential sites based on factors such as the number of listings, discussion threads, threat actors, and the number of listings related to cyber threats found on each site. Subsequently, several Python-based Web crawlers are designed and deployed to collect data from each of these Web sites. The authors’ aim is to identify threats across major Dark Net data sources linking assets to threat actors, using text features and Social Network Analysis metrics. The work presented in [49] employed 11 traditional hacker forums (collected through a crawler routed via Tor), one exploit database specific for DNM (i.e., 0day.today), and several public exploit repositories collected through APIs, such as Seebug, ExploitDB, PacketStorm, Metasploit, Vulnerlab, and Zeroscience. Traditional hacker forums are crawled through a depth-first search strategy implemented for efficiency. This choice makes the process incremental as a growing database of previously crawled links and dates is kept for each Website to ensure links are not visited or scraped twice. The authors of [110] collected data from 51 DNFs, 12 DNMs, 13 IRC channels, and 26 carding shops. For the first step of the hacker forums identification, the authors used three approaches, namely: (i) suggestions from cybersecurity experts; they contacted both the National Cyber-Forensics Training Alliance (NCFTA), a major non-profit organization focusing on the CTI sharing and the Policing in Cyberspace (POLCYB), an internationally recognized law enforcement entity; (ii) Surface Web and Tor search engines, which are queried based on the platform names suggested by the groups of experts; (iii) snowball identification, the platforms previously identified are used as seeds for a further in-depth search. Several Web crawlers are developed to collect the raw data in HTML format for forums, DNMs, and carding shops. For IRC data, they employ two bots, emulating fake users, inside each channel.  \n\nAuthors of [128] connect the Dark Net through TOR (using Polipo and Vidalia proxies) to collect information on eight large DNMs in the Dark Net, including Dream Market, Berlusconi Market, etc. The technology used to crawl and parse the Web page is the Scrapy framework42. After this step, the authors designed a custom parser for each marketplace to collect important information from cybersecurity-related categories. Moreover, some studies focus on identifying key hackers in Internet Relay Chat (IRC) channels, like the paper in [129], which describes an autonomic personality analysis based on author identification in IRC conversations. Using the IRC chat logs collected through autonomic IRC bots in various cybersecurity, underground channels, and general channels (computer and politics), the authors analyze them with the Exploiting IBM Watson Personality Insights to demonstrate that the personality-based solution can work effectively in user identification. Similarly, the work presented in [125] deals with key hackers’ identification exploiting a hybrid approach that combines content, Social Network, and seniority analysis. In this work, the authors collected data provided by a commercial version of the system described in [122], from which they selected three popular English hacker forums on the Dark Web. The papers presented in [50, 35] rely on an external threat intelligence platform for the Dark Web, called Sixgill43, to collect hacker activity and Social Network information; then, they analyze the organizational hierarchies.  \n\nTable 8 summarizes, for each analyzed paper, the technology used to crawl content in the Dark/Deep Web, the collected sample size, and the type of resource collected (i.e., DNF, DNM, IRC channel, carding shops, and so forth).  \n\n7 NLP-Based Techniques for Threat Intelligence Analysis  \n\nAs the manual analysis of all the sources of CTI (i.e., Clear Web, Social Networks, and Dark/Deep Web) is timeconsuming, inefficient, and prone to errors, several solutions to, even partially automatize the utilization of CTI information have been proposed in the literature. In this section, we aim to analyze such approaches by focusing on the NLP techniques exploited, such as text classification, text clustering, topic detection, and trend analysis.  \n\nTable 8: Crawling from Dark/Deep Web   \n\nPaperTechnologySampleSizeAlmukaynizi et al. [113]Custom crawler byNunes et al. [122]400 platformsTavabi et al. [115]Custom crawlerbyNuneset al.[122]80 DNFsTavabi et al. [123]Custom crawler by Nunes et al.[122]200hacker sitesMarin et al. [125]Custom crawler by Nunes et al. [122]3DNFsMarin et al. [124]Custom crawler by Nunes et al.[122]1 DNFDeliu et al. [28]Database onlineNulled.IO platformSuryotrisongko et al. [121]Database onlineNulled.IO platformNunes et al. [126]Data supplied by a threat intelligence company302WebsiteWilliams et al. [114]Python custom crawler10 DNFsTavabi et al. [115]Python custom crawler80 DNFsSamtani et al. [116]Custom crawler1 DNFSamtaniet al.[119]Customcrawler1 DNFBenjamin et al. [111]Custom crawler4 DNFsHuang et al. [120] ArnoldandSamtani[118]Custom crawler5DNFAmpel et al. [49]Python customcrawlers3 DNFs,5DNMs,2 exploit databasesEbrahimi et al. [127]Custom crawlers11 DNFs,1 exploit database for DNM, 6 public repositoriesEbrahimi et al. [112]Custom crawler8 DNMsDong et al. [128]Custom crawler7 DNMsAdewopo et al. [54]Scrapyframework8DNMsShao et al. [129]ArizonaStateUniversity database[110]2 DNMsDu et al. [110]CustomIRCbot6IRCchannelsKadoguchi et al. [50]Custom crawler,Automatic bot51 DNFs,12 DNMs,13 IRC channels and 26 Carding ShopsKadoguchi et al. [35]Sixgillplatform3000 posts from DNFsSixgillplatform1700 posts from DNFs  \n\n7.1 Text Classification  \n\nText classification is one of the main tasks in the NLP field, whose objective is to categorize textual documents according to their content. Another popular application of text classification is sentiment analysis. Sentiment analysis tries to predict whether the sentiment expressed in a target text is either positive or negative. Text classification can be binary, as it happens for sentiment analysis or multi-class. In this case, each class is characterized by specific features present in the corpus of the text. Due to its supervised nature, text classification requires the assignment of a label to each sample in the training set, thus allowing the classifier to learn the characteristics of the different classes. To perform a classification task, any classifier needs a numerical representation of the text as input. In Table 4, we presented the most popular and effective solutions for text representation, spanning from statistical approaches, such as BoW, TF-IDF, and GloVe, to DL models, e.g., Word2Vec. The obtained representation can be used as input to traditional ML algorithms or more advanced neural networks like Convolutional or Recurrent Neural Networks on top of a classification layer.  \n\nRecently, transformer-based solutions, like BERT (see Section 5.3), have gained popularity due to their impressive results. Transformer-based approaches exploit an encoder module to generate a context-accurate representation of the text, thanks to the attention system, which can, hence, be provided in input to a classification head. Text classification using the above-mentioned technologies is employed in many CTI tasks. In the following, we analyze the main applications of text classification for CTI to (i) Social Media and (ii) CTI Reports.  \n\nSocial Media: In [28], the authors build a binary classifier that detects security-relevant or irrelevant posts in a hacker forum. To do so, they used an SVM classifier, achieving an accuracy of $98.82\\%$ on the task. Similarly, the authors of [30] presented a Convolutional Neural Network (CNN, for short) model to perform the same binary classification task between security-relevant and irrelevant tweets. Then, if a post is classified as relevant, a second CNN is used to classify the post between 8 classes namely: vulnerability, DDoS, data leak, ransomware, 0-day, and marketing/general. The final performance of the two models is $94.72\\%$ on the binary task and $87.56\\%$ on the multi-class. In [130, 96], the authors proposed a Twitter-based streaming threat monitor on a specific infrastructure that classifies whether the tweet is relevant or not for CTI. In the same way, the strategy proposed by [53] uses a TF-IDF representation technique combined with two possible ML algorithms, namely Centroid classifier and SVM, to predict the relevance of the anomaly reported in the post achieving an F1 score of the $64.3\\%$ . Hackers forums represent a rich source of data; for this reason, in [49], the authors use a C-BiLSTM neural network to perform a multi-class classification finalized to predict the label of different types of attack. In [29], the authors collected threat description data from different blogs to build a CTI domain recognizer that uses a combination of Word2Vec representation and a CNN classifier. The authors of [54] exploited data from Twitter and a hacker forum to build a logistic regression model combined with a TF-IDF representation finalized to predict the relevance of the post for security monitoring. The strategy proposed by the authors of [51] is composed of a combination of pre-trained embeddings generated by Word2Vec or GloVe and a CNN to perform a binary classification of tweets related to IT infrastructures, according to the relevance of the security-related information contained. Similarly, in [59], the authors proposed an approach to identify features, classifiers, and practices that provide the best possible detection performance for software-vulnerability-related communication in online social media channels. In particular, the strategy exploits a combination of representations obtained with Word2Vec and an SVM classifier. In [50], instead of using the representation of single words, the authors employed doc2Vec for the representation of an entire document. The results are used as input to an MLP network to extract posts that contain important information and to design proper countermeasures to the predicted attack. In [131], the authors considered informal text about ransomware from forum threads. Hence, they employed well-known algorithms like SVM, Random Forest, and Naive Bayes to detect important entities and conduct analyses. The authors of [128] developed a framework to classify cyber threats in the context of marketplaces in the darknet. To do so, after testing several strategies, including Naive Bayes and MLP classifier, the authors exploited an SVM classifier in their solution. The terminology used in forums can be used to estimate the expertise of a hacker. In this sense, the authors of [60] proposed a hacker-expertise predictor that exploits features of the text, such as TF-IDF scores of the keywords, in combination with classification algorithms, i.e., KNN and regression trees.  \n\nCTI Reports: In [36], the authors classified CTI reports according to the type of threat. To do so, they used different ML algorithms, like KNN, SVM, or decision trees, achieving performance around $80\\%$ . Another paper that analyzes CTI reports is presented in [72]. Here, the authors proposed a trigger-enhanced CTI (TriCTI) discovery system, which aims to automatically discover actionable CTI. In particular, they used a fine-tuned BERT with an elaborate design to generate triggers. The trigger vector is further trained according to the similarity with the sentence containing it. Finally, a binary prediction is performed by exploiting similarity information. Analogously, in [132], the authors employed a BERT classifier to map TTPs to the MITRE ATT&CK framework. In detail, after conducting a brief hyperparameter search, the authors used the MITRE dataset to fine-tune different BERT models. As an additional contribution, they compared the performance of such BERT models with a standard approach using TF-IDF and linear regression. The BERT-based models obtain an accuracy of around $80\\%$ compared to the $61\\%$ accuracy of the traditional strategy. In [86], the authors compared different classifiers to predict the CTI class for an unseen cyber threat incident. In particular, they considered Naïve Bayes, K-Nearest Neighbors (KNN), decision tree, and deep learning neural networks. The authors of [61] proposed a threat action extraction strategy through multi-label classification. In particular, they selected ATT&CK as a threat action taxonomy and TF-IDF as a feature. Such information is then used as input to state-of-the-art classifiers. In the same way, [62] proposed an ML model for threat report categorization. The proposed solution generalizes across reports using a combination of TF-IDF and a variety of classifiers. In [63], the authors consider the classification of bug reports similar to the descriptions of vulnerability classes from CWEs. In particular, the authors evaluated supervised and unsupervised strategies on data extracted from issue-tracking systems of two NASA missions. The proposed approach concatenates the title, the subject, and the description of each bug report and processes them through TF-IDF and a classification algorithm. The authors of [133] proposed a framework named ChainSmith, which aims at automatically extracting IoCs and their corresponding campaign stages from technical documents. To do so, they consider the most informative words according to their occurrence in the sentence, and then, these features are used to train four neural network binary classifiers that predict topic probabilities.  \n\n  \nFigure 5: General classification procedure  \n\n7.2 Text Similarity and Clustering  \n\nThe representation techniques described in Section 5.2, as we saw in the previous section, illustrate how pre-trained embeddings can be used as input to a classifier. An important characteristic of these representations is the intrinsic relation encoded in the vector representation of similar words. This specific aspect can be exploited to calculate a similarity score between words using distance metrics like cosine similarity. The application of this is particularly useful for dividing a set of data into clusters, giving the obtained vectors to unsupervised clustering algorithms. An example of this is described in the TOM approach presented in [55]. In particular, the authors proposed two clustering methods: $(i)$ a semi-supervised matrix decomposition-based method, and $(i i)$ an unsupervised term frequency-based method. The first method generates a term-malware mapping matrix from the Threat Expert reports by using the TF-IDF representation technique. The second method determines the name of the clusters based on string distances, and the malware with similar names is considered a cluster using the K-means algorithm. In the strategy presented by [134], the authors proposed an approach that improves the OSINT processing by correlating and combining IoCs coming from different feeds. In [130, 96], authors performed clustering by the $\\mathbf{k}\\cdot$ -means algorithm as an aggregator of the outcome of the classifiers of tweets at the previous step of the pipeline of the approach. After the clustering, it is easier to transform unstructured data, like from social media, to standard formats, such as STIX. Similarly, in [56], the authors proposed a framework called CTI-Twitter, which applies a clustering strategy to the outcomes of the classes from a multi-class classifier. The idea is to detect inside each class the groups of semantically similar tweets to help the analysts detect trending keywords. In particular, the authors proposed two text clustering methods to group semantically similar tweets: $\\boldsymbol{\\mathrm{k}}$ -means with TF-IDF and Sentence Transformer embeddings and LDA. Analogously, the authors of [76] used the representation of tweets produced by the TF-IDF in combination with the DBSCAN algorithm to cluster tweets in potential novel events. The proposed strategy uses clustering to aggregate all tweet texts in a cluster into a single corpus. Then, they performed the named entity recognition process to detect the keywords. In the proposed paper [57], the authors exploited the clustering of data from different Dark Web sources to find similar contents. The clustering process has been performed through a combination of TF-IDF and K-means algorithms to find similarities between HTML pages and detect the top-k keywords. In a similar way, the authors of [102] presented a cybersecurity event discovery and evolution detection framework based on continuous tweet streams called CyberEM. In particular, the proposed framework consists of three components: pattern clustering, NMF-based event aggregation, and dynamic event inference. Focusing on the pattern recognition component, the objective is to detect the k clusters of the cybersecurity events to remove tweets that talk about cyber attacks in general. To do so, they employed Kullback Leibler divergence. The idea behind the approach is to detect the terms with higher KL-divergence following the institution that these terms are more informative in target domain-related tweets. In [135], the authors presented a framework called EIGER with the intent of clustering similar artifacts created by malware of the same family. The clustering strategy employs Levenshtein distance to calculate the similarity between the abstracts where the ones with the closest distance are merged sequentially. The authors of [136] formalized the threat-hunting problem from CTI reports and IoC descriptions and, in particular, used a best-effort Similarity search. The authors of [61] used TF-IDF representations to calculate semantic similarities of reports with the considered topics and actions of a threat-related article.  \n\n  \nFigure 6: General clustering procedure  \n\n7.3 Text Mining and Open Information Extraction  \n\nApplying Open Information Extraction (OIE, hereafter) to CTI involves using Text Mining and NLP techniques to automatically extract relevant and valuable information about cyber threats, attack patterns, vulnerabilities, and related entities from unstructured text sources without prior knowledge or supervision.  \n\nIn [137], the authors described Open-CyKG, a framework for extracting information from unstructured Advanced Persistent Threat (APT) reports and representing the retrieved data in a knowledge graph that offers efficient querying and retrieval of threat-related information. One module of this system consists of a neural attention-based OIE model to extract relation triples from unstructured APT reports. This model takes the concatenation of all inputs and passes it to two Bidirectional Gated Recurrent Units (Bi-GRU) layers, followed by an attention layer, two Time Distributed Dense (TDD) layers, and finally, a SoftMax layer for prediction. The work proposed in [93] develops a system leveraging both a self-attention deep neural network (SA-DNN) model and a text mining approach to identify the vulnerability category from the description text contained within a report. Similarly, the proposal of [26] aims at extracting features from unstructured CTI reports and attributing them to cyber-threat actors. Detailed feature sets, i.e., TTP, tools, malware, target organization, country, and application, have been used. Moreover, in this work, the authors proposed a novel embedding model called attack2vec to extract features from unstructured CTI reports. This novel model achieves accuracy, precision, recall, and F1-score of $96\\%$ , $96.5\\%$ , $95.58\\%$ , and $95.75\\%$ , respectively.  \n\nThe paper presented in [138] deals with the design of software for the automatic extraction of actionable threat intelligence from raw log data. The authors employed anomaly detection to disclose unknown attacks, and they pursued the iterative clustering and enrichment of anomalies with optional human verification with the purpose of transforming low-level log events into complex attack patterns. In this framework, every anomaly is primarily defined by the feature that triggered the detection mechanism. Then, the anomaly is transformed into an alert with enriched attributes storing contextual data as well as event and execution information. Finally, they eventually generate clusters of alarms that frequently occur together.  \n\n7.4 Cross-Lingual Threat Intelligence  \n\nCyber threat actors operate on a global scale, and many of them communicate in languages other than English. To comprehensively understand and combat cyber threats, it is essential to monitor and analyze threats originating from communities with different languages. However, while text classification techniques have been mainly used for cyber threat detection in English platforms, this task is hindered in non-English ones due to the language barrier and lack of ground-truth data. Recent approaches usually filter out non-English data or make an automatic English translation to leverage monolingual models and overcome this issue. For instance, in all the works based on a Twitter crawler, the authors usually start the search with an English keyword or set a condition on the preferred language of the post or its country of origin (i.e., “lang: en”). In a popular work of Samtani et al. [139], Russian data was machine-translated to English using Google Translate. However, translation errors can deteriorate the classification results, and on the other hand, training separate monolingual models on low-resource non-English languages is impracticable.  \n\nFor the above reasons, the authors of [140] demonstrated that their deep cross-lingual model can jointly learn the common language representation from two languages (namely, English and Russian), and it outperforms a monolingual model trained through machine-translated data for identifying cyber threats in non-English DNMs. They randomly sampled the product descriptions in each language by preserving the ratio of cyber to non-cyber products, and then the manual labeling step as cyber threats or non-threats was performed by cybersecurity experts and a Russian speaker. Moreover, the CL-LSTM (CrossLingual LSTM) algorithm leverages BiLSTM to jointly learn the common hacker language representation from English and Russian DNMs. The authors of [141] collected data from an English forum, a Russian forum, and two French forums and designed A-CLKT, an adversarial learning procedure that learns language invariant representations across two languages automatically. In the first phase of automated text representation, A-CLKT reserves an LSTM for each language to automatically create an embedding of hacker forum text. In the second phase, the authors leveraged a GAN to devise a novel adversarial learning strategy to operate on the English and non-English representations. Finally, a classification step is performed to classify the text as a threat or non-threat.  \n\nThe work presented in [142] collects data from Twitter both in English and in Russian, exploiting Twitter API language capabilities to detect language through the related flag (en $\\qquad=$ English, ru=Russian). Through two lexical databases, Wordnet44 and Russnet45, the authors created relationships between the two languages’ cybersecurity words and align them in vector embeddings. Then, an LSTM-based neural machine translation architecture is used to translate cybersecurity text from Russian to English. Finally, the work by Wu et al. [90] adopted a Language Technology Platform (LTP [143]) that is an integrated Chinese language processing platform that includes a suite of high-performance NLP modules and relevant Chinese corpora.  \n\n7.5 Topic Detection and Trend Analysis  \n\nTopic modeling is an unsupervised ML technique used to automatically identify topics in a collection of text documents and discover patterns in groups of words or documents that are semantically similar. Two of the most commonly used algorithms for topic modeling are Non-negative Matrix Factorization (NMF) and LDA [144]. NMF is a statistical method that aims to reduce the dimension of the input corpora, using the factor analysis method to provide comparatively less importance to the words with less coherence. LDA, instead, computes the posterior probability of the distributions of topics per document and the distribution of words per topic. These estimations are presented as matrices and used to infer two outputs, (i) the dominant topic per document and $(i)$ an ordered list of words that constitute that topic. The works that base their topic modeling approach in LDA are the following [28, 93]. Specifically, the authors of [28] applied LDA after using SVM to remove irrelevant posts to extract ten topics. The interpretation of each topic’s meaning is based on reviewing its top documents(posts) by human operators. The extracted topics deal with leaked credentials, malicious proxies, undetected malware, and asset-specific CTI. The work by Vishnu et al. [93] performs topic modeling on a 13-class categorization problem using the LDA method to discover the topic trends within the dataset for the various CVE categories. In particular, summarized vulnerability descriptions are converted to a document-term matrix and given to the LDA model to create the topic model. The model produced ten topics, from which the authors manually selected the most suitable to describe each vulnerability category.  \n\nAs seen before, the topic generated by LDA may not be meaningful to a user. Hence, the authors of [145] apply to CTI the algorithm SeededLDA proposed by Jagarlamudi et al. [146], which allows a user to give additional information to the topic model in order to learn topics of specific interest to a user. In SeededLDA, a user provides seed sets according to the state and the environment of the organization (i.e., IoT or Financial Industry) to guide the topics together with security blog posts.  \n\nThe paper by Hossen et al. [147] utilizes both LDA and another popular algorithm for topic modeling: Non-negative Matrix Factorization (NMF). They collect and analyze data from a well-known hacker forum for the purpose of identifying and classifying possible CTI. The paper described in [30] leverages topic modeling as the preliminary step of manual annotation of tweets to speed up and increase the accuracy of the whole process. The topic modeling API of  \n\nTable 9: Tool/Technique for Topic modeling   \n\nPaperTool/TechniqueforTopicModelingDeliu etal.[28]LDAVishnu et al.[93]LDAHossen et al.[147]LDAandNMFNagai et al.[145]SeededLDABehzadanetal.[30] Liet al. [58]WatsonNatural LanguageUnderstatingservice[103] ITFIDF-LPSuryotrisongkoet al.[121]BERTopicandTop2VecVahedietal.[109]BERT-LDASleemansetal.[150]DTM  \n\nIBM’s Watson Natural Language Understating service [103] is used to recollect text classification into five categories connected to cybersecurity for the textual contents of each tweet. The text category assignment was restricted to the top three categories with the highest confidence score.  \n\nThe approach proposed in [58] describes an improved keyword feature extraction method, namely the ITFIDF-LP (Incremental TF-IDF method considering word location and part of speech) method. In particular, this strategy considers keyword identification tools, whether a word is a stop word, its position in the article, and which part of speech this word represents.  \n\nGiven the limitations of prevailing topic models, several works developed custom approaches based on LDA [121, 109]. More recent topic modeling approaches (namely, BERTopic and Top2Vec) are leveraged by [121]. BERTopic relies on pre-trained transformer-based language models to compute document embedding, cluster these embeddings, and generate topics with the class-based TF-IDF (Term Frequency–Inverse Document Frequency) procedure [148]. Top2Vec is a new topic modeling and semantic search algorithm that creates embedded document/word vectors, makes lower dimensional embedding, finds dense areas of documents, calculates the centroid, and finally finds the closest word vectors [149].  \n\nTo categorize long and contiguous text (e.g., pastes), the authors of [109] incorporate BERT into LDA, proposing the BERT-LDA framework. It consists of three main components, namely (i) BERT’s encoder that tokenizes each word in each sequence (sentence) for every input paste; (ii) BoL model (produced by BERT) replacing the traditional BoW in the conventional LDA model captures information at about each paste’s semantics at the sequence-level, rather than at the word-level; and (iii) Topic Generation using LDA produces topics based on each paste’s BoL. The proposed BERT-LDA model was applied to all pastes gathered from Pastebin, PasteFS, and Pastelink platforms. The authors manually assigned names to five prevailing topics extracted by the model (namely, hackers, malware, networks, Web sites, and PII) and checked the results by comparing them with the selected keywords.  \n\nThe authors of [150] used the Dynamic Topic Model (DTM, hereafter) to model multiple document collections over time. They exploit Wikipedia concepts related to cybersecurity as a context model for training the DTM to understand how the concepts found among documents are changing over time. The leveraged corpus belongs to arXiv Cryptography and Security research papers. An important contribution of this work is the automatic domain concept extraction using Wikipedia concepts. They captured 3,836 concepts from Wikipedia, exploiting them to establish the context for the topic modeling portion.  \n\nTable 9 summarizes, for each analyzed paper, the tool and/or the technique employed by the authors to perform topic modeling.  \n\n7.6 Text Summarization  \n\nText Summarization is often used to reduce the verbosity of a document or Web content and obtain a concise description of the attack behavior that can be directly used to detect the attack itself. Indeed, threat reports are usually characterized by a significant amount of complex and irrelevant text, and only a small portion of the report describes attack behavior. Although topic classification has been used to identify topic-related context among out-of-domain contexts (e.g., advertisement text versus technical text), they are not good enough to provide a description of observable attack actions discriminating among technical concepts. Moreover, inside each sentence, some parts of the speech, such as adverbial and adjectival, do not contribute to the behavior description of the attack, and that can be safely removed. To solve this issue and provide a good summary of CTI content, authors of [78] designed a two-step approach that consists of a BERT classifier, which deals with sentence verbosity, and a BiLSTM network, which deals with word verbosity. In particular, for the first step of sentence verbosity, they use a 12-hidden layer BERT to discern the productive sentences from the non-productive ones. To train the model, they used 8,000 labeled sentences. For removing the word verbosity, instead, understanding the words’ roles in the text summary is crucial, and for this reason, they used a re-implementation of a deep BiLSTM model [151]. Since this model was not fine-tuned to handle cybersecurity sentences, they trained the model using 3,000 manually labeled sentences. Similarly, the paper presented in [87] performed text summarization, adopting the BERT transformer model to perform word embedding and BiLSTM to extract threat entities.  \n\nThe authors of [152] proposed a lightweight scheme, called CVErizer, for summarizing CVE’s content, which consists of two steps: (i) information extraction and (i) classification of vulnerabilities. They observed that the most relevant information pieces usually contained in a CVE description are: the vulnerability name, the name and the version of the software affected by the vulnerability, the kind of attacker who could exploit the vulnerability, the mechanism used, and the effect. This recurrent pattern is then formalized in an XML file, and through a lightweight taxonomy, these vulnerabilities are categorized into different types, reaching an accuracy score of $81\\%$ . To monitor the cybersecurity events, Li et al. [84] summarised CTI text using TextRank, a graph-based ranking algorithm. This approach entails the transformation of natural language text into a graph, where individual sentences are considered as vertices, and connections are established based on sentence similarity. The similarity is determined by calculating the count of common tokens found in the lexical representations of two sentences and then dividing this count by a normalization factor. Sentences exhibiting greater connectivity to other vertices are accorded higher importance and are subsequently ranked, resulting in the extraction of pivotal sentences. Arranging these summaries chronologically using timestamps reveals the development of cybersecurity events.  \n\n8 NLP-Based Techniques for Relation Extraction  \n\nIn this section, we delve into research dedicated to extracting relationships from cybersecurity data. To perform relationship extraction, multiple researchers have pre-identified cybersecurity entities. Furthermore, certain studies have successfully identified cybersecurity events from these recognized entities and extracted valuable relationships. Additionally, we have reviewed various research works that center on the development of graphs using this extracted knowledge. The process of relationship extraction and constructing a Knowledge Graph (KG) from security text can significantly contribute to generating actionable CTI.  \n\n8.1 Named Entity Recognition  \n\nNamed Entity Recognition (NER) assists in recognizing entities(proper nouns) from the unstructured text and serves as a fundamental technique for tasks such as information retrieval, constructing knowledge bases, question answering, generating automatic text summaries, and providing semantic annotations. The named entities include real-world objects like persons, organizations, locations, dates, and other entities with proper names. NER holds a pivotal role in NLP by focusing on identifying and categorizing named entities within the text.  \n\nThere are general tools available, such as Spacy, Stanford NER, NLTK, Flair, etc., that can recognize generic entity types like locations, persons, organizations, and dates. However, these entities might not fulflil the specific demands of specialized domains like cybersecurity [153]. Cybersecurity requires the identification and classification of entities unique to the field, including malware types, operating systems, attack methods, and other terms specific to cybersecurity. Figure 7 displays a sample of cybersecurity text sourced from the MITRE Web site46, along with its corresponding entities. The significance of identifying and labeling these domain-specific entities becomes evident in various cybersecurity tasks. For instance, in the context of malware analysis, NER can pinpoint the types of malware within a text document [154], thus aiding analysts in comprehending the threat’s nature. In the classification of attacks and vulnerabilities, NER plays a role in identifying the precise types of attacks or vulnerabilities [77] mentioned in security reports or incident logs. Additionally, NER contributes to the creation of cybersecurity KG and structures that organize and present cybersecurity-related information systematically.  \n\n  \nFigure 7: Cybersecurity named entity  \n\n8.1.1 Annotation Strategy  \n\nRecently, NER has been predominantly executed through supervised learning classifiers that require labeled text as input. Since the rapidly evolving threat landscape is characterized by emerging attack mechanisms and the convergence of various attack and malware types, the imperative arises to develop customized NER datasets. In the NER task, each word of unstructured text is assigned a specific tag instead of assigning a label to an entire paragraph. Researchers have employed various tagging schemes and annotation tools for annotating this task.  \n\nTagging Schemes: Researchers explored tagging schemes, including BIO, IO, IOE, BIOES, BILOU, etc. Among these schemes, BIO and BIOES are extensively utilized in CTI.  \n\n• BIO or IOB: BIO stands for “Begin, Inside, Outside,\" also referred to as the IOB format. The B (Beginning) and I (Inside) tags are primarily employed to label relevant entities. The B index indicates the start of a specific entity instance, while the I index signifies the continuation of the particular entity. Additionally, an O tag is used to denote terms that exist outside of any entity context. For instance, consider the sentence extracted from the Bleeping Computer site: Major US energy organization targeted in QR code Phishing attack. In this example, US is tagged as B-Location, Energy is assigned with the B-Industry tag, QR is labeled as B-attack type, code as I-attack type, Phishing as I-attack type, and all other tokens are assigned the O tag. In studies [52, 155, 70, 69, 156, 157, 137, 158, 159, 160], researchers employed the BIO/ IOB tagging scheme for annotating the tokens as cybersecurity entities.   \n• BIOES: The BIOES scheme also employs BIO tags akin to the BIO approach but contains two additional tags: E and S. The E tag indicates the end of a specific entity, while the S tag is utilized for single-word entities. In the sentence, Major US energy organization targeted in QR code Phishing attack, US is designated as S-Location, Energy is assigned the S-Industry tag, QR is marked as B-attack type, code as I-attack type, Phishing as E-attack type, and all other tokens are labeled with the O-tag. Few researchers have adopted the BIOES tagging scheme in their studies [161, 43, 162].   \n• BIOFR: Traditional BIO tagging typically concentrates solely on identifying entities and doesn’t consider the sentence’s structure. In contrast, BIOFR [163], which stands for Begin (B), Inside (I), Outside (O), Front (F), and Rear (R), incorporates attention to words surrounding the entities. However, it’s worth noting that BIOFR does not regard nouns as responsible for threats or vulnerabilities; instead, it summarizes them using verbs. Take the sentence, “A stack out-of-bound error was flagged in · · ·.\" When we apply BIOER, we get tagged sentences like this: “A [F-B-Tri] stack [B-Tri] out-of-bound [I-Tri] error [I-Tri] was [R-B-Tri] flagged [R-I-Tri] · · ·.\"  \n\nAnnotation Tools: For expediting the manual annotation process, the researchers employed various annotation tools, including Prodigy, BRAT, YEDDA, Doccano, LightTag, etc. The BRAT Rapid Annotation Tool (BRAT) [164] serves as a Web-based text annotation mechanism primarily designed for NLP tasks, encompassing both entity and relation annotation. The authors [155, 70, 161, 160] opted for BRAT in their work. Prodigy [165], a commercial tool, supports not only text-based tasks like NER, dependency parsing, and part-of-speech tagging but also tasks for audio and video annotation and computer vision. Few works [153, 166] used Prodigy for annotating the text. YEDDA [167], on the other hand, is an open-source lightweight tool supporting command-line annotation. It supports languages such as English and Chinese and works with symbols and even emojis. YEDDA is adopted by Ren et al. [158] in their study. Further, Zhou et al. [69] employed YEDDA for annotating the Chinese security-related text.  \n\n8.1.2 NER Approaches  \n\nConventional Methods: Early research on NER relied on rule-based and statistical machine-learning models. Rulebased strategies hinged on rules crafted by domain experts, amalgamating gazetteers(curated lists of known entities), and syntactic-lexical patterns [168]. Hanks et al. [153] employed gazetteers to identify a range of entities, including protocols, malware types, programming languages, attack types, flie extensions, and operating systems. These gazetteers were constructed by querying data from Wikidata. Additionally, the authors employed regular expressions to detect indicators such as CVEs, ports, hashes, and IP addresses. For recognizing URLs and Email addresses, they utilized the Spacy tool. In [52], the authors adopted hybrid techniques, incorporating rule-based and DL-based methodologies to identify cyber entities effectively. Specifically, they extracted CVE IDs, commonly employed to denote vulnerabilities within software or products, using regular expressions and replacing them with the CVE tag. Further, in [70], Alam et al. adopted regular expressions to recognize indicators such as IPv4, CVE, SHA1, SHA256, Email, and File Path. On the other hand, statistical methods harnessed the power of ML algorithms such as Perceptron, Support Vector Machine (SVM), Hidden Markov Model (HMM), and Conditional Random Field (CRF). The most effective methods for NER often involve the utilization of CRFs. CRFs address the NER task by implementing a sequence labeling model, where the assignment of a label to an entity is intricately linked to the labels assigned to neighboring entities within a predetermined contextual window. However, nowadays, researchers are using DL classifiers instead of ML classifiers.  \n\nDeep Learning for NER: The traditional approaches involved meticulous manual intervention in creating rules and undertaking intricate feature engineering. Following the rise of deep learning, many researchers have embraced DLdriven techniques in their research on NER to circumvent the laborious task of feature engineering. Significantly, the transformer framework showcases remarkable efficacy across diverse NLP tasks with models like BERT. In [51, 169], authors explored BiLSTM with CRF for identifying cybersecurity entities. In the study [170], the authors employed LSTM recurrent neural networks, a domain-agnostic approach, in combination with a CRF method to extract entities within the cybersecurity domain. VIEM [77] used a NER mechanism to identify vulnerable software names and versions. The NER model developed by Bidirectional Recurrent Neural Network achieves $97.8\\%$ and $99.1\\%$ precision and recall, respectively. Furthermore, they employed a heuristic approach that incorporated dictionary lookups to rectify inaccuracies in the NER model. With the introduction of a gazetteer, the overall accuracy increased to $99.69\\%$ . In [171], Georgescu et al. developed an automated system aimed at serving as a semantic indexing solution to identify preexisting vulnerabilities within IoT environments. They created a domain ontology and crafted a NER model to conduct semantic text analysis. To train the NER model, they employed the Watson Knowledge Studio tool, which leverages a semi-supervised learning approach. Pingchuan et al. [169] generated word embedding vectors by simultaneously training the model and the word vectors with the help of one hot encoding. The study by Kim et al. [52] integrated character-level attributes through Bag-Of-Character representations and incorporated GloVe for word embedding. Their strategy encompassed using a BiLSTM model along with CRF to extract cybersecurity entities. Similarly, Gao et al. [159] adopted a BiLSTM-CRF architecture, which incorporates domain dictionary embedding and a multi-attention mechanism for enhanced performance. They constructed a list of 15,357 words for domain embedding by collecting information from security blogs, CVE, NVD, and Wikipedia. In [172], the authors employed a novel approach to identify entities in both English and Chinese text. This method leveraged a neural network, CNN BiLSTM CRF model, in conjunction with a Feature Template (FT). The FT serves to extract local contextual features, while CNN was employed to capture character-level feature sequences, and BiLSTM was used to create the global feature vector.  \n\nThe study in [42] assessed various DL-based NER algorithms across a wide spectrum of sentence types, encompassing concise and lengthy structures. They investigated both domain-independent Word2Vec embeddings and domain-specific Word2Vec embeddings (trained on a cybersecurity corpus). Their findings demonstrated that the utilization of domainspecific embeddings resulted in superior performance. Further, they pinpointed that the optimal choice for cyber NERs entails the fusion of BERT embeddings with Bidirectional LSTMs. In [161], Wang et al. introduced APTNER, a NER dataset comprising 21 entities derived from STIX 2.1. The authors evaluated multiple NER models and discovered that the BERT embedding-based BiLSTM model with CRF achieved the highest F1 score of $82.31\\%$ . In another study, Wang et al. [155] leveraged knowledge engineering to boost the performance of their NER model, which relied on a combination of BERT-embedded BiLSTM and CRF. The model built using knowledge engineering achieved an F1-score of $91.62\\%$ . Wang et al. [43] developed a NER model using a novel Neural Network Cell called GARU, which combines a Graph Neural Network and a Recurrent Neural Network. They concatenated diverse embedding dimensions such as character level, word level, POS, and dependency relation in the embedding layer. For word embedding, they used two methods: Word2Vec, trained on cybersecurity datasets [173], and PERT [174], a BERT-inspired auto-encoding model. They incorporated character-level features from character-based CNNs. Additionally, they created a module for detecting entity boundaries and predicting entity heads and tails. Sun et al. [79] employed supervised neural network approaches to extract and categorize 15 cybersecurity entities. Their approach commenced with the use of Stanford CoreNLP to segment sentences in articles based on punctuation marks. Subsequently, token segmentation was performed within those sentences. They combined word embeddings with feature embeddings and inputted them into a BiLSTM RNN. They conducted an evaluation and performance comparison of their entity recognition method with two approaches: one using LSTM with ELMo embeddings and the other with fine-tuned BERT embeddings. The neural network incorporating ELMo and BERT embeddings achieved exceptionally high accuracy levels, reaching $99.8\\%$ and $99.2\\%$ , respectively. In [38], various fine-tuned models, including BERT, RoBERTa, ELECTRA, and DeBERTa, were utilized to perform NER and extract IoCs. Token annotation followed the CoNLL- $\\cdot2003^{47}$ structure, and IoCs were extracted from sentences based on predefined rules for 16 entities using the pyparsing48 module. When evaluating model performance, the fine-tuned DeBERTa model demonstrated superior results compared to the other models. However, in practical case studies, it was observed that the ELECTRA model effectively identified new IoCs.  \n\nThe enhancement of the identification and categorization of cybersecurity-related terms is the aim of Liu et al. who proposed a semantic augmentation approach in [175]. Their approach consists of three primary elements: internal domain augmentation, external general augmentation, and mixed linguistic features. Internal domain augmentation enriches the meaning of input words by incorporating insights from the K most similar words within the cybersecurity domain. Additionally, they fine-tuned the BERT model and utilized the resultant token representations for external general augmentation. Moreover, they generated a composite set of linguistic features, encompassing elements such as POS, morphology, and other component-related features. In [162], Yang et al. underlined the significance of improving word information in the context of Chinese cybersecurity NER. They have introduced a novel model called Star-HGCN, in which the hybrid embedding layer enriches word information by integrating character-level data and POS embeddings. In this model, the Star-Transformer layer adeptly captures implicit semantic connections among words in a sentence, while the GCN layer is applied to model explicit syntactic dependencies, drawing from dependency tree structures. In the decoding phase, a CRF is employed to carry out sequence labeling for sentences.  \n\nAlam et al. [70] developed an open-source toolkit named CyNER to extract cybersecurity-related entities from unstructured text. To accomplish this, they combined various methods: transformer-based models for identifying cyber entities, heuristic techniques like regular expressions for indicators, and established models like Spacy and Flair for general entities such as locations and persons. They gathered 60 threat reports from MITRE ATT&CK to generate a benchmark dataset. Using the BRAT annotation tool, they labeled the dataset with different types of entities, including vulnerabilities, organizations, systems, indicators, and malware. The transformer-based model, specifically XLM using RoBERTa large, achieved an F1 score of $76.66\\%$ on this task. Most research in NER relies on labeled data, but in cybersecurity, such data is scarce. So, In [176], the authors introduced an approach that combines a Generative Adversarial Network (GAN) with the BiLSTM Attention CRF model to acquire labeled data from crowd annotations. The GAN is utilized to identify shared features within crowd annotations, which are then integrated, with domain dictionary features and sentence dependency features, into the BiLSTM-Attention-CRF model. This integration is aimed at enhancing the quality of crowdsourced annotations. Similarly, In [177], the authors proposed an adversarial active learning approach for cybersecurity NER. They employed a BiLSTM layer to encode word embeddings and then utilized an additional LSTM layer to decode hidden representations obtained from the dynamic attention layer. More specific information about the representative work on neural network-based NER is included in Table 10. The table lists the different data sources the researchers employed as well as the embedding technique they applied.  \n\n8.1.3 NER Corpus  \n\nGenerating actionable threat intelligence through DL-based NER necessitates labeled data. Based on different tagging schemes and annotation tools, researchers invest significant effort in annotating security reports to create an NER corpus. Researchers defined different entity types according to their specific threat intelligence objectives. Few research works explain how they conducted and validated the annotation. In the study by Kim et al. [52], the annotation was carried out by five cybersecurity experts who were assigned text segments ranging from 1500 to 5000 lines. In another study [161], the authors enlisted the assistance of 30 undergraduates and four graduate students to label security-related text and verify the labeling process. Another study [155] involved three graduate students for cross-verification of the annotated data.  \n\nTo evaluate the quality of the annotation, Hanks et al. [153] conducted an inter-annotator agreement assessment. Notably, during the initial round of annotation, the authors found that less than $50\\%$ of the annotations reached a consensus. The primary source of disagreement stemmed from varying interpretations of entities, such as distinguishing between software names and tools or products. For instance, when encountering a term like Microsoft Word, some annotators treated Microsoft and Word as separate entities, classifying Microsoft as an organization and Word as a software name. In contrast, other annotators regarded Microsoft Word as a single entity and categorized it as a software name. To address these disagreements, the authors conducted a subsequent round of annotation. They provided additional training to annotators and redefined entity categories, merging certain entities into a single type.  \n\nIn the majority of NER studies, researchers create NER corpora, but few of them choose to share these valuable resources with the public. Wang et al. [180] have contributed a cybersecurity NER dataset in which they gathered threat reports from various sources such as GitHub, government agencies, and security companies’ Web sites. In the DNRTI dataset, they meticulously annotated 13 categories, including features, vulnerabilities, methods, organizations, industries, geographical areas, motives, timestamps, tools, security teams, sample files, attack types, and hacker organizations. Their annotation process employed the BRAT and utilized the widely accepted BIO labeling mode. However, the description of how they validated the quality of the annotations is not provided in sufficient detail. Table 11 lists the publicly accessible NER corpus.  \n\n8.2 Event Identification  \n\nTo respond rapidly to potential cyber threats, security analysts and IT personnel must stay informed about critical security events, regardless of their frequency of reporting. Given the rising number of cybersecurity incidents reported in articles, the capability to identify these events becomes a critical necessity. In NLP, event detection revolves around the discovery of details concerning entities within events, their respective functions, and the temporal and spatial attributes associated with these events. Event extraction is the process of extracting semantic and structural information from text, represented through typed phrases comprising trigger words and associated arguments [181]. It generally encompasses two primary sub-tasks: type classification, responsible for identifying specific event types within sentences, and element extraction, which captures trigger words and related arguments following diverse role patterns (schemas) to ensure comprehensive semantic understanding. When extracting events from the text, such as in the sentence “Russian cybercriminals breached the International Criminal Court’s IT systems amid an ongoing probe into Russian war crimes committed in Ukraine,\" we can analyze both the event type and trigger words. In this context, the term “breached\" serves as a trigger word, indicating an unauthorized intrusion or access to the IT systems of the International Criminal Court. This event is classified as a “Attack.Databreach\" due to its involvement in compromising or accessing sensitive data, which is a defining characteristic of data breach attack.  \n\nTable 10: Research work on neural network-based named entity recognition   \n\nPaperData SourceEntitiesTagging SchemeNLP TechniqueResultRemarksDionisio et al. [51]TwitterOrganization, product or as- set, version number, vulnera- bility, IDEntity label +0GloVe, Word2VecBiLSTM - 92% (Average F1 score)Number of entity type is lessPingchuan et al. [169]Lal et al. dataset [178]Software, modifier, OS, con- sequences,attack,means,fletag BIONMBiLSTM+CRF-89.38%(F1 score)Lowfl score for hardware and network typesKim et al. [52]PDF documentsname,network,hardware Main entities: Malware,IP, Hash,Domain/URL,Total 20 sub-entitiesBIOBag-Of- CharacterBOC+BiLSTM+CRF 75.05(F1 score)CVE achieves 100%performance and .url.normal, url.unknown, mal- ware.unknown, exhibit high differencesGao et al. [159]NER: Bridges et al. dataset [179], Domain dictionary: Wikipedia,Application, version, hard- ware, OS,file,vendor, edi- tionNMDomain dictionaryBiLSTM+Dict+Att+CRF 88.36%(F1 score)in precision and recall. Lowest performance on hardware and editionDasgupta et al. [42]CVE&NVD,blog Microsoft security bul- letin, Adobe securitySTIX 2.0+Exploit-TargetNMembedding(N- gram feature) Word2Vec, BERTBERT+BiLSTM+CRF 88.60%(F1 score)Trainedon dataset withvarying text lengths and complexity.Wang et al. [161]updates, NVD Twitter, Technical reports, CVE APT reportsAPT,SECTEAM,IDTY,OS, EMAIL,LOC,TIME,IP, DOM,URL,PROT,FILE,BIOESELMo,BERTBERT+BiLSTM+CRF 82.31%(F1 score)Generated a publicly available NER datasetWang et al. [155]Twitter, Blogs, Forums, Cybersecurity com- pany sitesTOOL,MD5,SHA1,SHA2, MAL,ENCR,VULNAME, VULID,ACTION Hacker groups, sample files, malicious samples, security teams, attack time, tool, country, industry, organiza- tion, user, methods, vulner-BIOWord2Vec, GloVe，ELMO, GPT,BERTBERT+ BiLSTM+CRF+ Knowledge engineering 91.62%(F1 score)Performance of vulnerability recognition increased by the Knowledge EngineeringWang et al. [43]Bridges et al. dataset [179], Open- Cyber: APT reports,ability, mode of transmission, file type, alias OpenCyber: Threat actor, Attack pattern, Vulnerabil- ity,Software,Malware,Cam- paign, Indicator, Course ofBIOESWord2Vec, PERTPERT based FIEBD: Bridges et al.-94.56% OpenCyber - 87.34%(F1 score)Predicted entity boundaries(start and end points)Alam et al. [70]CVE, security bulletins MITREATT&CKaction,Tool Malware,indicator, system, organization, vulnerability, email, URL, file path, hash, CVE, generic entity types ofBIOBERTXLM+RoBERTa Large 76.66%(F1 score)Developed CyNER python librarySun et al. [79]Security news article, vulnerability database, Twitterspacy and flair organization,person,device, product, Web site, capability, file,malware,money, num- ber, purpose geopolitical en-BIOPOS, ELMo, BERTELMO + BiLSTM RNN - 99.8%(F1 score)ELMO embedding better thanBERTLi et al. [177]APT report, CVE, secu- rity news, blogstity (GPE), time, CVE, vul- nerability,version organization,location, soft- ware,malware,ndicator, vul nerability, course-of-action,NMWord2VecDynamic-att+ BiLSTM+ LSTM -45% sample achievesAdversariallearningtoreducelabeling effortDong et al [77]CVE,vulnerability re- porttool, attack-pattern, ，cam- paign vulnerable software name and versionEntitySkip-gram88.27% (F1 score) Bidirectional RNN andExtractedvulnerablesoftware name andQin et al. [172]WooYunvulnerability database and FreebufVUL ID,network relevant term, software,organization,label+ O tag BIOWord2Vec0.978(precision) 0.991(recall) FT+CNN+BiLSTM+CRF 86%(F1 score)version Detection of entities inboth English and Chinese languagesChan et al. [38]Website Alien Vault OTXlocation, person attack technique,bitcoin ad- dress,CVE,Microsoft de- fender threat, domain,email, MD5, SHA-1, SHA-256, fileBIOBERTDeBERTa-97.51%(F1 score)The fine-tuned ELECTRA model demon- strated the ability to extract novel IoCs accurately.Gasmi et al. [170]Bridges et al.path, hostname, IPV4, IPV6, sslcert fingerprint, URI and URL vendor, application, version,BIOWord2vecLSTM+CRF-83.37%(F1Poor performance on the edition andYang et al. [162]dataset [179] FreeBuf portal and blogsfile, OS,hardware,edition VulnerabilityID,Computer terminology,Software,Orga- nization, LocationBIOESWord, Character level, POS em- beddingscore) Star-HGCN -90.98%(F1 score)hardware Performance of organization and soft- ware improved by Star-HCN method\n\n\\ NM indicates Not Mentioned  \n\nTable 11: Publicly available NER corpus   \n\nPaperDataInstanceLinkofthecorpusBridges et al.[179]853560tokens 73964tagshttps://github.com/stucco/auto-labeled-corpusKim et al. [52]498000tokenshttp://github.com/nlpai-lab/15720 tagsCTI-reports-datasetAlam et al. [70] Wang et al. [161]106991tokens 4350tagshttps://github.com/aiforsec/CyNER260134tokenshttps://github.com/wangxuren/APTNERWang et al.[180]39565tags 6574sentences 36412tagshttps://github.com/SCreaMxp/ DNRTI-A-Large-Scale-Dataset-for- Named-Entity-Recognition-in- Threat-Intelligence  \n\nTrong et al. [182] generated a corpus for cybersecurity event detection, encompassing 8,014 event triggers spanning 30 event types and drawn from 300 articles. These events types were classified into four categories related to cyber vulnerabilities/attacks: IMPACT, ATTACK, PATCH, and DISCOVER. They also evaluated various models for event detection using embedding techniques such as Word2Vec and BERT. The Document Embedding Enhanced Bidirectional RNN achieved $68.4\\%$ F1-score in the event detection task. In [76], the authors explored social media to extract cyber events and devised a method to prioritize potential cyber threats, considering criteria like user influence scores, named entity confidence, and keyword relevance. They mimicked the process of identifying named entities and keywords using TextRazor49(NER API), and the TextRank [183] algorithm from Gensim. In addition, TextRazor furnished confidence scores for named entities, while TextRank assigned scores to keywords based on word graphs. In [160], Luo et al. addressed the extraction of cybersecurity event details from Chinese text, focusing on four event types: IncidentsOnVulnerability, RansomwareAttack, Phishing, and Data Breach. Their approach involved converting the event extraction task into a sequence labeling task. This process began by embedding characters and incorporating word information into character representations. They introduced a $\\mathbf{k}\\cdot$ -window-size BiLSTM to capture contextual information spanning sentences.  \n\nTCEDCL [184] is a novel cybersecurity event detection method that doesn’t rely on event trigger word labeling but instead incorporates sentence semantics. It employs unsupervised comparison learning to find the most suitable candidate instances by using a contrastive learning model. They defined two main event types, further categorized into nine subtypes: VulnerabilityPatch, VulnerabilityDiscover, VulnerabilityImpact, SupplyChain, Malware, DDoSAttack, Ransom, Phishing, and Data Breach. A key benefit of TCEDCL is that it doesn’t rely on detecting trigger words, simplifying the data sorting process during model training and lessening trigger word accuracy’s influence on the model’s performance. Instead, the system only needs to determine the event type, making it exceptionally flexible in adapting to new event types with minimal labeled data needed to train a new classifier. W2E(Words to Events) [185] identifies emerging cyber threats with low false positives and high coverage by monitoring individual words instead of using semantic clustering methods. They used NLP techniques, such as POS tagging, lemmatization, and NER, to reduce false positives effectively. Additionally, it fliters and categorizes tweets based on keywords associated with five event types: Data Breach, DDoS attack, Vulnerability, Exploit, and Malware, while also monitoring CVE-related events separately. In [186] Mohammad et al. introduced a dual-level approach to cyber-event detection involving medium-level detection utilizing LDA and high-level detection based on Google Trends data. Their research encompassed comprehensive preprocessing steps, which included NER, POS tagging, symbol removal, stop-word elimination, and lemmatization. Also, they leveraged Word2Vec for feature vectorization and t-distributed stochastic neighbor embedding (t-SNE) for dimension reduction. This method achieved $95.96\\%$ accuracy in cyber event detection.  \n\nWhile existing methods can identify emerging cyber events, they often fall short of providing detailed threat characteristics. To overcome these limitations, Associated EE (AEE) [181] is introduced, which is a capable of performing event extraction for every sentence in a document. AEE consists of two components: event type classification and element extraction, both utilizing BERT to grasp sentence-level semantic understanding. To classify event types, it constructs a document-level graph that links sentences of diverse types and words within each document, utilizing a Document-Aware Graph Attention Network (DGAT) to represent sentences and grasp contextual information. AEE", "files_in_pdf": [{"path": ".pdf_temp/chunk_1_1756432206/images/47ge57.jpg", "size": 20755}, {"path": ".pdf_temp/chunk_1_1756432206/images/962vx5.jpg", "size": 178800}, {"path": ".pdf_temp/chunk_1_1756432206/images/j6fm4z.jpg", "size": 170529}, {"path": ".pdf_temp/chunk_1_1756432206/images/ejg3n2.jpg", "size": 18308}, {"path": ".pdf_temp/chunk_1_1756432206/images/ifyqnn.jpg", "size": 90987}, {"path": ".pdf_temp/chunk_1_1756432206/images/ocpcc5.jpg", "size": 48608}, {"path": ".pdf_temp/chunk_1_1756432206/images/jwgumf.jpg", "size": 81675}, {"path": ".pdf_temp/chunk_1_1756432206/images/qfrd2k.jpg", "size": 26328}, {"path": ".pdf_temp/chunk_1_1756432206/images/ox3a34.jpg", "size": 15491}, {"path": ".pdf_temp/chunk_1_1756432206/images/b3beej.jpg", "size": 60157}, {"path": ".pdf_temp/chunk_1_1756432206/images/v4614x.jpg", "size": 213810}, {"path": ".pdf_temp/chunk_1_1756432206/images/bwvh0i.jpg", "size": 130041}, {"path": ".pdf_temp/chunk_1_1756432206/images/v86agq.jpg", "size": 158683}, {"path": ".pdf_temp/chunk_1_1756432206/images/pemmq7.jpg", "size": 51500}, {"path": ".pdf_temp/chunk_1_1756432206/images/jtmovg.jpg", "size": 38777}, {"path": ".pdf_temp/chunk_1_1756432206/images/bta17m.jpg", "size": 91109}, {"path": ".pdf_temp/chunk_1_1756432206/images/k9clmr.jpg", "size": 605221}, {"path": ".pdf_temp/chunk_1_1756432206/images/qdr42z.jpg", "size": 26542}]}