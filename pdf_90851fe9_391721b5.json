{"origin_pdf_path": "https://open.mitchellhamline.edu/cgi/viewcontent.cgi?article=1141&context=cybaris", "text_in_pdf": "finders may work cooperatively in finding solutions that reduce the risks associated with a vulnerability.”184 While introducing this standard was undoubtedly important, not all vendors follow ISO/IEC standards and the policy is paywalled.  \n\nThe Cybersecurity & Infrastructure Security Agency (CISA) has released its vulnerability disclosure policy template for agencies seeking to implement a disclosure policy.185 The policy lays out guidelines for research, appropriate test methods, and the scope of testing.186 Whether additional government agencies choose to adopt CISA’s recommended template is up to those agencies. Where to find information about which agencies have adopted a VDP and how to find their VDP is not listed, leaving researchers to either track down this information, accept the risk of liability should an agency not have a VDP, or forgo research altogether.  \n\nEfforts to standardize VDPs continued when Disclose.io was formed in 2018.187 Disclose.io seeks to standardize vulnerability disclosure programs and to have them include “‘safe harbor’ language that protects well-intended hackers from legal action[.]”188 The lack of consistency and absence of “safe harbor” language is a deterrent to disclosing bugs for those who discover them.189 The project hopes that including standard language in contracts will provide an opportunity to “foster security research instead of stifling it.”  To make finding information on VDPs easier, a database of companies and information on where to find their vulnerability disclosure policy is available for anyone to search.191 However, the database does not show which, if any, of these programs have adopted the standard language recommended by disclose.io and only one program is listed as having a full “safe harbor” provision.192 Without further voluntary adoption of the standard contract language, however, researchers still lack protections for the security research they perform.  \n\nIn 2022, the quest for standardizing vulnerability disclosure continued when the Internet Engineering Task Force (IETF) introduced RFC 9116.193 RFC 9116 seeks to standardize where researchers can find information about a company’s disclosure policy directly from the company’s website. Information includes who to contact, a URL to the company’s disclosure policy, and the expiration of the policy.194 This year, Cloudflare, a DNS provider, created a dashboard to make it easy for web domain administrators to incorporate and encourage adoption of this standard.  As with all attempts to make vulnerability disclosure more transparent and standardized, RFC 9116 only goes so far as the company is willing to adopt it.  \n\nHowever, even in instances where a company has adopted a disclosure program or bug bounty, security researchers have still face the threat of CFAA charges. For instance, when drone manufacturer DJI implemented a bug bounty program, they told computer researcher Kevin  \n\nFinisterre that security issues with their servers were covered under the program.196 When Finisterre discovered vulnerabilities that could allow an attacker to access user’s private information, DJI did an about-face, telling Finisterre that the company’s servers weren’t covered under the bounty program after all, threatening Finisterre with CFAA charges.197 In another example, Voatz, a digital election system manufacturer, implemented a VDP to ensure their systems were secure. When an undergraduate student, relying on the terms of the VDP, began performing security research on Voatz’s systems they were reported to the FBI by Voatz.198 The student’s research complied with the terms of the VDP at the time the research was undertaken, but Voatz publicly claimed that the student’s work violated the terms of the VPD – the terms they claim were violated were added later only when word of their referral of the student to the FBI was made public.199 An additional issue is that while there are guidelines in creating a VDP to provide safe harbor or limit liability under the CFAA, ultimately researchers are bound by the terms the company chooses to set.200 Frequently, this includes a provision that a researcher may not disclose any discovered vulnerabilities to any entity but the company itself.201 Should a researcher discover a serious vulnerability exposing customers to risk and report it to the company under their VDP, only to find that the company made no efforts to fix the security issues, the researcher may not disclose the issue to affected parties, the public, or law enforcement without exposing themselves to the risk of litigation for violating the CFAA.202 As previously discussed, it is not mere conjecture; companies frequently avoid fixing the vulnerabilities in their products and often deny they exist until a breach or security incident is made public.203  \n\nWithout Congressional action to amend the CFAA once again, researchers will, despite the myriad efforts undertaken, always be reliant on the whims of judicial holdings, changes in prosecution policies, or discretion of private corporations to determine whether their work will fall afoul of the CFAA.  \n\nV. CFAA AMENDMENT PROPOSALS THAT LIMIT SECURITY RESEARCHER LIABILITY.  \n\nCongress has several courses of action it could take to amend the CFAA and limit liability under the CFAA for researchers. Any or all of them would offer protections, allowing researchers to work without fear. Many of these are not new; they have been presented by legislators, advocated for by interest groups, or suggested legal experts in the field. This article will present these arguments for amending the CFAA and conclude with a seemingly counterintuitive point: that increasing corporate liability could actually reduce researchers’ liability.  \n\nA. Redefining “Without Authorization” to Include Code-Based Access Restriction.  \n\nIn response to the death of internet activist Aaron Swartz204, H.R. 2454 – Aaron’s Law Act of 2013 was introduced in the House of Representatives.205 The bill sought to redefine “access without authorization” as “obtaining information on a protected computer that the accessor lacks authorization to obtain by knowingly circumventing one or more technological or physical measures that are designed to exclude or prevent unauthorized individuals from obtaining that information.”206 Requiring the bypassing of some technological measure would provide some protection to legitimate researchers, but instances where technological measures were meant to be in place but improperly configured might still give rise to liability under the CFAA.207 For this reason, the EFF made a recommendation that went further, not only shielding researchers from liability for ineffective access control but also explicitly providing that violations of terms of service, agreements, or contractual obligations would not give rise to liability under the CFAA.208 These amendments would go where the Van Buren Court was unwilling: requiring that access without authorization requires defeating a technological barrier while eliminating criminalization of a breach of contract. While this proposal seeks to limit a researcher’s criminal liability under the CFAA, the next proposal would provide researchers protection from civil liability.  \n\nB. Safe Harbor for “Good Faith Security Researchers.”  \n\nThe threat of civil action looms large for security researchers and, given the new DOJ policy, is likely the largest risk they face.209 Rapid7 proposal for security researcher protections is multi-faceted. First, the proposal would limit the circumstances under which a civil action may be brought.  Next, like the aforementioned DOJ policy, which takes its definition from the DMCA Sec. 1201 protections for researchers, Rapid7’s proposal would define “good faith security research” but improves upon it by including actions that legitimate security researchers would take: “such a minimizing any damage and making an effort to disclose any discovered vulnerabilities to the computer owner.”  The definition is more well-defined than the DMCA and DOJ counterparts, recognizing the importance of not being overbroad given that most security research involves computers that the researcher does not own.212 In addition to a more robust definition of “good faith security research,” Rapid7’s proposal includes an affirmative defense for conduct that involves subclause (c)(4)(A)(i)(I) allowing researchers to avoid liability should they face a civil suit while acting solely for “good faith security research.”  This aspect of the proposal provides civil protections, where the DOJ policy was unwilling to go for criminal liability. The proposal would be a great step in protecting legitimate security researchers, but as with most proposals to “fix” the CFAA is not without caveat. For instance, “good faith security researcher” is defined by requiring responsible disclosure of any vulnerabilities discovered as part of the research. As discussed previously, even the act of disclosing vulnerabilities has given rise to threats of civil action under the CFAA. Concerns remain about swinging the pendulum in the other direction by providing overly broad protections that attackers may invoke disingenuously to escape liability for their malicious acts.  Rather than providing safe harbor protections for researchers that may be weaponized by attackers, another proposal seeks to shield researchers by redefining a different core term used to determine civil liability under the CFAA: “loss.”  \n\nC. Amending the Definition of “Loss”  \n\nIn her well-researched law review article, Riana Pfefferkorn puts forth a novel proposal to protect security researchers from civil liability by amending the CFAA’s “loss” definition.215 In a two-pronged approach, the proposal would 1) amend the definition of “loss” to prevent the costs of remediating a disclosed vulnerability alone, absent any other alleged loss, from meeting the $\\mathbb{S}5{,}000$ threshold and 2) add a fee-shifting provision, shifting litigation costs from defendants to plaintiffs’ whose losses do not meet that threshold.216 The proposal would put an external security researcher reporting a vulnerability to a company on the same legal ground as a member of a company’s internal security team. In the latter case, there is nobody for the company to sue; “fixing what the internal team found is just the cost of doing business.”  Absent any other harm, the company is not a victim of cybercrime as they have suffered no loss, freeing security researchers from the risk of civil liability for responsibly disclosing vulnerabilities.218 The second proposed amendment would then work as a shield to protect researchers from meritless claims or claims that cannot meet the $\\mathbb{S}5{,}000$ loss threshold without including costs of vulnerability remediation.219 The risk of being liable for the costs of a defendant’s legal fees will deter companies from pursuing meritless claims, but would serve as no barrier for instances  \n\nwhere a plaintiff can show they suffered actual “loss” as defined by the proposal.220 While this fee-shifting arrangement would work to protect researchers who are certain their work has caused no harm, the reality of the work performed by researchers is not so black and white. In interviews with researchers, Brian Krebs notes that while the risk of costly civil litigation for reporting vulnerabilities weighs on researchers, nearly as often researchers expressed unease in reporting vulnerabilities because their research may have gone “just a tad too far.”221 This proposal would likely not shield researchers that, while operating in “good faith,” accidentally cause some harm. Where a researcher cannot be sure of the outcome of their research, they may still find themselves at risk of civil liability, even under the changes proposed.  \n\nD. Remove Immunity from Civil Liability from Corporations.  \n\nAll the proposed solutions thus far, would offer significant protections for security researchers while not completely eliminating the risks that researchers face. Even so, even a slightly flawed solution is better than none and given the ever-increasing rise in cybercrime and vulnerabilities waiting to be exploited by hackers, we cannot afford to forgo good solutions in search of the perfect one. It is with that in mind that this article proposes its flawed suggestion for amending the CFAA.  \n\nWhile previous proposals all center around decreasing security researchers’ exposure to civil liability under the CFAA, this article proposes increasing exposure to civil liability for “loss” caused by vendor software or hardware vulnerabilities. To achieve this, this article proposes amending section 1030(g) by removing the last line reading: “[n]o action may be brought under this subsection for the negligent design or manufacture of computer hardware, computer software, or firmware.” At first glance, amending the CFAA to once again provide for a civil remedy for “loss” caused by software and hardware companies’ products may seem especially punitive, but the purpose is not to punish corporations but to incentivize their cooperation with security researchers.  \n\nSoftware companies have been largely immune to lawsuits for damages as a result of vulnerabilities present in their software. Courts have largely been silent on whether software is a “product,” particularly when the software operates as a service or deals primarily with ideas and content, allowing software companies to escape liability under the strict product liability doctrine.222 According to Thomas F. McKim, author of a treatise on business torts, “despite past dire warnings that software and computers will result in the application of strict liability under product liability law, this has not happened.”223 The economic loss rule also prevents recovery through a tort cause of action when the damage from a software vulnerability affects a person or property but is solely monetary.224  The ILOVEYOU attack resulted in $\\mathbb{S}10$ billion in damages225, but none would be recoverable because none was physical damage or pain and suffering from a physical injury. Software companies also take steps to immunize themselves from liability through contracts law. Software is generally not “sold” but licensed, subject to end-user license agreements (EULA) or terms of service (TOS).  These agreements typically include anticonsumer terms that “disclaim all warranties and limit remedies to a nominal amount such as $\\mathbb{S}100$ or the amount paid in licensing fees.”227 When Congress amended the CFAA in 2001 to provide immunity for software companies, these clickwrap agreements were in their infancy, but since then, they have evolved and ingrained themselves into our everyday internet-connected lives.228  \n\nThere is a risk that removing immunity from civil liability may stifle innovation that we all so profoundly covet and have come to expect from tech companies. However, given the current crisis with internet security and our reliance on software in our daily lives, holding tech companies liable for damage caused by their products would serve as a deterrent to releasing products that have not been properly vetted and tested. More importantly for security researchers, it will serve to incentivize these companies to work with security researchers who report vulnerabilities before they can be weaponized, making both the internet safer and, in a strange turn of events, helping to shield those companies from civil liability under the CFAA.\n\nCybaris® Cybaris® \nVolume 16 Issue 2 Article 1 \n2025 \nPatching the CF AA so Resear chers No Longer P ay Patching the CF AA so Resear chers No Longer P ay \nJoshua Bak er \nFollow this and additional works at: https:/ /open.mitchellhamline.edu/cybaris \n Part of the Computer Law Commons , Intellectual Pr oper ty Law Commons , and the Science and \nTechnology Law Commons \nRecommended Citation Recommended Citation \nBaker, Joshua (2025) \"P atching the CF AA so Resear chers No Longer P ay,\" Cybaris® : Vol. 16: Iss. 2, Ar ticle \n1. \nAvailable at: https:/ /open.mitchellhamline.edu/cybaris/v ol16/iss2/1 \nThis Ar ticle is br ought t o you for fr ee and open access b y \nthe Law Re views and Journals at Mitchell Hamline Open \nAccess. It has been accepted for inclusion in Cybaris® b y \nan authoriz ed administr ator of Mitchell Hamline Open \nAccess. F or mor e information, please contact \nsean.f elhof er@mitchellhamline.edu . \n© Mitchell Hamline School of Law \n\nPATCHING THE CFAA SO RESEARCHERS  NO LONGER PAY  \nJoshua Baker  \nI. INTRODUCTION  ................................................................................................................... 149 \nII. THE HISTORY OF THE CFAA’ S ENACTMENT ASSUMED HACKERS WERE ONLY MALICIOUS . ... 152 \nA. The Dual Morality of Hacking is Not Recognized by the CF AA.  ............................. 155 \nB. Hackers are Often Not the Criminal Masterminds the CF AA was Enacted to Punish.\n 156 \nC. The Methods and Tools Used by Hackers are Morally Agnostic. ............................ 157 \nIII. THE CFAA  PROVIDES CORPORATIONS IMMUNITY FROM CIVIL LIABILITY AND SHIFTS THE COST \nOF CYBERCRIME TO EVERYONE ELSE . ........................................................................................... 159 \nA. The First CF AA Conviction Puts Security Research on Notice  ............................... 164 \nB. Precedent is Set, Leaving Researchers Liable for Any Damage Caused by \nUnauthorized Access to Computers. ................................................................................. 166 \nC. Robert Morris Births an Industry  ............................................................................ 167 \nI V. THE CFAA  CHILLS NECESSARY SECURITY RESEARCH . ........................................................ 168 \nA. Recent Legal Developments Provide some Protections but Don’t Go Far Enough to \nProtect Researchers.  .......................................................................................................... 171 \n1. Van Buren Limits Some Risks but Leaves Many Questions Unanswered.  .... 172 \n2. The Ninth Circuit Limits CFAA’s Liability for Accessing Public Information.\n 173 \n3. DOJ Policy Shields “Good- Faith” Researchers from Criminal Prosecution.  . 174 \nB. Researchers Attempt to Protect Themselves by Responsibly Disclosing \nVulnerabilities to Companies Only Goes as Far as Those Companies Willing to Adopt \nThem.  ................................................................................................................................. 176 \nV. CFAA  AMENDMENT PROPOSALS THAT LIMIT SECURITY RESEARCHER LIABILITY . ............... 180 \nA. Redefining “Without Authorization” to Include Code -Based Access Restriction.  .. 180 \nB. Safe Harbor for “Good Faith Security Researchers.”  ............................................ 181 \nC. Amending the Definition of “Loss”  ......................................................................... 183 \nD. Remove Immunity from Civil Liability from Corporations. ..................................... 184 \n \n  \n\n \n149  I. INTRODUCTION  \nThe Computer Fraud and Abuse Act  (CFAA)  is the federal statute that criminalizes \nunauthorized access to computers – i.e. hacking.1 The CFAA’s original scope criminalized \nintrusion into computers used by the government and financial institutions, but amendments have \nexpanded the scope to include virtually all internet -connected devices.2  Later amendments to  \nCFAA provide d a civil cause of action allowing  for victims of computer crime to sue for \ndamages in limited circumstance.3 A lot has changed in the technology sector since 1986 and at \nthe time of the CFAA’s enactment, Congress could not have imagin ed that hackers would play a \npivotal role in helping to safeguard computers against malicious attacks.4 Unlike today, there was \nnot a nuanced view of hackers or their activities.  \nMany of the methods and activities that were thought to be solely in the realm of \nmalicious hackers are now used by security researchers, many of whom got their start as “hackers” in the traditional sense,  seeking  to improve the security of computing systems. While \nthe definition of hackers and hacking has expanded to include “good faith” research, the CFAA \ndoes not differentiate between accessing a computer without authorization for benevolent \npurpose and a ccessing a computer without authorization for mali cious reasons.\n5 As the internet \n \n1 18 U.S.C. § 1030 . \n2 See United States v. Kramer , 631 F.3d 900, 902 (8th Cir. 2011) (noting the definition of “computer” is \n\"exceedingly broad,\" and concluding an ordinary cell phone is a computer); see also  United States v. Nosal  (Nosal \nII), 844 F.3d 1024, 1050 (9th Cir. 2016), cert. denied, 138 S. Ct. 314 (2017) (noting “protected computers” include \n“effectively all computers with Internet access…”) . \n3 Violent Crime Control & Law Enforcement Act of  1994, 1994 Enacted H.R. 3355, 103 Enacted H.R. 3355, 108 \nStat. 1796, 2097.  \n4 U.S. Dep’t of Just., Department of Justice Announces New Policy on Charging Cases Under the Computer Fraud \nand Abuse Act, https://www.justice.gov/opa/pr/department -justice -announces -new-policy -charging- cases -under -\ncomputer -fraud -and-abuse -act (stating that ”[c] omputer security research is a key driver of improved \ncybersecurity”) . \n5 18 U.S.C. § 1030(a)(2)(c) (prohibiting unauthorized access of a protected computer to obtain information, stating: \n“Whoever intentionally access a computer without authorization or exceeds authorized access  and thereby obtains \ninformation from any protected computer.”) . \n\n \n150  has expanded, so has t he need for security research to secure cyberspace from growing threats. In \na 2002 memo, Bill Gates, then CEO of Microsoft, acknowledged the need for a security first \nmindset, “emphasiz[ing] security right out of the box” and the need to “constantly refine and improve security that security as threats evolve.”\n6 While companies improved their efforts to \nsecure their products, the efforts  of security researchers  were t he primary  driver of computer \nsecurity.7 According to Alex Stamos, former Chief Security Officer for Yahoo and Facebook:  \nMore than any other field of computing, security has benefited from the existence of a \nlarge,  diverse, unofficial community of researchers and practitioners. I can think of few \nadvancements  in semiconductor design that did not originate  in a well -funded corporate or \nacademic lab,  but a majority of the advancements in finding and fixing security flaws over \nthe last two  decades has come from the “security research  community .”8 \n So, too, has the federal government recognized the importance of the work of the security \nresearch community. The Attorney General’s Cyber -Digital Task Force acknowledge s this \nimportance , writing that computer security experts provide “valuable contributions to combating \ncyber threats by discovering significant, exploitable vulnerabilities affecting, among other things, \nthe confidentiality of data, the safety of Internet -connected devices,  and the security of \nautomobiles.”\n9 \n Despite these efforts , cybercrime is on the rise.10 As of this writing, the Cybersecurity & \nInfrastructure Security Agency’s (CISA) Known Exploited Vulnerabilities (KEV) catalog \n \n6 Memo from Bill Gates , Microsoft (Jan. 11, 2002) , https://news.microsoft.com/2012/01/11/memo- from -bill-gates/  \n[https://perma.cc/Q35F -2KJ3 ]. \n7 Brief of Amicus Curiae Computer Security Researchers,  Van Buren, 141 S. Ct. 1648, 210 L. Ed. 2d 7 , 2020 WL \n4005654. (citing Expert Report and Decl. of Alex Stamos ¶16, Apple, Inc. v. Corellium, LLC, No. 9:19- cv-81160-\nRS, ECF No. 451- 6 (S.D. Fla. 2020) (“Stamos Decl.”) (“The computer security research community is comprised of \nnot only computer security companies but also individuals and organizations with expertise in computer security.” \nDOJ, Report of the Attorney General’s Cyber -Digital Task Force) . \n8 Id. \n9 Id. at 8.  \n10 Ani Petrosyan,  Annual Number of Data Compromises and Individuals Impacted in the United States from 2005 to \n2023, Statista (Feb. 12, 2024), https://www.statista.com/statistics/273550/data -breaches -recorded -in-the-united -\nstates -by-number -of-breaches -and-records -exposed/  [https://perma.cc/9F2N -RJ27 ]. \n\n \n151  contains 1236 vulnerabilities c onfirmed to have been exploited in the wild.11 One cannot hardly \ngo a day without reading about another security incident in the news. If computer companies \ntruly have committed  to security in their products, the real -world effects have yet to be felt. And \nwith immunity from civil liability under the CFAA, it is not the companies whose vulnerabilities \nare exploited that pay the costs. The security research community stands by to fill this gap, but \nthe risk of prosecution and civil liability under the CFAA continues to chill  cybersecurity \nresearch.   \nThe Supreme Court’s 2021 decision in Van Buren v. United States  partially limited the \nscope of the CFAA .12 Providing some protections to security researchers , the decision prompted \nchanges to the federal criminal charging policy for “good faith security researchers.” Although Van Buren narrowed the scope of the “exceeds authorized access” phrase in the CFAA, a majority of the research performed by security researchers is done “without authorization” on computers they do not own.\n13 While the new charging guidelines provide protections for \nresearchers , the risk of civil ligation remains. Policies for responsible vulnerability disclosure can \nmitigate some risk , but those protections go only as far as the terms of the policy and rel y on the \n“good faith” of the company to whom the vulnerability is disclosed.14 \nThis climate has  forced researchers  to partially or completely  forg o res earch that may fall \nafoul of the CFAA. Additionally, confusing and non- standard vulnerability disclosure policies \n(VDP ) leave researchers unsure whether t hey should disclose vulnerabilities and, if so, to whom. \nAdvocates have called for changes to the CFAA that would provide a safe harbor provision for \n \n11 Known Exploited Vulnerabilities Catalog, Cybersecurity & Security Infrastructure Security Agency, \nhttps://www.cisa.gov/known- exploited -vulnerabilities -catalog . \n12 Van Buren v. United States, 141 S. Ct. 1648 (2021) . \n13 Id. \n14 See infra Section  IV (B).  \n\n \n152  security researchers . Absent these changes, however, a ny and all mitigation to the liability a \nresearcher faces is at the sole discretion of the compan y whose vulnerabilities they find. \nThis article will proceed first by providing a more nuanced definition of hackers , showing \nthat Congress’s narrow understanding when the CFAA was enacted has functioned to criminalize \nlegitimate research efforts . Second , the article will proceed to  discuss  the current state of \ncybercrime, focusing on both the computer  industry’s historical and current practices that have \ncontributed to the insecurity of the interne t.  Third, the article will showcase how the CFAA \nstifles the important work of cybersecurity researchers  by exposing them to the risk of \nprosecution and civil litigation. R ecent efforts by the courts, the federal government , and private \nindustry to mitigate the risk have  not gone  far enough to provide protection to researchers .  \nFinally, the article will discuss the various proposals for amending the CFAA, including redefining “access”, “good faith security researcher” and “loss .” The article will put forth a \nproposal of its own: eliminating corporations’  immunity from civil liability under the CFAA to \nnot only improve overall cybersecurity but  importantly , serve as a shield for security researchers.  \nII. T\nHE HISTORY OF THE CFAA’ S ENACTMENT ASSUMED HACKERS WERE ONLY MALICIOUS . \nThe Computer Fraud and Abuse Act (CFAA) was initially enacted in 1986 as a response \nto growing concerns about computer -related crimes in the government and financial sectors.15 \nThe 1983 film \"WarGames\" played a significant role in inspiring this legislation after a screening \nby then President Ronald Reagan at Camp David.16 The movie, which depicted a young hacker \naccessing a military supercomputer and nearly triggering a nuclear war, raised awareness among \n \n15 86 CIS PL 99474; 99 CIS Legis. Hist. P.L. 474.  \n16 Kevin Bankston, How Sci -Fi Like  WarGames  Led to Real Policy During the Reagan Administration , \nSlate (Oct. 8, 2018), https://slate.com/technology/2018/10/reagan -wargames -star-wars -science- fiction -policy.html \n[https://perma.cc/3AYV -U4K2 ]. \n\n \n153  lawmakers about the potential national security risks posed by unauthorized computer access.17 \nThis fictional scenario prompted real -world discussions in Congress about the need for \ncomprehensive cybersecurity legislation.18 As a result, the CFAA, as originally drafted, aimed to \nprotect sensitive information stored on government and financial institution computers, \nrecognizing the potential national security risks associated with unauthorized access to such data.\n19 The CFAA criminalized unauthorized access to government and financial institution \ncomputers with intent to defraud.20 Additionally, the CFAA criminalized causing damage to \ncomputers accessed without authorization and trafficking in passwords that would allow unauthorized access to a government computer or otherwise affect interstate commerce.\n21 \nCongress believed this legislation, coupled with “active efforts of industry to safeguard their property”, would address the growing issue of computer crime.\n22 Thus, when t he CFAA was \nenacted , Congress considered the issue of cybercrime to be one of dual responsibility: the \ncomputer industry working to prevent cyber crimes and the government enforcing the law when \nthey do occur.23  \nAs technology and society changed, Congress updated the CFAA to address new and \nemerging concerns around cybercrime. In response to the growth of network connected computers, the CFAA was expanded to include computers used in interstate or foreign commerce, expanding the act's reach b eyond government and financial systems, encompassing a \nwide range of private sector computers.\n24  The CFAA was later amended again to expand the \n \n17 Synopsis, WarGames Plot, IMDB , https://www.imdb.com/title/tt0086567/plotsummary/?ref_=tt_stry_pl#synopsis  \n[https://perma.cc/9Y4L -HGGY] . \n18 See supra note16. \n19 Id. \n20  Pub. L. No. 99 -474, 100 Stat. 1213 (1986)  \n21 Id. \n22 132 Cong. Rec.  H3275- 76(daily ed. June 3, 1986) ( statement of Rep. Hughes) . \n23 Id. \n24 Violent Crime Control& Law Enforcement Act of 1994 ,  Pub. L. No. 108 Stat. 1796, 2097 . \n\n \n154  definition of “protected computer” to include not only those used in interstate and foreign \ncommerce but also communication.25 This change effectively brought all internet -connect ed \ncomputers under the CFAA’s purview, significantly broadening its reach in this era of rapidly \nexpanding internet adoption.26  \nAdditionally, and perhaps most significantly so far as liability to researchers is concerned, \nCongress made an exception to the economic loss doctrine, amending the CFAA to provide a \ncivil cause of action to victims of cybercrime.27 In 2001, the CFAA was again amended to \nprovide immunity from civil liability  for the  negligent design or manufacture of computer \nhardware, computer software, or firmware.28 The end result of these amendments was an \nexpansion of the risks researchers face under the CFAA, while the computer industry was \nprovided immunity  from civil liability for damages their products may create.  \nWhile amendments to the CFAA have contributed to increased liability for researchers, to this day C ongress’s initial belief s about hacking continue to impact the current  state of cybersecurity. \nThe belief s that hacking could only be malicious , and that the computer industry would \nsafeguard against cybercrime has prove n false on both accounts. The computer industry has not \nmet expectations in  prevent ing cybercrime, leaving a large group of hackers  dedicated to finding \nvulnerabilities in software and hardware that  malicious actors seek to exploit . The CFAA, \nhowever, does not di stinguish between good and bad hackers, and this fundamental \nmisunderstanding of who hackers are and what they do has resulted in  both criminalization of \n \n25 Economic Espionage Act of  Pub. L. No. 104- 294,  110 Stat. 3488, 3491 (defining “protected computer” as any \ncomputer “which is used in or affecting interstate or foreign commerce or communication, including a computer \nlocated outside the United States that is used in a manner that affects interstate or foreign commerce or communication of the United States”) . \n26Computer Crimes , 61 Am. Crim. L. Rev. 441, 451 n.81 (2024).  \n27 See supra note  3. \n28 Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism  \n(USA PATRIOT Act) ACT OF 2001, 107 P ub.L. No. 107=56, 115 Stat. 272, 38284.  \n\n \n155  and civil liability for important security research.  To better understand why this differentiation \nmatters, first one must get a broader sense of hackers and hacking culture.  \nA. The D ual M orality of H acking is N ot Recognized by the CFAA.  \nMedia reporting and popular culture generally associate the term hacker with unethical \nbehavior.29 During House discussions regarding the CFAA, there was concern that hackers were \nbeing glamorized in the media , and there was a need to acknowledge hackers for what they are: \ncriminal trespassers.30 While it is true that some hackers may have malicious motivations, not all \naccept the definition of a hacker as such. Before hacker s took on a negative connotation, it was \nused as a term of endearment: “a clever programmer who produced elegant code for solving \ndifficult problems.”31 Hackers are a large and diverse group with wide -ranging goals and \nmotivations ; therefore , members of the hacking community cannot be singularly defined. \nReasons for engaging in hacking are personal and expansive : “curiosity, thrill- seeking, extortion, \nacademic interest, a desire to fix problems, and the urge to wreak havoc.”32 Hacker, however, is \noften utilized as a catch -all term that doesn’t differentiate the purpose of the individual.33 \n To account for the alternate purposes of hackers, the term has been further differentiated \nas “white hat” hackers and “black hat” hackers. “Black hat” hackers seek to do harm, “motivated by mischief or profit rather than by actually fixing vulnerabilities and security flaws.”\n34 “White \nhat” hackers , on the other hand, “seek to improve cybersecurity by finding vulnerabilities in \nhardware and software.”35 The singular term, “ hacker ”, can never fully account for the wide \n \n29 Synopsis , Hacking Is Not a Crime , https://www.hackingisnotacrime.org  [https://perma.cc/PRN3 -HQK9 ]. \n30 Supra note 22. \n31 SCOTT  J. SHAPIRO , FANCY  BEAR GOES PHISHING  46 (1st ed. 2023) . \n32 Shooting the Messenger: Remediation of Disclosed Vulnerabilities as CFAA “Loss,”  29 Rich. J.L. & Tech. 89, \n101 (2022) (citing Ido Kilovaty, Freedom to Hack, 80 OHIO ST. L.J. 455, 480 (2019)).  \n33 Id. \n34 Id.  \n35 Id. at 101 -02. \n\n \n156  range of motivations behind hacking, and some have called for alternative designations that \nencompass the purpose of the individual . The terms “Hacktivist ,” “Researcher ,” or \n“Whistleblower” have been suggested as an alternative to “white hat” hacker to account for the purpose behind the hacker’s actions.\n36 To further differentiate, the terms “Attacker ,” “Malicious \nAdversary ,” or “Threat Actor” have been suggested as a replacement for “black hat” hacker.37 \nAside from the negative connotation associated with the word hacker, there is also a \nmisunderstanding of who  hackers are. While there is no singular defining characteristic of a \nhacker , studies have revealed a more precise definition of those who engage in hacking.  \nB. Hackers are O ften N ot the C riminal M asterminds the CFAA was E nacted to P unish.  \nIn general, those engaged in hacking tend to be young men bored “with work or school, \nnonsocial, and have few outside activities.”38 The initial motivation for these young hackers is \nfun: providing an intellectual challenge, puzzle solving, and an opportunity to gain esteem in the \neyes of their peers.39 Most learned hacking techniques from other hackers in online forums \nwhere peer pressure fosters an environment of escalation of increasing deviant behavior.40 With \nthe rise of the internet, many “get their start as part of an online video game culture.”41 Of those \ncharged with cybercrimes, 80% had no prior criminal history.42 Unlike other categories of crime, \ncybercriminals tend to have higher education and employment status.43 Cyber -offenders \n \n36 Tenets , Hacking is Not a Crime, https://www.hackingisnotacrime.org/conduct [https://perma.cc/Y828 -JBBS ]. \n37 Id. \n38 W. Cagney McCormick,  The Computer Fraud & Abuse Act: Failing to Evolve with the Digital Age , 16 SMU Sci. \n& Tech. L. Rev  481, 483 (2013) (citing Scott Tulman, Unique Characteristics of Computer Crime Prosecutions and \nOffers , in I1B-40A Criminal Defense Techniques  § 40A.03[2] (2011)).  \n39 See s upra note 31, at  292. \n40 Id. at 292 ( describing deviant behaviors ranging from “game cheats and booting to profit -oriented cybercrime” ). \n41 Id. \n42 Id. \n43 See s upra note 39, at  293 (citing Alice Hutchings, “Cybercrime Trajectories: An Integrated Theory of Initiation, \nMaintenance, and Desistance,” in Crime Online: Correlates, Causes, and Context,  ed. Thomas J. Holt (Durham, NC: \nCarolina Academic Press, 2016), 117 -40). \n\n \n157  generally believe that they will not be caught and that law enforcement lacks the capability to  \ninvestigate cybercrimes.44 These hackers are “moral agents, possessing a sense of justice \npurpose, and identity” who take responsibility for their actions.45 They are, however, apt to \njustify attacks: blaming victims for not securing their computers or minimizing the amount of \nharm they have caused.46 Importantly, most juvenile and young adult offenders tend to “age out \nof crime.”47 Numerous criminal hackers transition from cybercrime to cybersecurity, where the \nsame skills they’ve acquired can be used t o protect rather than harm.48 In fact, it is generally a \nprerequisite in the cybersecurity community to have been a hacker to understand how to defend \nagainst attackers .49 This is because the methods and tools utilized by attackers are also used by \nresearchers to discover vulnerabilities before they can be exploited by those attackers.  \nC. The Methods and Tools Used by H ackers are M orally Agnostic . \nHackers use a multitude of security tools to find vulnerabilities. Port and networking \nscanning is a method for scanning servers on the internet to check for open ports – essentially channels by which computers communicate.\n50 Certain open ports can be indicative of a \nmisconfiguration on the server or other potential vulnerabilities , and therefore , port scanning is a \nhighly effective tool for testing network security and the efficacy of a network’s firewall.51 Both \nresearchers and attackers scan the internet for these misconfigurations or vulnerabilities , only \ndiffering in what they intend to do once they find one : researchers responsibly disclose their \nfindings, while attackers seek to exploit  them . Hackers also utilize d ata scr aping and automated \n \n44 Id. at 292 . \n45 Id. at 293 ( noting that undeserving targets are left alone while target those believed to be deserving ). \n46 Id.  \n47 Id. \n48 Id. at 295 . \n49 Id. at 89 . \n50 See supra note 7, at 20. \n51 Id. \n\n \n158  access testing , a method by which a script can automatically access all of a website’s available \ndirectories.52 These tools can find portions of websites that were not intended to be publicly \navailable and , therefore , provide  access to potentially private or sensitive information.53 Reverse \nengineering and code inspection all ows hackers to examine source code and work backwards to \ndetermine how the software and computer systems function.54 This method allows hackers to \nfind potential code or computer system  vulnerabilities .55 What they choose to do after \ndiscovering vulnerabilities is ultimately what defines a hacker as a researcher or an attacker. \nAnother method that hackers  utilize is  brute force attacks to guess passwords. Brute forcing can \nbe used by an attacker to gain unauthorized access to an account , or it can be used by a \nresearcher to check if default passwords were not changed in a system , presenting a significant \nrisk of breach or exploitation by an attacker.56 Additionally, hackers can utilize a security testing \nmethod known as “fuzzing.”57 Fuzzing is an automated process by which “junk inputs” are \nthrown at a computer system , causing it to crash or otherwise have the system respond in an \nunintended way , thereby exposing vulnerabilities.58 This list is by no means exhaustive.59 One \nimportant takeaway is that these tools and methods are morally agnostic: it is the intent of the person using them that determines whether they are used to cause or prevent harm.\n60 The CFA A, \n \n52 Id. at 18.  \n53 Id. \n54 Id. at 21; see also  Source Code , WIKIPEDIA , https://en.wikipedia.org/wiki/Source_code  (last accessed Dec. 8, \n2024), [https://perma.cc/P9A4 -27UW ]. \n55 Id. \n56  Brute Force Attack, OWASP, https://owasp.org/www -community/attacks/Brute_force_attack (last visited Dec. 8, \n2024), [https://perma.cc/ RCU6 -RSF3 ] (describing how attackers utilize brute force attacks); but see  An Overview of \nthe Usage of Default Passwords , Elec. & Computer Eng'g & Computer Sci. Fac. Pubs. (2018), \nhttps://digitalcommons.newhaven.edu/cgi/viewcontent.cgi?article=1070&context=electricalcomputerengineering-\nfacpubs, [https://perma.cc/7L4R -Z88P ] (describing breaches exploiting default user credentials and tests showing \nthat default passwords remain a significant problem).  \n57 See s upra note 3, at 158.  \n58 Id.  \n59 Security Hacker , WIKIPEDIA , https://en.wikipedia.org/wiki/Security_hacker#Techniques , \n[https://perma.cc/8C5D -9ZPG ]. \n60 Shapiro, s upra note 31, at  159. \n\n \n159  however, does not consider  a hacker’s motivations  or the purpose behind the methods and tools \nutilized by hackers, leaving both malicious attackers and benevolent researchers caught in its \nwake.  \nIII. THE CFAA  PROVID ES CORPORATIONS  IMMUNITY  FROM CIVIL LIABILITY AND SHIFTS THE \nCOST OF CYBERCRIME  TO EVERYONE ELSE . \nEstimates of the cost of cybercrime have risen from an estimated 1 billion dollars at the \nenactment of the CFAA to 452 billion dollars in 2024 with estimates up to 1.8 trillion dollars by \n2028.61 During this time , software and hardware vulnerabilities have increased dramatically. \nSince tracking began in 1999, the number of Common Vulnerabilities and Exposures (CVE) that \nhave been published has risen from 321 in 1999 to 28,961 in 2023.62 Through three quarters in \n2024, the number of reported vulnerabilities is at 29,004 making it a record year with an additional quarter yet to be reported.\n63 The number of security incidents that make use of \nsoftware vulnerabilities continues to rise.64 Havibeenpwned.com, a website that tracks website \nbreaches and the exposed account information obtained in those breaches, has 834 breaches listed in its database consisting of over 14 billion compromised accounts .\n65 Personal information \nexposed in these breaches include s names, passwords, physical addresses, dates of birth, \nemployers, government -issued IDs, and social security numbers.66 Many of these data breaches \noccurred because attackers e xploit ed vulnerabilities in the company’s software or hardware.67 \n \n61 Ani Petrosyan,  Annual Number of Data Compromises and Individuals Impacted in the United States from 2005 to \n2023, STATISTA  (Feb. 12, 2024), https://www.statista.com/forecasts/1399040/us -cybercrime- cost-annual  \n[https://perma.cc/9F2N -RJ27 ]. \n62Metrics , CVE , https://www.cve.org/about/Metrics , [https://perma.cc/3RSK -KVHT ]. \n63 Id. \n64  Id. at 61.  \n65 HA VEIBEENPWNDED, https://haveibeenpwned.com , [https://perma.cc/Y3DF -MC3J ] \n66 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites  [https://perma.cc/54PV -B5ZU ]. \n67 Id. \n\n \n160  In 2013, a data breach containing information for 153 million Adobe accounts was posted \nonline.68 While the passwords for accounts in the dataset were encrypted, poor cryptography \nallowed them to be easily converted back to plain text.69 In 2018, a database containing billions \nof data record s for Apollo was compromised.70 The database was publicly available on the \ninternet and did not require a password to access  it.71 In 2019, verifications.io, an email address \nvalidation service, suffered a breach exposing personal information of over 750 million users.72 \nSimilar to the Apollo breach, a database was public -facing without requiring a password.73 In \n2021, a Facebook hack compromised the data of over 500 million users.74 The information was \nallegedly obtained by exploiting a vulnerability that Facebook had claimed to have fixed two \nyears prior.75 In 2022, a vulnerability in the Twitter site allowed information on over 6 million \nusers  to be extracted .76 The vulnerability was introduced in a June 2021 update to their code.77 In \n2024, user data for almost 50 million AT&T customers was published online.78 AT&T denied \nthat there was a data breach for nearly  2 weeks before acknowledging that the breach did \nhappen.79 In all of these instances, the CFAA immunizes the negligence of corporations \n \n68 Breached Websites that H ave Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#Adobe  [https://perma.cc/A5CF -J28S ]. (listing breaches  in the \nfollowing paragraph as by no means exhaustive, but just a quick highlight of breaches that occurred because of poor \nsecurity practices) . \n69 Id. \n70 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#Apollo [https://perma.cc/A5CF -J28S ]. \n71 Id. \n72 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#VerificationsIO  [https://perma.cc/A5CF -J28S ]. \n73 Id. \n74 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#Facebook [https://perma.cc/A5CF -J28S ]. \n75 Id. \n76 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#Twitter  [https://perma.cc/A5CF -J28S ]. \n77 Id. \n78 Breached Websites that Have Been Loaded into Have I Been Pwned, HA VEIBEENPWNDED , \nhttps://haveibeenpwned.com/PwnedWebsites#AllegedATT  [https://perma.cc/A5CF -J28S ]. \n79 Id. \n\n \n161  responsible for the breaches. Even when a corporation is breached due to a vulnerability in the \nsoftware or hardware of a vendor, under the CFAA , those vendors face no civil liability for the \ndamage those vulnerabilities caused. Spending on cybersecurity increases every year – project ed \nto reach $215 billion in 2024 – and yet the number of breaches every year continues to rise.80 \nWhile the correlation between the increase in software vulnerabilities and the increase in data breaches does not necessarily give rise to causation, it’s not too far of a leap to think that if the computer industry were to release software with fewer  vulnerabilities in their products , fewer \nwould be able to be exploited in data breaches.  \nHowever, this is not our reality; software vendors consistently release products and \nsoftware with vulnerabilities .\n81 Even if vendors release fixes once a vulnerability is  discovered , \nrisk remains ; not all vulnerabilities are known and patched before they are exploited by \nattackers.82 It's estimated that 80 percent of intrusions into federal computer systems are \nattributable to software errors, or poor -quality software.83 And despite the growing number of \nvulnerabilities, breaches , and cost s associated with software vulnerabilities, the time and effort \nspent on software security is declining.84 Sammy Migues, principal at Imbricate Security and co-\nauthor of the Building Security in Maturity Model (BSIMM) report, notes that companies tend to think of security vulnerabilities as “shrinkage” and until “shrinkage of revenue from software \n \n80 David Malmstrom, Data Breach Securities Class Actions: Record Settlements and Investor Clams on the Rise, \nHarvard Law School Forum on Corporate Governance  (Aug. 21, 2024) , \nhttps://corpgov.law.harvard.edu/2024/08/21/data -breach -securities -class -actions -record -settlements -and-investor -\nclaims -on-the-rise/#4  [https://perma.cc/KW2E -RMK3 ]. \n81 See supra note 38, at 484. (citing C lay Wilson , Computer  Attack and C yber Terrorism: Vulnerabilities and P olicy \nIssues for C ongress  5, CRS REPORT FOR CONGRESS  (2003).  \n82 Id.  \n83 Id. at 485 . \n84 Taylor Armerding, Zero-day software defects are leading to many very bad days,  NERD FOR TECH (Oct. 28, \n2024), https://medium.com/nerd -for-tech/zero -day-software -defects -are-leading -to-many -very-bad-days-\nc1d9d032ad63 [https://perma.cc/H9JY -CKGN] . \n\n \n162  defects broadly hits unacceptable levels, there won’t be a lot of change.”85 Companies f acing no \nliability for hardware and software vulnerabilities will surely  not lead to this change. In fact, \nthose in the cybersecurity industry have recently taken Microsoft to task for using one of their \nown security flaws as an opportunity to upsell customers on their own security offerings.86 While \ncertainly not alone in the computer industry , Microsoft has a sordid history of releasing buggy \nproducts that are exploited by attackers.  \n In 1994, Microsoft found itself scrambling to catch up to competitors like Netscape, \nwhich was already beginning to showcase the power of the internet .87 A potential nightmare \nscenario was upon Microsoft: a world where consumers preferred competitor s’ less expensive \nhardware with the  Netscape web browser providing access to the internet, forgoing the more \nexpensive machines running the Microsoft Windows operating system.88 By mid -1994, \ncompared to the year prior, the number of websites grew from 2,700 to 23,500, almost \nexclusively run on the UNIX operating system running on Java.89 Crucially, Microsoft was \nvirtually nowhere to be found on the internet.90 Microsoft had some serious ground to cover  and \nthey did just that.91 Congress’s expectation that industry would safeguard its products and \nactively prevent  cybercrime was soon forgotten.  \nIn an effort to catch Netscape, Microsoft added the internet into almost all aspects of the \nWindows operating system, including a web browser, Internet Explorer, in their latest version, \n \n85 Id. \n86 Alex Stamos, Microsoft’s Dangerous Addiction to Security Revenue, SentinelOne  (Jan. 31, 2024), \nhttps://www.sentinelone.com/blog/microsofts -dangerous -addiction -to-security -revenue/   \n87 Id. at 141 . \n88 Id. at 143 . \n89 Id. at 142 ( noting that Java was a programming language developed by Sun Microsystems) . \n90 Id. at 143 ( noting in a memo to employees, Bill Gates, after 10 hours of web browsing, discovered  there were \nvirtually no Microsoft file formats to be found on the internet) . \n91 Id. at 144 . \n\n \n163  Windows 95.92 Previously, security was  not a  substantial concern for Microsoft as its main \nproduct, Windows, was for personal computers: this new push for internet connectivity would \nexpose the vulnerabilities in the operating system and applications.93 While security concerns \nwere considered , they paled in comparison to the pressure to incorporate the I nternet into every \naspect of the new Windows 95 operating system; the push for I nternet features in lieu of security \nconsideration would have disastrous consequences.94 Rushed development and poor coding \npractices were exploited mercilessly.95 Rather than working to prevent cybercrime, Microsoft, in \nreleasing poorly tested software and the vulnerabilities that came with it, would become the leading enabler of cybercrime.  \nVulnerabilities in Outlook and Word would wreak havoc on the internet.\n96 Viruses hidden \nin macros -enabled Word documents were sent out via email and , when opened by the recipient , \nwould automatically run the hidden code and send to the recipient ’s contacts.97 While initially \nthese virus es were not destructive, the volume of emails  caused servers to become overwhelmed \nand soon unresponsive.98 Later variations were much more harmful. A particularly nasty attack, \nnamed ILOVEYOU, deleted every image file it could find, hid files, and renamed files, inserting its code, to be run again when users tried to open the infected files.\n99 The virus took advantage of \na flaw in Outlook whereby the application did not read the entirety of a file name and a flaw in \nWindows that allowed code in email attachments to run automatically upon clicking.100 The virus \n \n92 Shapiro,  supra note 31, at 144.  \n93 Id. \n94 Id. \n95 Id. \n96 Id. at 146 . \n97 Id. at 147 . \n98 Id.  \n99 Id. at 149 . \n100 Id. (explaining that the file was named “LOVE -LETTER -FOR -YOU.TXT.vbs” which denote d it is a file that \ncontains code, but Outlook stopped parsing the filename after the first period, making it appear to be  an innocuous \ntext file) . \n\n \n164  spread faster than anything in history to that point, causing networks to become unresponsive: it \nwas estimated that 10 percent of the world’s computers were infected with a total cost approaching 10 billion dollars.\n101 The Windows operating system did nothing to stop the virus \nfrom deleting files and spreading with impunity.102 Microsoft wasn’t held financially responsible \nfor rampant abuse of vulnerabilities and the damage they cause d, but Bill Gates did release a \nmemo at least acknowledging the poor security practices and a plan to fix them.103 \nUnfortunately, this wasn’t the first time  vulnerabilities in software products  were easily exploited \ncausing the internet to come to a halt. In fact, over a decade earlier the computer industry was put on notice, but the first CFAA prosecution made one thing clear: companies would not bear the responsibility for the harm their insecure products caused.  \nA. The First  CFAA Conviction Puts Security Research  on Notice  \nThe first prosecution under the CFAA was not an attacker seeking to do harm but a young \ncomputer scientist exploring the then -young internet as part of his PhD thesis\n104. Robert Morris \nJr. was a graduate student at Cornell University in the school’s computer science program105. As \npart of his role as the school’s system administrator , he discovered a major security flaw in the \nUNIX operating system that could be exploited over the internet.106 He shared this discovery \nwith a friend , and neither had ever heard of a program being used to spread on the internet \nbefore.107 Morris carefully ensured  that his code didn’t risk destroying data  before releasing the \n \n101 Id. \n102 Id. \n103 Gates, supra note 6. \n104 Shapiro, supra note 31, at 71.  \n105 Id. at 4. \n106 Id. at 71.  \n107 Id. (noting Morris decided to showcase the flaws for his PhD thesis, and thus “the brilliant project”, as they called \nit, was born. As history would have it the project, a scientific endeavor as far as Morris was concerned, would come \nto know Morris’s discoveries by a  different name: “The Morris Worm”) . \n\n \n165  program on the internet .108 Within hours of releasing the internet worm, Morris realized there \nwas a problem.109 Due to a miscalculation in his program, numerous networks across the country \nwere offline.110 \nThe FBI opened an investigation against Robert Morris Jr.,  but they were unsure of  how  \nto proceed.111 Nobody had yet been tried under the CFAA , and the language of the CFAA did not \nmake it clear under what section Morris  should be charged.112 Ultimately, the government \nelected to charge Morris  with a felony , given the amount of damage his actions had caused.113  \nAt his trial, Morris  argued that the CFAA required dual intent : both intent  to access a \ncomputer and intent to cause damage.114 The trial court judge disagreed with Morris’ reading of \nthe law, instead giving the jury instructions that the government need not prove Morris  intended \nto cause damage, only that he intended to release the worm.115 The juror delivered a unanimous \nguilty verdict.116  \n \n108 Id. at 71 ( noting that, a ccording to Paul Graham’s testimony, any feature that risked destroying data was out of \nthe question) . \n109 Id. (noting that the  worm worked by exploiting four vulnerabilities in the UNIX operating system that allowed it \nto rapidly spread across the young internet. As careful as he was, Morris made one miscalculation in his \nprogramming. The worm was set to check if a computer was a lready infected with the worm to ensure that the worm \nwould not reinfect the same computer more than once, but just in case network administrators tried to delete the \nprogram, Morris included instructions to have the worm automatically install itself every seventh time. Had Robert \nchosen a lower reinfection rate, say 1 in 700, “the worm would have spread harmlessly and the brilliant project \nwould have succeeded brilliantly”) . \n110 Id. at 4 ( listing affected networks  includ ing Cornell, the University of Pittsburgh, the RAND corporation, the \nUniversity of Minnesota, the Stanford Research Institute, the University of Utah, the Lawrence Livermore National \nLaboratory, the Los Alamos National Laboratory, and NASA Ames Research Center ). \n111 Id. at 32.  \n112 Id. at 56 ( explaining that t he Department of Justice could either charge Morris with a misdemeanor under section \n(a)(3) for unauthorized access to a government computer or with a felony under section (a)(5) for unauthorized intrusions that caused $1,000 or more in damages. At the tim e it was unclear whether an individual needed to both \nintentionally access a computer and intentionally cause damage) . \n113 Id. 56-57, 70 ( noting that damages under the CFAA can be aggregated and thus the damage was calculated based \non all system administrators work in eliminating the worm, patching their systems, and bringing them back online. \nThe total damage was estimated to be $475,000) . \n114 Id. at 60 . \n115 Id. at 74 . \n116 Id. \n\n \n166  B. Precedent  is Set, Leaving R esearchers L iable  for Any D amage C ause d by U nauthorized \nAccess to C omputers . \nMorris appealed his conviction, continuing his argument that the CFAA required intent \nfor both unauthorized access and intent to cause damage.117 Morris argued that the Senate and \nHouse comments supported his position.118 Specifically , he pointed to the Senate Report stating \nthat \"the new subsection 1030(a)(5) to be created by the bill is designed to penalize those who \nintentionally alter, damage, or destroy  certain computerized data belonging to another.\"119 The \nHouse Judiciary Committee stated that a new section to the CFAA “can be characterized as a ‘malicious damage’  felony violation involving a Federal interest computer.”\n120 Finally, Morris \nnoted that a member of the House Judiciary Committee referred to the offense as “ ’malicious \ndamage’  felony during the floor debate.”121 Unfortunately for Morris , the Second Circuit Court \nof Appeals disagreed, holding that “[d]espite some isolated language in the legislative history \nthat arguably suggests a scienter component for the ‘ damages ’ phrase […], the wording, \nstructure, and purpose of the subsection, […] persuade us that the ’ intentionally ’ standard applies \nonly to the ’ accesses ’ phrase of  section 1030(a)(5)(A), and not to its ’ damages ’ phrase .”122 \nMorris’ conviction was upheld, and with it, a message was sent: hackers are criminally liable for any and all damages that result from intentional unauthorized access to a computer.\n123 Morris \nwas the first person charged and convicted under the CFAA, despite the  good intentions for \nundertaking his project. While the law and its interpretation by the courts were rigid, history \nwould be much kinder to Morris and the importance of cybersecurity that his work underscored.  \n \n117 United States v. Morris , 928 F.2d 504, 505  (2d Cir. 1991) . \n118 Id. at 508 . \n119 Id. (citing Senate Report at 10, U.S. Code Cong. & Admin. News at 2488)(emphasis added) . \n120 Id. (citing H.R. Rep. No. 99 -612, 99th Cong. 2d Sess. at 7 (1986)) (emphasis added) . \n121 Id. (citing 132 Cong. Rec. H3275, 3276 (daily ed. June 3, 1986) (remarks of Rep. Hughes) ) (emphasis added) . \n122 Id. at 509.  \n123 Id. at 511 . \n\n \n167  C. Robert Morris Births an Industry  \nThe computer community was fractured over Morris’ actions.124 Some did not see Morris \nas the folk hero that did the world a favor for exposing the flaws in the system and refused to \naccept that it was the computer community's fault for not fixing the flaws sooner.125 Others \nnoting that Morris’ actions were not malicious, praised him for exposing vulnerabilities and poor practices of network administration thereby making the internet safer.\n126 One supporter \n“predicted that history would vindicate Morris: ‘When all is said and done, this kid is going to come down as a folk hero.’”\n127 \nIndeed, history has been kind to Morris . The FBI credits  the Morris Worm and the \nvulnerabilities it exposed with almost independently launching the cybersecurity industry.128 \nWithin days of the launch of the Morris Worm the Department of Defense set up the country’s first computer emergency response team:\n129 the CERT/CC at Carnegie Mellon University.130  \nDevelopers began creating computer intrusion detection software.131 Network administrators \nbegan utilizing firewalls to protect their networks.132 Companies began implementing password \nmanagement systems.133 Ironically, Morris achieved the mission he set out on for his PhD thesis  \nand opened the world’s eyes to the importance of cybersecurity.134 While new measures are now \n \n124 Shapiro, supra note 31,  at 48 . \n125 Id. (A sentiment that is still used today to silence cybersecurity researchers) . \n126 Id. at 49 . \n127 Id. \n128 The Morris Worm, 30 Years Since First Major Attack on the Internet , FBI (Nov. 2, 2018), \nhttps://www.fbi.gov/news/stories/morris -worm -30-years -since -first-major -attack -on-internet- 110218.  \n129 Id. \n130 Wikipedia. https://en.wikipedia.org/wiki/CERT_Coordination_Center#History  \n131 Id. \n132 What is the Morris Worm? History and Modern Impact , OKTA ( Aug. 29, 2024), https://www.okta.com/identity -\n101/morris -worm/  [https://perma.cc/9UBN -QEJC].  \n133 Id. \n134 Id. \n\n \n168  taken to protect computer s from vulnerabilities , the creators of these vulnerabilities  remain \nlargely immune from any liability for the damage their creations cause.  \nIV. THE CFAA  CHILLS NECESSARY SECURITY RESEARCH . \nThe broad language and scope of the CFAA provides  myriad ways a researcher may find \nthemselves criminally prosecuted and civilly liable,  which has led to a chilling effect on \ncybersecurity research. I n a study by the Center for Democracy & Technology , Participants \n(researchers and hackers) listed  the CFAA as the primary source of risk in their research.135 Over \nhalf of those respondents reported forgoing some research or avoiding research altogether that \nmight bring liability under the CFAA.136 A large majority of concerns stemmed from the \nuncertainty around the definition of the term “ access ”, which remains undefined in the CFAA .137  \nThe uncertainty of the extent  of CFAA applicability has forced researchers to first investigate \nthe legal implication s of their work before acting. For instance, when launching a community -led \nproject to improve internet security, Rapid7, a cybersecurity -focused corporation, recommended \nthat anyone planning on contributing to the project first consult an attorney , noting it’s \n \n135 Joseph Lorenzo Hall  & Stan Adams, Taking the Pulse of Hacking: A Risk Basis for Security Research , Ctr. for \nDemocracy & Tech ., March 2018 , at 9 . \n136 Id. \n137 Id. (“What this means for researchers is that, when they wish to interface with another machine or system, it is \nnot always clear what they can do. One researcher noted that some servers were configured in a way that essentially \nallowed unfettered public acces s, making it impossible to determine what kinds of access the server’s owner \nintended. One researcher reported trying to avoid implicating the CFAA while researching onboard vehicle \ndiagnostic systems where the car was also connected to the manufacturer’s servers because of uncertainty about the \nbounds of authorized access. One subject indicated uncertainty as to how the CFAA might apply to accessing \nmalware hosts. Another noted that, in certain scanning exercises, there was no method by which operators could \nsignal whether or not they authorized access to information on their systems. As a result, the researcher was forced to choose between not conducting the research or potentially  running afoul  of the CFAA. Although network \nscanning has, as one subject notes, become a standard practice, many researchers employ methods to make their web \ntraffic readily identifiable to allow operators to send opt- out messages. Another subject noted preference for a \nmethod of scanning which results in obtaining zero data, thereby leaving that element of Section 1030(a)(2)(C) \nunsatisfied.”) . \n\n \n169  impossible to know if scanning computers on the internet won’t be violative of the CFAA.138 It’s \nimpossible to know the number of researchers that elected to not contribute to the project, but \neven if it was just one, that’s one less person working to make the internet a more secure space. In this way, the CFAA contributes to the problems faced by the world today by forcing researchers trying to improve cybersecurity to sit on the sidelines while cybercrime continues to increase.   \nTo assist researchers in navigating the legal landscape created  in part  by the CFAA, the \nElectronic Frontier Foundation (EFF) created the Coders’ Rights Project.\n139 The vulnerability \nreporting FAQ l ists ten things a researcher must consider w hen publishing vulnerability \ninformation to limit legal risks. Even these are no guarantee, and researchers remain at risk of retaliation for disclosing vulnerabilities.  \nIn one case, MIT researchers who discovered security vulnerabilities in a mobile voting \nplatform chose  to first disclose their findings to the Department of Homeland Services in an \nattempt to protect themselves from retaliation from the platform’s creator.\n140 In another instance, \nresearchers  discovered a flaw in another voting system that could allow attackers to change votes \nwithout detection.141 Despite the seriousness of their findings , they were forced to limit their \nresearch to only publicly facing aspects of the voting system to  limit their legal risk.142 History \n \n138 Marcia Hofman n, Legal Considerations  for Widespread Scanning,  RAPID7 (Oct. 30, 2013), \nhttps://www.rapid7.com/blog/post/2013/10/30/legal -considerations -for-widespread -scanning/  \n[https://perma.cc/K53W -33GA ]. \n139 Coders’ Rights Project , EFF, https://www.eff.org/issues/coders  [https://perma.cc/3TWM -7C9Y ] (last visited  Dec. \n18, 2024) . \n140 Brief of Amicus Curiae Computer Security Researchers , Electronic Frontier Foundation, Center for Democracy \n& Technology, Bugcrowd, Rapid7, Scythe , and Tenable in Support of Petitioner , Van Buren, 141 S. Ct. 1648, 210 L. \nEd. 2d 26, 2020 WL 4005654 at 29. (In addition to having already s ought  legal assistance from the MIT \nTechnology Law Clinic.) . \n141 Id at 10. \n142 Id at 32 . \n\n \n170  had already provided ample reason for these and other security researchers to limit their research \nor otherwise take extraordinary steps in disclosing their findings. \nIn 2008, t hree students at MIT discovered vulnerabilities in  the Massachusetts Bay \nTransit Authority’s (MBTA) ticketing system.143 The students planned to showcase their findings \nat DEFCON, a computer security conference in Las Vegas . 144 The MBTA filed  a lawsuit \nclaiming, among other things, violations of the CFAA.145 Before  the students presentation at \nDEFCON, the court issued a temporary restraining order preventing the students from “providing program, information, software code, or command that would assist another in any material way to circumvent or otherwise attack the  of the Fare Media System.”\n146 The order  \n“pre-emptively gagging security researche rs” was unprecedented according the EFF .147 The \ncharges were eventually dismissed in 2009, but highlighted the legal risk faced by researchers . \nIn 2010, Andrew  Auernheimer disclosed a  vulnerability in AT&T servers to media outlet \nValleywag , which included over 114,000 email addresses.148 Auernheimer was charged under \n \n143 Jon Choate, MBTA v. Anderson: D. Mass: MIT Students' Security Presentation Merits Temporary Restraining \nOrder , Jolt Digest (Aug. 15, 2008), http://jolt.law.harvard.edu/digest/mbta -v-anderson  [https://perma.cc/9GL9 -\n64KZ ] (The students showed that vulnerabilities with the system allowed the CharlieCards to reprogrammed, \nallowing the money stored on the cards to be increased to $600. They were also able to show that the cards could be \nread by non- MBTA equipment and this cou pled with software written by the students allowed for the cards’ \nencryption to decrypted.) . \n144 Call the cops on second thought, Scientific American (Aug. 14, 2008), \nhttp://www.scientificamerican.com/blog/post.cfm?id=call- the-cops-on-second -thought -don-2008- 08-14 \n(https://web.archive.org/web/20110320041140/http://www.scientificamerican.com/blog/post.cfm?id=call -the-cops-\non-second -thought -don-2008- 08-14). \n145 Massachusetts Bay Transportation Authority v. Anderson et al. , No. 1:2008cv11364 (D. Mass . Aug . 10, 2008)  \n(Just ia). \n146 Temporary Restraining Order, Massach usetts Bay Transportation Authority , No. 1:2008cv 11364 at 2 (the Fare \nMedia System was the third -party employed by the MBTA for managing fare tracking, charging, and fare collection)  \n(Justia ). \n147Declan McCullagh, Judge orders halt to Defcon speech on subway card hacking, CNET (Aug. 9, 2008),  \nhttp://news.cnet.com/8301 -1009_3 -10012612- 83.html \n(https://web.archive.org/web/20090925032115/http://news.cnet.com/8301- 1009_3 -10012612- 83.html ). \n148Timothy B. Lee, Internet troll “weev” sentenced to  41 months for AT&T/iPad hack,  Ars Technica (Mar. 18, 2013 \n11:35 AM), https://arstechnica.com/tech -policy/2013/03/auernheimer -aka-weev -sentenced -to-41-months -for-attipad -\nhack/ (Daniel Spitler discovered the security flaw in AT&T servers that disclosed iPad user’s email addresses when \nsent a unique ICC -ID – the serial number for a SIM card associated with AT&T network. AT&T fixed the \n \n\n \n171  section 18 U.S.C 1030(a)(2)(C), among others, for obtaining information from a protected \ncomputer without authorization.149 Auernheimer argued that he “served the public by exposing \nAT&T’s non -existent security and cavalier disregard of its customer’s information.”150 Despite \nthe customer information  being exposed on a public -facing  web page, AT&T did not intend for \nthe information to be public, so Auernheimer’s discovery and disclosure of the information was  \ndeemed  without authorization and in violation of the CFAA .151 That the CFAA criminalized \nAuernheimer for notifying the public that their private information was publicly exposed rather than AT&T for exposing it can only be described as Kafkaesque. After failing to get the charges dismissed, Auernheimer was convicted and sentenced to 41 months in prison in 2012.\n152 Again , \nthe broad language and scope of the CFFA provided wide latitude for criminal prosecution.153   \nA. Recent Legal Developments Provide some Protections but D on’t G o Far Enough to P rotect \nResearchers . \nRecent decisions and policy changes have served to provide some protection to \nresearchers from criminal prosecution . Those decisions only had an ancillary impact on \nresearchers as they were not addressing the specific use cases for when a researcher might find themselves in violation of the CFAA. However, they did force the Department of Justice to \n \nmisconfiguration on their servers, but there was no way of knowing whether attackers took advantage of the \nmisconfiguration prior to its patching.) . \n149 United States v. Auernheimer , No. 11 -cr-470 (SDW), 2012 U.S. Dist. LEXIS 158849 at 2 (D.N.J. Oct. 26, \n2012) . \n150 Id. at 20. \n151 Karen McVeigh, Hacker Andrew ‘Weev’ Auernheimer attempts to overturn conviction , The Guardian (Mar. 19, \n2014, 8:54 EDT), https://www.theguardian.com/technology/2014/mar/19/hacker -andrew -auernheimer -try-overturn-\nconviction [https://perma.cc/8G22 -KFJD ]. \n152Joe Silver, “Weev” prosecutor admits: I don’t understand what the hacker’ s co- conspirator did, Ars Technica \n(Mar. 20, 2014, 2:40 PM), https://arstechnica.com/tech -policy/2014/03/lawyers -for-self-described -hacker -weev -\ncontest -his-computer -fraud -conviction/ (reporting that on appeal, Auernheimer argued the CFAA should not apply \nbecause visiting a public webpage did not bypass code -based security, but the court vacated his conviction on \njurisdictional grounds, leaving the CFAA issue unresolved. ). \n153 Id.; see also  note152 (reporting Hanni Fakhoury, staff attorney at the EFF, believed Auernheimer's case was an \nexample of a prosecution aimed at a person, not a crime .) \n\n \n172  reconsider and update their charging policy for “good faith security researchers.” These are steps \nin the right direction, but as soon discussed, they do not go far enough to protect researchers from criminal liability and are silent on civil liability.  \n1. Van Buren Limits Some Risks but L eaves M any Q uestions U nanswered.  \nIn 2021, the Supreme Court addressed the scope of the CFAA  for the first time .\"\n154 The \nCourt  held that the \"exceeds authorized access\" clause of the CFAA applies only when an \nindividual “accesses a computer with authorization but then obtains information located in \nparticular areas of the computer —such as files, folders, or databases —that are off -limits to \nthem”155. The Court rejected the government's broader interpretation, which would have \ncriminalized violations of purpose -based restrictions on access.156 The majority reasoned that \naccepting the government's interpretation would attach criminal penalties to a “breathtaking \namount of commonplace computer activity” and allow private parties to make violations of the \nCFAA via their computer -use policies.157 However,  in a footnote, the Court declined to address \nwhether access  violations of the CFAA  should rely on “technological (or “code -based”) \nlimitations on access, or instead also looks to limits contained in contracts or policies.”158 While \nthe Court narrowed the scope of the CFAA with its ruling, as discussed, the majority of the researchers ’ activities can be deemed to be “without authorization ,” which the Court did not \naddress. Additionally, the re is a risk of liability under contract theory or corporate policies, as the \n \n154 Van Buren v. United States , 593 U.S. 374, 381 (2021).  (involving Nathan Van Buren, a police sergeant in Georgia, \nwho used his authorized access to a law enforcement database to retrieve information about a license plate in \nexchange for money from an acquaintance.) . \n155 Id. \n156 Id. at 390.  (citing  United States v. Rodriguez , 628 F. 3d 1258 (CA11 2010); United States v. John, 597 F. 3d 263 \n(CA5 2010); Int'l Airport Ctrs., L.L.C. v. Citrin , 440 F. 3d 418 (CA7 2006); EF Cultural Travel BV v. Explorica, \nInc., 274 F. 3d 577 (CA1 2001); but see Royal Truck & Trailer Sales & Serv., Inc. v. Kraft, 974 F. 3d 756 (CA6 \n2020 ); United States v. Valle, 807 F. 3d 508 (CA2 2015);  WEC Carolina Energy Solutions LLC v. Miller , 687 F. 3d \n199 (CA4 2012);  United States v. Nosal, 676 F. 3d 854 (CA9 2012).)  \n157 Id.at 376. \n158 Id. at 408 . \n\n \n173  Court declined to require that a technological barrier  be bypassed as the amicus brief submitted \nby computer security researchers had  hoped for .159 \n2. The Ninth Circuit L imits CF AA ’s Liability for Accessing P ublic I nformation. \nIn 2022, the Ninth Circuit Court of Appeals, on remand in light of its recent Van Buren \ndecision, addressed the application of the CFAA to web scraping of publicly available data.160 \nThe court was left to decide whether hiQ's continued scraping of LinkedIn's public data after \nreceiving the cease- and-desist letter constituted accessing a computer \"without authorization\" \nunder the CFAA.161 The court, in its second decision on this case following a remand from the \nSupreme Court to reconsider in light of Van Buren v. United States, held that hiQ's scraping of public LinkedIn profiles did not violate the CFAA. The court reasoned that the CFAA's \"without authorization\" provision is best understood as applying only to private information that requires permission or authentication to access.\n162 The court held that the CFAA distinguishes between \nthree different kinds of computer systems: “(1) computers for which access is open to the general public and permission is not required, (2) computers for which authorization is required and has been give n, and (3) computers for which authorization is required but has not been given.”\n163 \nSince LinkedIn's member profiles were public and did not require authorization to view , they fell \nwithin the first category of computers, and thus , the court concluded that the CFAA did not apply \nto hiQ's scraping activities .164 The decision emphasized that the CFAA was primarily designed to \ncombat hacking and unauthorized access to private information, not to police the use of public \n \n159 Supra note 7, at 17.  \n160 hiQ Labs, Inc. v. LinkedIn Corp. , 31 F.4th 1180 (9th Cir. 2022)  (involving a data analytics company, that scraped \npublic profile information from LinkedIn's website until LinkedIn sent a cease- and-desist letter and implemented \ntechnical measures to prevent scraping.) . \n161 Id. at 1195 . \n162 Id. at 1201 . \n163 Id. at 1197 -98. \n164 Id.  \n\n \n174  data.165 The ruling implies that if information is publicly available on a website without \nauthentication or password protection, a violation of the terms of service or defiance of a cease -\nand-desist letter will not give rise to liability under the CFAA. 166  While the ruling is a good start \nin protecting researchers, but this is just one circuit that has further narrowed the applicability of \nthe CFAA. Questions still remain whether other circuits will come to the same conclusion , \nleaving researchers in the  same limbo that split circuit courts had forced the Supreme Court to \ninterpret in Van Buren v. United States . 2022 was a banner year for attempts to limit research \nliability under the CFAA and the courts weren’t the only ones to get in on the action.  \n3. DOJ P olicy Shields “ Good-Faith” R esearchers from C riminal P rosecution. \nIn 2022, the Department of Justice (DOJ) announced a new policy of no longer charg ing \nsecurity researchers acting in “good faith” with CFAA violations.167 The policy change was  \npartially p rompted by the Supreme Court’s ruling in Van Buren and , like the Court , falls short of \nrequiring the defeat of a technical limitation for computer access to be unauthorized.168 This \nmeans that written policies, “such as when an employee violates a contract that puts certain files \noff limits in all situations, or when an outsider receives a cease -and-desist (C&Ds) letter \ninforming them that their access is now unauthorized,” may still give rise to criminal prosecution \n \n165 Id. at 1201 . \n166 Id. at 1200 (While this article is solely focused on the risk the CFAA imposes on researchers , the court noted \nother causes of action available to “victims of data scraping ” including  trespass to chattel s, copyright infringement, \nmisappropriation, unjust enrichment, conversion, breach of contract, or breach of privacy. ). \n167 9-48.000 – Computer Fraud and Abuse Act, https://www.justice.gov/opa/press -release/file/1507126/dl \nhttps://perma.cc/4H22 -8CUT  . \n168 Andre Crocker, DOJ’ s New CF AA Policy is a Good Start But Does Not Go Far Enough to Protect Security \nResearchers , EFF (May 19, 2022), https://www.eff.org/deeplinks/2022/05/dojs -new-cfaa-policy -good -start-does-\nnot-go-far-enough -protect -security  [https://perma.cc/X85Y -KBW8 ]. \n\n \n175  under the CFAA.169 Additionally, the new policy isn’t binding on the courts and can be rescinded \nat any time.170 Even if it were, what constitutes “good faith security research” isn’t black and \nwhite and even the definition provided by DOJ constitutes  mostly examples of research activities \nthat may or may not be covered by the policy.171 Even if a defendant tries to convince the DOJ \nthat their actions are “ good faith security research ,” it cannot be used as an  affirmative \ndefense.172 If the DOJ brings a charge under the CFAA, “ good faith security research ” is not \ngrounds for dismissal.173 Thus, while this policy change by the DOJ at least expresses an \nunderstanding of the importance of security research and seeks to limit criminal liability, it does \nnothing to shield researchers from the risk of frivolous and overly broad CFAA civil litigation.174 \nUnfortunately, t he risk of being sued civilly for  reporting a discovered vulnerability to the \naffected party remains.175 Brian Krebs, a cybersecurity expert who runs krebsonsecurity.com, \nreports that when researchers reach out to seek advice on how best to report a security vulnerability, it’s not criminal prosecution they are most worried about  but rather “[i]t’s that \nthey’re going to get sued by the company responsible for the security vulnerability or data leak. ”\n176 Given these concerns and the failure of Congress and the courts to provide more \nprotection for researchers , efforts  in the private sector  have been made to mitigate this risk. Bug \nbounties and V ulnerability  Disclosure Programs (VDP) present some promise in protecting \nsecurity researchers, but they come with  their own limitations.  \n \n169 Id. \n170 Id. \n171 Supra note 164. \n172What Counts as “Good Faith Security Research?”, KrebsonSecurity  (Jun. 3, 2022), \nhttps://krebsonsecurity.com/2022/06/what -counts -as-good -faith-security -research/  [https://perma.cc/5MJU -Y9WU ]. \n173 Id. \n174 See supra note 165. \n175 See s upra note 169. \n176 Id. \n\n \n176  B. Researchers Attempt to P rotect T hemselves by R esponsibly D isclosing V ulnerabilities to \nCompanies O nly G oes as F ar as T hose C ompanies Willing to Adopt T hem.  \nIn 2001, a hacker, known as Rain Forest Puppy (RFP), released his “disclosure policy for \npublishing information about security holes ,” which could be used to serve others who were \nsearching for bugs and vulnerabilities.177 The purpose was to try to standardize the process by \nwhich researchers and vendors could work together on security bug disclosures .178 RFP laid out \nthis framework to avoid vendors trying to blame researchers who found the bug and vice versa, \nresearchers trying to blame vendors for shoddy work or rushing to launch a product before it was fully secure.\n179 RFP’s disclosure policy was designed to start communication between vendors \nand researchers to “get the bugs fixed.”180 While this disclosure policy was initiated from the \nresearcher ’s side, RFP did find vendors receptive to the process, including Microsoft and other \nsmaller software vendors.181 \nThe concept of voluntary vulnerability disclosure was slowly integrated  into vendors ’ \nprocesses. In a process that began in 2005, the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) released ISO/IEC 29147.\n182 \nISO/IEC 29147 sought to standardize the process by which vulnerabilities are disclosed.183 For \nsecurity researchers , this mean s having a “process through which vendors and vulnerability \n \n177 Kim Zetter, Three Minutes with Rain Forest Puppy , PCWorld.com (Sept. 28, 2001), \nhttp://pcworld.com/news/article/0%2Caid%2C63944%2C00.asp \n(https://web.archive.org/web/20010930194040/http://pcworld.com/news/article/0,aid,63944,00.asp) . \n178 Id. \n179 Id. \n180 Id. \n181 Id. \n182 A brief history of vulnerability disclosure , disclose.io, https://disclose.io/history/ [https://perma.cc/DE76 -3B5Q ] \n(last visited Dec. 18, 2024) . \n183 Vulnerability disclosure , ISO, https://www.iso.org/obp/ui/#iso:std:iso -iec:29147:ed- 1:v1:en \nhttps://perma.cc/Z8NJ -GEH2  \nensuring that identified vulnerabilities are addressed; b) minimizing the risk from vulnerabilities; c) providing users with sufficient information to evaluate risks from vulnerabilities to their systems; [and] d) setting expectations to \npromote positive communication and coordination among involved parties.”)  (last visited Dec . 18, 2024).", "files_in_pdf": []}